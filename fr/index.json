[{"authors":"alexandre-drouin","categories":null,"content":"Alexandre Drouin is a Research Scientist and the Research Lead of the Human Decision Support Program. He joined ServiceNow from Element AI, which he integrated in 2017. He holds a Ph.D. in Computer Science from Université Laval, where he was supervised by François Laviolette. In addition to his position at ServiceNow Research, he is an Adjunct Professor in the Department of Computer Science and Software Engineering at Université Laval and is a member of the scientific committee of Brief.Science. Alexandre’s research interests include algorithms for causal discovery/inference from observational data, practical applications of causal inference, learning robust models from heterogeneous data, and time series forecasting.\n","date":1654214400,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1654214400,"objectID":"8e50c806833bfcf2a42476fdd52064a5","permalink":"https://elementai.github.io/servicenowresearch/fr/author/alexandre-drouin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/alexandre-drouin/","section":"authors","summary":"Alexandre Drouin is a Research Scientist and the Research Lead of the Human Decision Support Program. He joined ServiceNow from Element AI, which he integrated in 2017. He holds a Ph.","tags":null,"title":"Alexandre Drouin","type":"authors"},{"authors":"alexandre-lacoste","categories":null,"content":"Alexandre joined Element AI as its first Research Scientist in the early 2017. His main interests revolve around multi-task transfer learning using probabilistic machine learning, causality and meta-learning. In his free time, he explores how AI can help solve climate change issues.\nPrior to Element AI, Alexandre worked 3 years at Google in the Research Group for building end-to-end question answering systems using deep learning. This system is currently in use by google’s search engine to answer some of the most complex questions.\nHe obtained his PhD in theoretical machine learning, working with Mario Marchand and Francois Laviolette, during which he developed bridges between Bayes and PAC-Bayes theories. He obtained his Master with Douglas Eck in the former MILA where he applied machine learning to music. Finally, he studied Physics during his undergrad.\nAlexandre has been playing with neural networks in his early career, in the beginning of 2000, where he self-thought himself machine learning using Christopher Bishop’s first book. He applied his knowledge to solve computer vision problems in the production line of optical components at ITF technologies.\n","date":1654214400,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1654214400,"objectID":"0bc106a1cae3272949931207b341afec","permalink":"https://elementai.github.io/servicenowresearch/fr/author/alexandre-lacoste/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/alexandre-lacoste/","section":"authors","summary":"Alexandre joined Element AI as its first Research Scientist in the early 2017. His main interests revolve around multi-task transfer learning using probabilistic machine learning, causality and meta-learning. In his free time, he explores how AI can help solve climate change issues.","tags":null,"title":"Alexandre Lacoste","type":"authors"},{"authors":"david-berger","categories":null,"content":"PhD student at Mila and Visiting Researcher at ServiceNow. Interested in causal inference, and dynamic treatment regimes.\n","date":1654214400,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1654214400,"objectID":"92943431457824bf0ede3f6f1a37b09e","permalink":"https://elementai.github.io/servicenowresearch/fr/author/david-berger/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/david-berger/","section":"authors","summary":"PhD student at Mila and Visiting Researcher at ServiceNow. Interested in causal inference, and dynamic treatment regimes.","tags":null,"title":"David Berger","type":"authors"},{"authors":"christopher-pal","categories":null,"content":"Chris Pal is an associate professor in the Department of computer and software engineering at the École Polytechnique of Montreal. Prior to arriving in Montreal, he was a professor in the Department of Computer Science at the University of Rochester. He has been a research scientist with the University of Massachusetts and has also been affiliated with the Interactive Visual Media Group and the Machine Learning and Applied Statistics groups at Microsoft Research. His research at Microsoft lead to three patents on image processing, computer vision and interactive multimedia. He earned his masters in Math and PhD from the University of Waterloo in Canada. During his masters research he developed methods for automated cartography and the analysis of high resolution digital aerial photography. He was also involved with a number of software engineering projects developing spatial databases for managing environmental information. His PhD research led to contributions applying probability models and optimization techniques to image, video and signal processing. During his PhD studies Chris was also a research assistant at the University of Toronto in the Department of Electrical and Computer Engineering. At Toronto he collaborated closely with the Banting and Best Department of Medical Research. He performed research on image processing and statistical methods for the analysis of large scale genomics and computational molecular biology experiments using DNA microarrays. Prior to his graduate studies Chris was with the multimedia research company Interval in Palo Alto, CA (Silicon Valley). As a result of his research at Interval he was awarded a patent on audio signal processing.\n","date":1650844800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1650844800,"objectID":"8d23d582fca0cb764f65715e66cbc684","permalink":"https://elementai.github.io/servicenowresearch/fr/author/christopher-pal/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/christopher-pal/","section":"authors","summary":"Chris Pal is an associate professor in the Department of computer and software engineering at the École Polytechnique of Montreal. Prior to arriving in Montreal, he was a professor in the Department of Computer Science at the University of Rochester.","tags":null,"title":"Christopher Pal","type":"authors"},{"authors":"florian-golemo","categories":null,"content":"Postdoc in machine learning for robots at Mila \u0026amp; ElementAI. Supervised by\nLiam Paull (Mila), Aaron Courville (Mila), and Chris Pal (EAI). Interested in sim2real transfer, robot perception and shoddy robots.\n","date":1650844800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1650844800,"objectID":"e78f71c83540514082665d5281af5799","permalink":"https://elementai.github.io/servicenowresearch/fr/author/florian-golemo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/florian-golemo/","section":"authors","summary":"Postdoc in machine learning for robots at Mila \u0026 ElementAI. Supervised by\nLiam Paull (Mila), Aaron Courville (Mila), and Chris Pal (EAI). Interested in sim2real transfer, robot perception and shoddy robots.","tags":null,"title":"Florian Golemo","type":"authors"},{"authors":"pau-rodriguez","categories":null,"content":"Pau is a Research Scientist at ServiceNow, an adjunct professor at Universitat Autonoma de Barcelona, and an ELLIS member. His main research interest is machine learning methods that generalize with fewer labeled data, closer to how humans learn. Previously, he did a Ph.D. in Deep Learning and Computer Vision at CVC-UAB. Before, he finished the Master of Artificial Intelligence at KU Leuven. He would like AI to solve the most critical problems of humanity.\n","date":1649635200,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1649635200,"objectID":"1b7f669ad449e10735347b1f985d235c","permalink":"https://elementai.github.io/servicenowresearch/fr/author/pau-rodriguez/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/pau-rodriguez/","section":"authors","summary":"Pau is a Research Scientist at ServiceNow, an adjunct professor at Universitat Autonoma de Barcelona, and an ELLIS member. His main research interest is machine learning methods that generalize with fewer labeled data, closer to how humans learn.","tags":null,"title":"Pau Rodriguez","type":"authors"},{"authors":"rim-assouel","categories":null,"content":"","date":1649635200,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1649635200,"objectID":"3d3e08907f091fbbc45d98e1136d2481","permalink":"https://elementai.github.io/servicenowresearch/fr/author/rim-assouel/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/rim-assouel/","section":"authors","summary":"","tags":null,"title":"Rim Assouel","type":"authors"},{"authors":"yoshua-bengio","categories":null,"content":"Recognized worldwide as one of the leading experts in artificial intelligence, Yoshua Bengio is most known for his pioneering work in deep learning, earning him the 2018 A.M. Turing Award, “the Nobel Prize of Computing,” with Geoffrey Hinton and Yann LeCun. He is a Full Professor at Université de Montréal, and the Founder and Scientific Director of Mila – Quebec AI Institute. He co-directs the CIFAR Learning in Machines \u0026amp; Brains program as Senior Fellow and acts as Scientific Director of IVADO. In 2019, he was awarded the prestigious Killam Prize and in 2021, became the second most cited computer scientist in the world. He is a Fellow of both the Royal Society of London and Canada, Knight of the Legion of Honor of France and Officer of the Order of Canada. Concerned about the social impact of AI and the objective that AI benefits all, he actively contributed to the Montreal Declaration for the Responsible Development of Artificial Intelligence.\n","date":1649635200,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1649635200,"objectID":"ba28e558ebbd5104df02d3e3b352f799","permalink":"https://elementai.github.io/servicenowresearch/fr/author/yoshua-bengio/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/yoshua-bengio/","section":"authors","summary":"Recognized worldwide as one of the leading experts in artificial intelligence, Yoshua Bengio is most known for his pioneering work in deep learning, earning him the 2018 A.M. Turing Award, “the Nobel Prize of Computing,” with Geoffrey Hinton and Yann LeCun.","tags":null,"title":"Yoshua Bengio","type":"authors"},{"authors":"issam-h.-laradji","categories":null,"content":"Issam Laradji is a research scientist at ServiceNow who focuses on methods that minimize the amount of labels required to efficiently train machine learning models. He completed his postdoc at McGill’s Graphics lab and completed his PhD at the Machine Learning lab of University of British Columbia. His current topics of interest are natural language processing, computer vision (both 2D and 3D), and optimization. On the side, he continuously works on Haven-AI, a toolkit to help people build end-to-end deep learning methods and manage large-scale experiments.\n","date":1648339200,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1648339200,"objectID":"cd1f1dd6d81b6fb6ff7689df66fff2e5","permalink":"https://elementai.github.io/servicenowresearch/fr/author/issam-h.-laradji/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/issam-h.-laradji/","section":"authors","summary":"Issam Laradji is a research scientist at ServiceNow who focuses on methods that minimize the amount of labels required to efficiently train machine learning models. He completed his postdoc at McGill’s Graphics lab and completed his PhD at the Machine Learning lab of University of British Columbia.","tags":null,"title":"Issam H. Laradji","type":"authors"},{"authors":"david-vazquez","categories":null,"content":"David has degrees in Software Engineering from the Universidade de A Coruña (UDC) and Computer Science from the Autonomous University of Barcelona (UAB), which includes a Masters in Computer Vision and Artificial Intelligence and a PhD in Computer Science. He then completed a postdoc at the Computer Vision Center (CVC), as well as a postdoc between CVC and Montréal Institute of Learning Algorithm (MILA). Previously he worked in Computer Vision applied to the automotive industry, including: (i) Advanced Driver Assistance Systems (ADAS) with a focus on pedestrian detection where he created a driving simulator and adapted it using Domain Adaptation to work in the real world. (ii) Created an Autonomous Driving simulator and a real Autonomous Vehicle prototype where he worked mainly in the perception system of the vehicle (Object detection, Semantic Segmentation, 3D reconstruction, SLAM, etc).\n","date":1646092800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1646092800,"objectID":"449bbf1e6d55d04344b989f0e5a368ea","permalink":"https://elementai.github.io/servicenowresearch/fr/author/david-vazquez/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/david-vazquez/","section":"authors","summary":"David has degrees in Software Engineering from the Universidade de A Coruña (UDC) and Computer Science from the Autonomous University of Barcelona (UAB), which includes a Masters in Computer Vision and Artificial Intelligence and a PhD in Computer Science.","tags":null,"title":"David Vazquez","type":"authors"},{"authors":"marc-etienne-brunet","categories":null,"content":"Marc-Etienne is a PhD candidate at the Vector Institute studying machine learning interpretability and algorithmic bias under the supervision of Richard Zemel and Ashton Anderson. For the last year, he has been developing new methods of sample-based explainability at Element AI.\nPreviously, he was co-founder and CTO of Neo Smart Blinds, an Internet of Things (IoT) startup now selling its products and services globally. He has also worked as a consultant in IoT and predictive analytics.\nHe holds a Master’s in machine learning from the University of Toronto, and a Bachelor’s in electrical engineering from McGill University in Montreal.\n","date":1639440000,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1639440000,"objectID":"b1b33f1e678cfc6830a49f262fd19b8c","permalink":"https://elementai.github.io/servicenowresearch/fr/author/marc-etienne-brunet/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/marc-etienne-brunet/","section":"authors","summary":"Marc-Etienne is a PhD candidate at the Vector Institute studying machine learning interpretability and algorithmic bias under the supervision of Richard Zemel and Ashton Anderson. For the last year, he has been developing new methods of sample-based explainability at Element AI.","tags":null,"title":"Marc-Etienne Brunet ","type":"authors"},{"authors":"pierre-andre-noel","categories":null,"content":"Pierre-André Noël is an Applied Research Scientist at ServiceNow Research. His recent work involves Graph Neural Networks, Self-Supervised Learning, Relational Databases, Knowledge Graphs and/or Constrained Inference. He holds a PhD in Physics from Université Laval and was a postdoctoral researcher at University of California Davis. His doctoral and postdoctoral research pertained to Complex Networks, Statistical Mechanics and Stochastic Processes. In 2017, he joined an NLP team at Element AI where he spent the following years building core capabilities and working on special projects. ServiceNow acquired Element AI in 2021, and Pierre-André now focuses on fundamental research, with an applied twist.\n","date":1639440000,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1639440000,"objectID":"8c9d162e09c24d9e123e027867aba5f8","permalink":"https://elementai.github.io/servicenowresearch/fr/author/pierre-andre-noel/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/pierre-andre-noel/","section":"authors","summary":"Pierre-André Noël is an Applied Research Scientist at ServiceNow Research. His recent work involves Graph Neural Networks, Self-Supervised Learning, Relational Databases, Knowledge Graphs and/or Constrained Inference. He holds a PhD in Physics from Université Laval and was a postdoctoral researcher at University of California Davis.","tags":null,"title":"Pierre-André Noël","type":"authors"},{"authors":"torsten-scholak","categories":null,"content":"Torsten is a senior researcher and project leader in the Human-Machine Interaction Through Language research program. His current research interest is deep learning for code, especially with large language models and integrating symbolic reasoning. This year, he is co-organizing the Deep Learning for Code workshop at ICLR. Previously, he has been more focused on semantic parsing. He has published several papers on translating natural language questions into SQL queries. One of his most successful works on this topic is the PICARD project, which is a state-of-the-art text-to-SQL parser.\n","date":1639440000,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1639440000,"objectID":"d7baf1acc124441f0b2fab43d8149967","permalink":"https://elementai.github.io/servicenowresearch/fr/author/torsten-scholak/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/torsten-scholak/","section":"authors","summary":"Torsten is a senior researcher and project leader in the Human-Machine Interaction Through Language research program. His current research interest is deep learning for code, especially with large language models and integrating symbolic reasoning.","tags":null,"title":"Torsten Scholak","type":"authors"},{"authors":"philippe-brouillard","categories":null,"content":"PhD student at Mila/University of Montreal and visiting researcher at ServiceNow. His interests lie at the intersection of causal discovery and machine learning.\n","date":1639267200,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1639267200,"objectID":"db82441a34671ca242a44c0944f29ea9","permalink":"https://elementai.github.io/servicenowresearch/fr/author/philippe-brouillard/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/philippe-brouillard/","section":"authors","summary":"PhD student at Mila/University of Montreal and visiting researcher at ServiceNow. His interests lie at the intersection of causal discovery and machine learning.","tags":null,"title":"Philippe Brouillard","type":"authors"},{"authors":"oleksiy-ostapenko","categories":null,"content":"I am a third-year Ph.D. student at Mila supervised by professor Laurent Charlin. During my Master’s degree, which I obtained at the Humboldt University of Berlin, I interned at SAP AI Research lab, where I also spent some time working as an associate researcher. My main research interest lies in developing systems that can accumulate and transfer knowledge throughout their lifetime.\n","date":1638748800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1638748800,"objectID":"a684c5ae942e14eda642bcd7e3465d0f","permalink":"https://elementai.github.io/servicenowresearch/fr/author/oleksiy-ostapenko/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/oleksiy-ostapenko/","section":"authors","summary":"I am a third-year Ph.D. student at Mila supervised by professor Laurent Charlin. During my Master’s degree, which I obtained at the Humboldt University of Berlin, I interned at SAP AI Research lab, where I also spent some time working as an associate researcher.","tags":null,"title":"Oleksiy Ostapenko","type":"authors"},{"authors":"sai-rajeswar-mudumba","categories":null,"content":"Sai Rajeswar is a Ph.D. student at MILA advised by Prof.Aaron Courville. Earlier he received his Master’s from the Indian Institute of Technology Delhi in Computer Science and worked as a Researcher at Xerox Research Center. During his Ph.D. he had an opportunity to spend time at ElementAI as a visiting researcher and at DeepMind as a Research Scientist Intern. His research has been focused on unsupervised learning and large-scale representation learning. More recently, his research is pivoting towards self-supervised exploration in RL and skill discovery. Besides being a massive music addict (classical \u0026amp; jazz), he loves hiking, cycling, traveling, poetry, and festivals.\n","date":1637020800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1637020800,"objectID":"6ede5490a7cae3e64bae5d7dc2740e84","permalink":"https://elementai.github.io/servicenowresearch/fr/author/sai-rajeswar-mudumba/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/sai-rajeswar-mudumba/","section":"authors","summary":"Sai Rajeswar is a Ph.D. student at MILA advised by Prof.Aaron Courville. Earlier he received his Master’s from the Indian Institute of Technology Delhi in Computer Science and worked as a Researcher at Xerox Research Center.","tags":null,"title":"Sai Rajeswar Mudumba","type":"authors"},{"authors":"dzmitry-bahdanau","categories":null,"content":"Dzmitry (Dima) Bahdanau is a Sn. Staff Research Scientist and the Research Lead of the Human-Machine Interaction Through Language Program. He holds a PhD in Computer Science from Mila, Université de Montréal, where he was supervised by Yoshua Bengio. Dzmitry’s research interests include but are not limited to goal-driven dialogue, AI-based code modeling and semantic parsing, language understanding and systematic generalization, connecting symbolic AI with deep learning, semantic parsing and goal-driven dialogue. In addition to his position at ServiceNow Research, Dzmitry is an Adjunct Professor at McGill University and Industry Core Member at Mila, Quebec Artificial Intelligence Institute.\n","date":1636934400,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1636934400,"objectID":"36a3df0861de2bcae25a83f4c3132473","permalink":"https://elementai.github.io/servicenowresearch/fr/author/dzmitry-bahdanau/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/dzmitry-bahdanau/","section":"authors","summary":"Dzmitry (Dima) Bahdanau is a Sn. Staff Research Scientist and the Research Lead of the Human-Machine Interaction Through Language Program. He holds a PhD in Computer Science from Mila, Université de Montréal, where he was supervised by Yoshua Bengio.","tags":null,"title":"Dzmitry Bahdanau","type":"authors"},{"authors":"gaurav-sahu","categories":null,"content":"Gaurav is a Visiting Researcher at ServiceNow Research, where he is exploring the feasibility of large pretrained language models for data augmentation. He is a Ph.D. student in the NLP Lab, University of Waterloo, advised by Prof. Olga Vechtomova. In general, his research interests include generative text modelling and multimodal learning. Apart from research, he is much enthused by language and art. He sketches and paints (his art collection), and is currently learning to speak Japanese and French. He also enjoys writing and making music from time to time.\n","date":1636934400,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1636934400,"objectID":"c414853af87ade8563c31fa6f457a770","permalink":"https://elementai.github.io/servicenowresearch/fr/author/gaurav-sahu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/gaurav-sahu/","section":"authors","summary":"Gaurav is a Visiting Researcher at ServiceNow Research, where he is exploring the feasibility of large pretrained language models for data augmentation. He is a Ph.D. student in the NLP Lab, University of Waterloo, advised by Prof.","tags":null,"title":"Gaurav Sahu","type":"authors"},{"authors":"parmida-atighhehchian","categories":null,"content":"Parmida Atighehchian is an Applied Research Scientist at ServiceNow Research. Her work focuses on finding practical AI solutions to industry ML practitioners’ pain points, including lack of data, model explainability, and model performance evaluation. After completing a Master’s in computer vision and machine learning at Concordia University, for which she received a Concordia Merit Scholarship among other awards, Parmida shifted her focus to active learning, uncertainty estimation, and explainability. Parmida is a co-author and maintainer of the popular bayesian active learning library (BaaL), which was open-sourced in 2018 and integrated into Pytorch Lightning in 2021. Together with her collaborators in BaaL, she has patented their novel methodology to use Bayesian Active Learning in production and has published several papers to promote the vast applications of active learning, which goes beyond data labeling. Her last publication in collaboration with OATML-OXford at ICML 2022 introduces a new methodology to simulate point base acquisition in a batch active learning regime. Currently, Parmida works on methods of effective and practical data augmentation for intent classification and intent discovery.\n","date":1636934400,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1636934400,"objectID":"2a9e1f0be591924915f73254b05135a4","permalink":"https://elementai.github.io/servicenowresearch/fr/author/parmida-atighhehchian/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/parmida-atighhehchian/","section":"authors","summary":"Parmida Atighehchian is an Applied Research Scientist at ServiceNow Research. Her work focuses on finding practical AI solutions to industry ML practitioners’ pain points, including lack of data, model explainability, and model performance evaluation.","tags":null,"title":"Parmida Atighhehchian","type":"authors"},{"authors":"timothy-j.-odonnell","categories":null,"content":"Timothy J. O’Donnell is Assistant Professor in the Department of Linguistics at McGill University. In his research, Timothy develops mathematical models of language generalization, learning, and processing. His research draws on experimental methods from psychology, formal modeling techniques from natural language processing, theoretical tools from linguistics, and problems from all three.\n","date":1636934400,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1636934400,"objectID":"fd68920a97535f258eaeaed9b44885de","permalink":"https://elementai.github.io/servicenowresearch/fr/author/timothy-j.-odonnell/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/timothy-j.-odonnell/","section":"authors","summary":"Timothy J. O’Donnell is Assistant Professor in the Department of Linguistics at McGill University. In his research, Timothy develops mathematical models of language generalization, learning, and processing. His research draws on experimental methods from psychology, formal modeling techniques from natural language processing, theoretical tools from linguistics, and problems from all three.","tags":null,"title":"Timothy J. O'Donnell","type":"authors"},{"authors":"harm-de-vries","categories":null,"content":"Harm de Vries is a research scientist in the Human-Machine Interaction Through Language program. He holds a PhD in Computer Science from Mila, Universite de Montreal, where he was supervised by Aaron Courville. During his PhD, he worked on machine learning methods for (visually) grounded language understanding. He’s currently focused on how NLP methods can improve human-machine interaction and is therefore interested in a wide range of research topics such as large language models, semantic parsing, task-oriented dialogue, and text2code. His research has been published in EMNLP, ICLR, NeurIPS, CVPR, and ECCV.\n","date":1634256000,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1634256000,"objectID":"6f1dc0f5f53f3586a0035ad0392c02dd","permalink":"https://elementai.github.io/servicenowresearch/fr/author/harm-de-vries/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/harm-de-vries/","section":"authors","summary":"Harm de Vries is a research scientist in the Human-Machine Interaction Through Language program. He holds a PhD in Computer Science from Mila, Universite de Montreal, where he was supervised by Aaron Courville.","tags":null,"title":"Harm de Vries","type":"authors"},{"authors":"nathan-schucher","categories":null,"content":"Nathan is a Research Developer in the Human-Machine Interaction Through Language team at ServiceNow Research. He works on how to improve task and model adaptation for large language models–with particular focus on semantic parsing and code generation. For instance, he contributed to the development of PICARD, a state-of-the-art algorithm for constrained decoding (2021), and his recent work on prompt tuning for low-resource semantic parsing will appear at ACL 2022. In parallel to his work at ServiceNow Research, Nathan is completing an M.Sc in Computer Science at McGill University and Mila with Prof. Siva Reddy. Previously he worked as a software developer at ElementAI, building a platform for large-scale machine learning experimentation.\n","date":1634256000,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1634256000,"objectID":"ff7dedfec9d08b8812dcb5eac50d6bdb","permalink":"https://elementai.github.io/servicenowresearch/fr/author/nathan-schucher/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/nathan-schucher/","section":"authors","summary":"Nathan is a Research Developer in the Human-Machine Interaction Through Language team at ServiceNow Research. He works on how to improve task and model adaptation for large language models–with particular focus on semantic parsing and code generation.","tags":null,"title":"Nathan Schucher","type":"authors"},{"authors":"vaibhav-adlakha","categories":null,"content":"My current research interests are information extraction, question answering, and conversational agents. I am interested in creating systems that not only can read documents, but also can comprehend the information within, to answer our questions and converse with us.\n","date":1633046400,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1633046400,"objectID":"50d05e60f659c4869cebc815c3eef791","permalink":"https://elementai.github.io/servicenowresearch/fr/author/vaibhav-adlakha/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/vaibhav-adlakha/","section":"authors","summary":"My current research interests are information extraction, question answering, and conversational agents. I am interested in creating systems that not only can read documents, but also can comprehend the information within, to answer our questions and converse with us.","tags":null,"title":"Vaibhav Adlakha","type":"authors"},{"authors":"raymond-li","categories":null,"content":"Raymond is a Research Developer in the Human-Machine Interaction Through Language program. His research advances the path towards more natural interactions between humans and machines, using language as an interface. At ServiceNow Research, his work has focused on various NLP topics such as summarization and text-to-SQL. He now primarily works on semantic parsing and code generation problems. Raymond’s background is in Applied Mathematics and Computer Science. He holds a Master’s and engineering degree from École Polytechnique (France) as well as a MSc. in Computer Science from Polytechnique Montreal where he was supervised by Christopher Pal.\n","date":1609891200,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1609891200,"objectID":"76671b64a5cdf49f9c6e6edb3cf24e02","permalink":"https://elementai.github.io/servicenowresearch/fr/author/raymond-li/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/raymond-li/","section":"authors","summary":"Raymond is a Research Developer in the Human-Machine Interaction Through Language program. His research advances the path towards more natural interactions between humans and machines, using language as an interface. At ServiceNow Research, his work has focused on various NLP topics such as summarization and text-to-SQL.","tags":null,"title":"Raymond Li","type":"authors"},{"authors":"rafael-pardinas","categories":null,"content":"Rafael is a researcher at ServiceNow Research with an extensive background in software engineering and distributed systems. Currently focusing on fundamental and applied Machine Learning research.\nHe holds a MSc. in Computer Science and a BSc. in Physics; the combination of which has provided a good foundation towards his current role in Reinforcement Learning and Natural Language Processing research.\nFor the last two years he has been mostly focusing on Deep Reinforcement Learning projects specifically Offline RL, Policy Optimisation, RL driven Energy-Based Models and the intersection between RL and NLP.\n","date":1581033600,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1581033600,"objectID":"f323bb1e143afbf22b750b7fc39a1b97","permalink":"https://elementai.github.io/servicenowresearch/fr/author/rafael-pardinas/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/rafael-pardinas/","section":"authors","summary":"Rafael is a researcher at ServiceNow Research with an extensive background in software engineering and distributed systems. Currently focusing on fundamental and applied Machine Learning research.\nHe holds a MSc. in Computer Science and a BSc.","tags":null,"title":"Rafael Pardinas","type":"authors"},{"authors":"cyril-ibrahim","categories":null,"content":"Cyril is a research developer at ServiceNow Research. He worked on different research projects focused on reinforcement learning, computer vision, and deep learning, while also working on applied research projects such as real-world applications of reinforcement learning . He completed a master’s degree in software engineering at Polytechnique Montreal with a focus on computer graphics and machine learning and did his research project on the use of computer simulations to train self-driving cars under the supervision of Christopher Pal.\n","date":1569369600,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1569369600,"objectID":"698cfba72deef94350d37f87ac12f154","permalink":"https://elementai.github.io/servicenowresearch/fr/author/cyril-ibrahim/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/cyril-ibrahim/","section":"authors","summary":"Cyril is a research developer at ServiceNow Research. He worked on different research projects focused on reinforcement learning, computer vision, and deep learning, while also working on applied research projects such as real-world applications of reinforcement learning .","tags":null,"title":"Cyril Ibrahim","type":"authors"},{"authors":"christopher-beckham","categories":null,"content":"Christopher Beckham is currently a PhD student at Mila, supervised by Christopher Pal. His research interests lie in unsupervised and weakly supervised learning, with a particular emphasis on autoencoders, adversarial learning, and inverse graphics. He obtained his MASc at École Polytechnique Montréal, and before that a BCMS(Hons) at The University of Waikato in New Zealand, whose machine learning lab is most prominently known for its machine learning workbench WEKA.\n","date":1558569600,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1558569600,"objectID":"2fc8f0011bc029a3dfe20d0534f786e6","permalink":"https://elementai.github.io/servicenowresearch/fr/author/christopher-beckham/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/christopher-beckham/","section":"authors","summary":"Christopher Beckham is currently a PhD student at Mila, supervised by Christopher Pal. His research interests lie in unsupervised and weakly supervised learning, with a particular emphasis on autoencoders, adversarial learning, and inverse graphics.","tags":null,"title":"Christopher Beckham","type":"authors"},{"authors":"joel-lamy-poirier","categories":null,"content":"Joel is an Applied Research Scientist in the Emerging Technologies Lab, with experience in various fields of artificial intelligence including computer vision and natural language processing. He focuses on efficient implementations of deep neural networks, particularly on large scale distributed training and large language models. He recently proposed a new form of 3d parallelism, which improves on the state of the art in scalability and computational efficiency.\nPrior to joining ServiceNow, he was a graduate researcher at the Perimeter Institute for Theoretical Physics, where he worked on exact computations in supersymmetric quantum field theory and string theory. He has a Ph.D. in physics from the University of Waterloo (2016).\n","date":1544832000,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1544832000,"objectID":"5f0be4385f5675f85abb97d2eb51f082","permalink":"https://elementai.github.io/servicenowresearch/fr/author/joel-lamy-poirier/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/joel-lamy-poirier/","section":"authors","summary":"Joel is an Applied Research Scientist in the Emerging Technologies Lab, with experience in various fields of artificial intelligence including computer vision and natural language processing. He focuses on efficient implementations of deep neural networks, particularly on large scale distributed training and large language models.","tags":null,"title":"Joel Lamy Poirier","type":"authors"},{"authors":"alexandre-piche","categories":null,"content":"Alexandre Piche is a Senior Research Scientist at ServiceNow Research. He is interested in bridging the gap between academic research in Reinforcement Learning (RL) and applications in energy, education, and enterprise AI. At ServiceNow Research, he focuses on sequential decision making under uncertainty, RL for generative models, and generalization in RL. Alexandre is completing his PhD at Mila, Université de Montreal and has previously interned at DeepMind, London, and Riken AIP, Tokyo (remote).\n","date":1538006400,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1538006400,"objectID":"98c45752a5bea1e312ae58cc8563b6d0","permalink":"https://elementai.github.io/servicenowresearch/fr/author/alexandre-piche/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/alexandre-piche/","section":"authors","summary":"Alexandre Piche is a Senior Research Scientist at ServiceNow Research. He is interested in bridging the gap between academic research in Reinforcement Learning (RL) and applications in energy, education, and enterprise AI.","tags":null,"title":"Alexandre Piche","type":"authors"},{"authors":"amine-el-hattami","categories":null,"content":"Amine is a research developer at ServiceNow Research. His main work is around natural language processing and deep learning. Specifically, he contributes to projects that use large language models to enhance ServiceNow’s product. Amine holds a bachelor’s degree in electrical engineering, a master’s degree in NLP and deep learning, and is currently pursuing a Ph.D. in the same field at Mila. Before joining ServiceNow, Amine held multiple software engineering positions in various industries like video processing, where he worked on embedded systems design, virtual assistant design, and the finance industry, where he designed training and deployment pipelines for large language models.\n","date":1483228800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1483228800,"objectID":"c892428a3e61f45194904c72f0dcd9a8","permalink":"https://elementai.github.io/servicenowresearch/fr/author/amine-el-hattami/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/amine-el-hattami/","section":"authors","summary":"Amine is a research developer at ServiceNow Research. His main work is around natural language processing and deep learning. Specifically, he contributes to projects that use large language models to enhance ServiceNow’s product.","tags":null,"title":"Amine El Hattami","type":"authors"},{"authors":"nicolas-chapados","categories":null,"content":"Nicolas Chapados holds an engineering degree from McGill University and a PhD in Computer Science from University of Montreal, Canada. While still writing his thesis and jointly with his advisor Yoshua Bengio, he co-founded ApSTAT Technologies in 2001, a machine learning technology transfer firm, to apply cutting-edge academic research ideas to areas such as insurance risk evaluation, supply chain planning, business forecasting, national defence, and hedge fund management. From this work, he also co-founded spin-off companies: Imagia, to detect and quantify cancer early with AI analysis of medical images, Element AI, to help organizations plan and implement their AI transformation, and Chapados Couture Capital, a quantitative asset manager. He holds the Chartered Financial Analyst (CFA) designation.\n","date":1483228800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":1483228800,"objectID":"5f93108c46b1ee2186a873fc3e2ab018","permalink":"https://elementai.github.io/servicenowresearch/fr/author/nicolas-chapados/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/nicolas-chapados/","section":"authors","summary":"Nicolas Chapados holds an engineering degree from McGill University and a PhD in Computer Science from University of Montreal, Canada. While still writing his thesis and jointly with his advisor Yoshua Bengio, he co-founded ApSTAT Technologies in 2001, a machine learning technology transfer firm, to apply cutting-edge academic research ideas to areas such as insurance risk evaluation, supply chain planning, business forecasting, national defence, and hedge fund management.","tags":null,"title":"Nicolas Chapados","type":"authors"},{"authors":"adam-salvail","categories":null,"content":"Adam began his career in AI research, focusing on topics related to forecasting and risk management, and has progressed into assuming various technical leadership roles. These roles include implementing innovation mandates that explore the use of machine learning for spatiotemporal forecasting, as well as managing multimillion-dollar R\u0026amp;D projects.\nCurrently, he leads the ‘ServiceNow Research Emerging Technologies Lab’. This team takes emergent AI technologies, from their beginnings in fundamental research, to their incorporation into the experience of ServiceNow’s users.\nAdam’s skillsets lie in building healthy cross-functional AI R\u0026amp;D teams, and in utilizing innovation management to deliver value to users. Both are built on his technical expertise in deep learning.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"a78d833afed882aad072f4e648dc74c3","permalink":"https://elementai.github.io/servicenowresearch/fr/author/adam-salvail/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/adam-salvail/","section":"authors","summary":"Adam began his career in AI research, focusing on topics related to forecasting and risk management, and has progressed into assuming various technical leadership roles. These roles include implementing innovation mandates that explore the use of machine learning for spatiotemporal forecasting, as well as managing multimillion-dollar R\u0026D projects.","tags":null,"title":"Adam Salvail","type":"authors"},{"authors":"ankit-vani","categories":null,"content":"I am a PhD candidate at Mila, Université de Montréal, under the supervision of Aaron Courville.\nI am interested in studying the emergence of complex and interesting phenomena from simple rules. This includes trying to uncover the principles that drive intricate behavior in biological intelligence, as well as building systems that operate on proposed simple principles towards emerging complex phenomena like language and understanding. Presently, I am pursuing the emergence of systematicity in deep neural networks, a critical trait for artificial intelligence to generalize in the real world.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"09fb29ba61ea50ecd19c618b80eecfe0","permalink":"https://elementai.github.io/servicenowresearch/fr/author/ankit-vani/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/ankit-vani/","section":"authors","summary":"I am a PhD candidate at Mila, Université de Montréal, under the supervision of Aaron Courville.\nI am interested in studying the emergence of complex and interesting phenomena from simple rules.","tags":null,"title":"Ankit Vani","type":"authors"},{"authors":"catherine-martin","categories":null,"content":"Catherine is the Research Enablement Program Manager of ServiceNow Research and joined ServiceNow in January 2021 with the acquisition of the company Element AI. Catherine holds a MSc in History from Université de Sherbrooke with a specialization in Digital Humanities in which she has established bridges between human science research and digital technologies. She has worked in several environments such as museums and research laboratories. Catherine switched fields when she joined Element AI at its early beginning. Like a Swiss army knife, she played many different roles, always supporting researchers and collaborators in their research activities.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"e1ec06f884bd775057622007b74dbb03","permalink":"https://elementai.github.io/servicenowresearch/fr/author/catherine-martin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/catherine-martin/","section":"authors","summary":"Catherine is the Research Enablement Program Manager of ServiceNow Research and joined ServiceNow in January 2021 with the acquisition of the company Element AI. Catherine holds a MSc in History from Université de Sherbrooke with a specialization in Digital Humanities in which she has established bridges between human science research and digital technologies.","tags":null,"title":"Catherine Martin","type":"authors"},{"authors":"charles-guille-escuret","categories":null,"content":"Charles has joined ServiceNow as a visiting researcher in December 2021 and investigates self-supervised approaches to learn powerful kernels without labels as well as their downstream practical applications. He is currently a third year PhD candidate at the Montreal Institute of Learning Algorithm where his research focuses on theoretical optimization and learning dynamics, with the goal of improving our understanding of how neural networks learn and behave in realistic settings.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"58a8a5783853bb5a1c6b77408f266f8e","permalink":"https://elementai.github.io/servicenowresearch/fr/author/charles-guille-escuret/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/charles-guille-escuret/","section":"authors","summary":"Charles has joined ServiceNow as a visiting researcher in December 2021 and investigates self-supervised approaches to learn powerful kernels without labels as well as their downstream practical applications. He is currently a third year PhD candidate at the Montreal Institute of Learning Algorithm where his research focuses on theoretical optimization and learning dynamics, with the goal of improving our understanding of how neural networks learn and behave in realistic settings.","tags":null,"title":"Charles Guille-Escuret","type":"authors"},{"authors":"chris-manning","categories":null,"content":"Christopher Manning is a professor of computer science and linguistics at Stanford University, Director of the Stanford Artificial Intelligence Laboratory, and Co-director of the Stanford Human-Centered Artificial Intelligence Institute. He works on software that can intelligently process, understand, and generate human language material. He is a leader in applying Deep Learning to Natural Language Processing, including exploring Tree Recursive Neural Networks, neural network dependency parsing, the GloVe model of word vectors, neural machine translation, question answering, and deep language understanding. He also focuses on computational linguistic approaches to parsing, natural language inference and multilingual language processing, including being a principal developer of Stanford Dependencies and Universal Dependencies. Manning is an ACM Fellow, a AAAI Fellow, an ACL Fellow, and a Past President of ACL. He has coauthored leading textbooks on statistical natural language processing and information retrieval. He is the founder of the Stanford NLP group (@stanfordnlp) and manages development of the Stanford CoreNLP software.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"5e1f775bd45ffac3bbc56fc591991e0c","permalink":"https://elementai.github.io/servicenowresearch/fr/author/chris-manning/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/chris-manning/","section":"authors","summary":"Christopher Manning is a professor of computer science and linguistics at Stanford University, Director of the Stanford Artificial Intelligence Laboratory, and Co-director of the Stanford Human-Centered Artificial Intelligence Institute. He works on software that can intelligently process, understand, and generate human language material.","tags":null,"title":"Chris Manning","type":"authors"},{"authors":"chris-tyler","categories":null,"content":"Chris has a background in physics focusing on statistical mechanics and optics. He is an avowed generalist with an interest in art, design, history, philosophy, languages, linguistics and poetry. Before coming to Service Now through the Element AI acquisition, Chris was a member of the Human-AI Interaction research team and the Applied Research Lab. In the context of the ATG, Chris is an AI Developer who can contribute to all aspects of AI/ML systems but with a particular interest in novel user interactions, especially those based on natural language.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"6b99981f43bc5e5eafe58fc1b1b9ce90","permalink":"https://elementai.github.io/servicenowresearch/fr/author/chris-tyler/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/chris-tyler/","section":"authors","summary":"Chris has a background in physics focusing on statistical mechanics and optics. He is an avowed generalist with an interest in art, design, history, philosophy, languages, linguistics and poetry. Before coming to Service Now through the Element AI acquisition, Chris was a member of the Human-AI Interaction research team and the Applied Research Lab.","tags":null,"title":"Chris Tyler","type":"authors"},{"authors":"daniel-tremblay","categories":null,"content":"Daniel is a Software Engineer who puts his broad skillset at the service of finding solutions to new problems. He has assumed technical leadership roles on various SaaS applications and machine learning projects and pushes a continuous delivery mindset to ensure the users’ needs are properly met. His lean entrepreneurial spirit has been a driving force in fostering a mentality of rapid prototyping to quickly de-risk projects.\nThese T-shaped skills, along with a focus on the end-user and an entrepreneurial drive allow Daniel to execute rapidly on proof-of-value cycles which are essential in a research transfer environment such as the Emerging Technologies Lab.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"1779e4e6bf1f84c71ffb30ce7628545b","permalink":"https://elementai.github.io/servicenowresearch/fr/author/daniel-tremblay/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/daniel-tremblay/","section":"authors","summary":"Daniel is a Software Engineer who puts his broad skillset at the service of finding solutions to new problems. He has assumed technical leadership roles on various SaaS applications and machine learning projects and pushes a continuous delivery mindset to ensure the users’ needs are properly met.","tags":null,"title":"Daniel Tremblay","type":"authors"},{"authors":"denis-kotcetkov","categories":null,"content":"Denis is an AI Developer with current interest in large language models and optimisation of algorithms for speed and performance on distributed systems. Before joining ElementAI and subsequently ServiceNow worked on projects in the fields of computer vision, object recognition and video processing, biometrics, domain specific languages and DBs. After joining the company worked in AI for Good team, later in ARL and contributed to various projects, like, metric few shots learning algorithms stability analysis, satellite image objects recognition (analysis of extend of villages destruction in Darfur civil war), satellite video stabilisation and objects tracking, searching for objects in online media (like tear gas canisters detection in protests videos and photos), synthetic image generation to augment existing data in low data environments, financial time series analysis. In various projects his contribution is from initial research and prototyping phase up to final product release.\nSkills at hand: Python, C++, CUDA, parallel systems, computer vision, object recognition, biometrics, video analysis, satellite image and video processing, synthetic image generation, neural networks, time series, large language models (tentatively), data ingress and processing, algorithms optimisation and prototyping.\nPersonal: Has a dog, does some sports\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"8b9dde58d0a447e8c79b94fe3e2e05c7","permalink":"https://elementai.github.io/servicenowresearch/fr/author/denis-kotcetkov/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/denis-kotcetkov/","section":"authors","summary":"Denis is an AI Developer with current interest in large language models and optimisation of algorithms for speed and performance on distributed systems. Before joining ElementAI and subsequently ServiceNow worked on projects in the fields of computer vision, object recognition and video processing, biometrics, domain specific languages and DBs.","tags":null,"title":"Denis Kotcetkov","type":"authors"},{"authors":"denis-therien","categories":null,"content":"Before joining ServiceNow Research, Dr. Denis Thérien was Vice-President Research and Partnerships at Element AI. He previously occupied a similar position at the Canadian Institute for Advanced Research (CIFAR), after serving as Vice Principal of Research and International Relations at McGill University.\nDr. Thérien received his B.Sc. from the Université de Montréal, and his M.Sc., and PhD from the University of Waterloo. He began his career at McGill in 1978, and was appointed Director of the School of Computer Science in 1997. He is interested in complexity theory and has done extensive work on developing algebraic characterizations for complexity classes. He is also a fan of logical tools, combinatorics, probabilistic methods and mathematics in general.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"8b3f3a22cdb3c70acb6fc1a991bea635","permalink":"https://elementai.github.io/servicenowresearch/fr/author/denis-therien/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/denis-therien/","section":"authors","summary":"Before joining ServiceNow Research, Dr. Denis Thérien was Vice-President Research and Partnerships at Element AI. He previously occupied a similar position at the Canadian Institute for Advanced Research (CIFAR), after serving as Vice Principal of Research and International Relations at McGill University.","tags":null,"title":"Denis Therien","type":"authors"},{"authors":"di-le","categories":null,"content":"Di Le is an AI/ML design thought-leader, strategist, and a key contributor to the intelligent automation of enterprise software at ServiceNow. Over the past decade, she has designed autonomous mobile robots to scale in North America, Europe and Asia, human-centered AI design frameworks, and is always focusing on AI awareness, explainability, and responsibility.\nAs a technology creator, public speaker, and a CES Innovations Awards judge, the continued dialogue and pursuit of responsible AI and data science and creating technology that is both benevolent and beneficial to humanity, is always at the center of her focus.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"7b901494bba15fbf11a517585a063679","permalink":"https://elementai.github.io/servicenowresearch/fr/author/di-le/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/di-le/","section":"authors","summary":"Di Le is an AI/ML design thought-leader, strategist, and a key contributor to the intelligent automation of enterprise software at ServiceNow. Over the past decade, she has designed autonomous mobile robots to scale in North America, Europe and Asia, human-centered AI design frameworks, and is always focusing on AI awareness, explainability, and responsibility.","tags":null,"title":"Di Le","type":"authors"},{"authors":"etienne-marcotte","categories":null,"content":"Étienne Marcotte is an Applied Research Scientist in the Human Decision Support of ServiceNow Research. His current research focus is on doing probabilistic forecasts using Neural Networks.\nHe has experience in using Operations Research on a variety of applications. These include optimizing retail operations while at Element AI, power production and distribution while at Engine, and airspace management during a Post-Doc at ULB.\nHe has a Physics PhD from Princeton University, New Jersey, USA. His PhD is in numerical exploration of exotic forms of material, in the classical regime.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"70eace2c972c133933353e95c4b15434","permalink":"https://elementai.github.io/servicenowresearch/fr/author/etienne-marcotte/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/etienne-marcotte/","section":"authors","summary":"Étienne Marcotte is an Applied Research Scientist in the Human Decision Support of ServiceNow Research. His current research focus is on doing probabilistic forecasts using Neural Networks.\nHe has experience in using Operations Research on a variety of applications.","tags":null,"title":"Etienne Marcotte","type":"authors"},{"authors":"gabriel-huang","categories":null,"content":"Hi! My name is Gabriel (Buo-Xuan) Huang and I am doing a PhD in machine learning, at the Montreal Institute for Learning Algorithms. My supervisor is Simon Lacoste-Julien.\nI am interested in generative learning, latent-variable models, structured prediction, optimal transport, weakly-supervised learning, reinforcement learning, convex optimization, music generation, and fundamental questions of optimization and statistical learning.\nPreviously I did the MVA Master’s degree in machine learning at École Normale Supérieure in Paris, in parallel with an engineer’s degree at École Centrale Paris (now CentraleSupélec). While I was doing my master’s, I worked for three years in the industry on computer vision and human activity recognition. Before that, I did classe préparatoire at Lycée Hoche in France.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"7034847b7d7b5087bd457c5e0f532579","permalink":"https://elementai.github.io/servicenowresearch/fr/author/gabriel-huang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/gabriel-huang/","section":"authors","summary":"Hi! My name is Gabriel (Buo-Xuan) Huang and I am doing a PhD in machine learning, at the Montreal Institute for Learning Algorithms. My supervisor is Simon Lacoste-Julien.\nI am interested in generative learning, latent-variable models, structured prediction, optimal transport, weakly-supervised learning, reinforcement learning, convex optimization, music generation, and fundamental questions of optimization and statistical learning.","tags":null,"title":"Gabriel Huang","type":"authors"},{"authors":"hector-palacios","categories":null,"content":"Hector Palacios is a Research Scientist at ServiceNow Research. He works on fundamental and applied research on Artificial Intelligence (AI), on the intersection of reasoning and machine learning (ML). At ServiceNow Research, his research has focused on combining pre-trained ML models and reasoning AI techniques like constraint and planning, focusing on generalization and robustness. In academia, Hector worked on automated planning under incomplete information. He holds a PhD in Computer Science from Universitat Pompeu Fabra, Barcelona/Span, where he was supervised by Hector Geffner. His Ph.D. dissertation received the 2010 Best Dissertation Award by ICAPS and an honourable Mention at the 2009 Artificial Intelligence Dissertation Awards by ECCAI, the European Committee for AI. Later on, he shared the IJCAI-JAIR Best Paper Prize 2012 for an “outstanding paper published in JAIR in the preceding five calendar years”.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"1fd7d547f00a51d87bc4b777c4f5e173","permalink":"https://elementai.github.io/servicenowresearch/fr/author/hector-palacios/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/hector-palacios/","section":"authors","summary":"Hector Palacios is a Research Scientist at ServiceNow Research. He works on fundamental and applied research on Artificial Intelligence (AI), on the intersection of reasoning and machine learning (ML). At ServiceNow Research, his research has focused on combining pre-trained ML models and reasoning AI techniques like constraint and planning, focusing on generalization and robustness.","tags":null,"title":"Hector Palacios","type":"authors"},{"authors":"joao-monteiro","categories":null,"content":"João is a Research Scientist at ServiceNow with interests on devising learning algorithms and models classes that improve out-of-distribution generalization, as well as to define learning procedures that are general purpose in the sense that they can be applied to multiple different tasks. João obtained a PhD from the Institut National de la Recherche Scientifique in Montreal where he focused on applications of generative modeling and metric learning to voice biometrics settings, aiming to improve the state-of-the-art in tasks such as speaker verification and spoken language identification, while also concerned with improving the robustness of such approaches against spoofing attackers.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"28aaf1848f88458b14948f50d1754883","permalink":"https://elementai.github.io/servicenowresearch/fr/author/joao-monteiro/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/joao-monteiro/","section":"authors","summary":"João is a Research Scientist at ServiceNow with interests on devising learning algorithms and models classes that improve out-of-distribution generalization, as well as to define learning procedures that are general purpose in the sense that they can be applied to multiple different tasks.","tags":null,"title":"João Monteiro","type":"authors"},{"authors":"krishna-sanagavarapu","categories":null,"content":"I recently worked as a Research Assistant at Arizona State University. My research interests are Machine Learning, Natural Language Understanding, and Generation. I have 5+ years of professional experience in Analysis, Design, Development, Implementation, and testing of various stand-alone and client-server architecture-based enterprise application software in python.\nMy favorite movie character is Batman and my favourite movie director is Christopher Nolan. I like photography and traveling.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"efaf6fecd78db3c69c2bbde93eed818e","permalink":"https://elementai.github.io/servicenowresearch/fr/author/krishna-sanagavarapu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/krishna-sanagavarapu/","section":"authors","summary":"I recently worked as a Research Assistant at Arizona State University. My research interests are Machine Learning, Natural Language Understanding, and Generation. I have 5+ years of professional experience in Analysis, Design, Development, Implementation, and testing of various stand-alone and client-server architecture-based enterprise application software in python.","tags":null,"title":"Krishna Sanagavarapu","type":"authors"},{"authors":"marie-eve-marchand","categories":null,"content":"Marie-Ève holds a PhD in Art History (Université de Montréal) and conducted research as a FRQSC postdoctoral fellow in the field of decorative arts and design studies. Before joining the ServiceNow Research team, she worked in the academic sector as researcher, affiliate faculty, and staff member. Among other positions, she worked as Facilitator, Student and Academic Affairs in the Fine Arts Dean’s Office at Concordia University and was Scientific Coordinator of the interuniversity research group CIÉ/CO. Marie-Ève has also taught art history and museology as a sessional lecturer and collaborated with various museums and cultural institutions in Québec.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"86ef12df3ac9ac7b45b1bbf65b771d68","permalink":"https://elementai.github.io/servicenowresearch/fr/author/marie-eve-marchand/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/marie-eve-marchand/","section":"authors","summary":"Marie-Ève holds a PhD in Art History (Université de Montréal) and conducted research as a FRQSC postdoctoral fellow in the field of decorative arts and design studies. Before joining the ServiceNow Research team, she worked in the academic sector as researcher, affiliate faculty, and staff member.","tags":null,"title":"Marie-Eve Marchand","type":"authors"},{"authors":"marilyse-turgeon-solis","categories":null,"content":"Marilyse joined ServiceNow and the ATG group in 2022 as the Executive assistant of Nicolas Chapados (VP Research). Prior to joining ServiceNow, she spent 10 years in Vancouver teaching French and French literature at UBC and Quest University. She holds a Master degree in History, and a joint PhD (UBC/Paris-Nanterre) in French literature. Her research focus was on the figure of the nun, and her representation in 18th century French novels, and 18th century French society. In a nutshell, various sources highlight the process by which fiction participates in the construction of a negative social imagination of nuns and convents. Her research sheds a new light on a social imagination that was prevalent in the eighteenth century, and is an original contribution to the study of representation of women in literature. On a personal level, she loves cooking, playing piano, reading, and more than anything, hiking and spending time in the mountains.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"07a713d649832c1cc17aa1477d2c316f","permalink":"https://elementai.github.io/servicenowresearch/fr/author/marilyse-turgeon-solis/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/marilyse-turgeon-solis/","section":"authors","summary":"Marilyse joined ServiceNow and the ATG group in 2022 as the Executive assistant of Nicolas Chapados (VP Research). Prior to joining ServiceNow, she spent 10 years in Vancouver teaching French and French literature at UBC and Quest University.","tags":null,"title":"Marilyse Turgeon-Solis","type":"authors"},{"authors":"masoud-hashemi","categories":null,"content":"Masoud is an Applied Research Scientist in Trust and Governance Lab. During the past four years, he has been focused on developing algorithms and tools to facilitate ML model validation and Responsible AI development. He holds a Ph.D. from the University of Toronto with a “sparse image and signal processing (Compressed Sensing \u0026amp; Dictionary Learning)” background.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"66e3a505b3d801ab416d14aaa1096c19","permalink":"https://elementai.github.io/servicenowresearch/fr/author/masoud-hashemi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/masoud-hashemi/","section":"authors","summary":"Masoud is an Applied Research Scientist in Trust and Governance Lab. During the past four years, he has been focused on developing algorithms and tools to facilitate ML model validation and Responsible AI development.","tags":null,"title":"Masoud Hashemi","type":"authors"},{"authors":"nathan-cooper","categories":null,"content":"Hi there, my name is Nathan Cooper. I am currently a Ph.D. student at the College of William and Mary under the mentorship of Dr. Denys Poshyvanyk. My research interests are at the intersection of Software engineering and Machine Learning. I hope to contribute to educating the world by helping creating the next generation of education tools such as the Khan Academy and the edX platform that democratizes knowledge and education. It is my belief that personalized learning will be the future of education and I hope to contribute to that vision.\nAs a hobby, I work on personal projects which you can find a list of, hopefully mostly complete, ones on my Projects page. Below you will find my resume if you are curious in any of my other experiences or accomplishments. If you have any questions or just want to say hi, feel free to connect via email at nacooper01@email.wm.edu, Twitter @ncooper57, or LinkedIn!\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"69439a1eb8c53f37525a95d385ea74e6","permalink":"https://elementai.github.io/servicenowresearch/fr/author/nathan-cooper/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/nathan-cooper/","section":"authors","summary":"Hi there, my name is Nathan Cooper. I am currently a Ph.D. student at the College of William and Mary under the mentorship of Dr. Denys Poshyvanyk. My research interests are at the intersection of Software engineering and Machine Learning.","tags":null,"title":"Nathan Cooper","type":"authors"},{"authors":"nick-jia","categories":null,"content":"I’m a PhD student in the Cleverhans Lab, at University of Toronto and the Vector Institute, advised by Prof. Nicolas Papernot. During my undergraduate degree, I studied Engineering Science, majoring in Machine Intelligence at the University of Toronto. My undergraduate thesis advisor was also Prof. Papernot. I’m currently interning at ServiceNow in the Advanced Technology Group. I was a recipient of the Vector Scholarship in AI (2020-21).\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"e133f54979fa016b7f75003c9a8c3198","permalink":"https://elementai.github.io/servicenowresearch/fr/author/nick-jia/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/nick-jia/","section":"authors","summary":"I’m a PhD student in the Cleverhans Lab, at University of Toronto and the Vector Institute, advised by Prof. Nicolas Papernot. During my undergraduate degree, I studied Engineering Science, majoring in Machine Intelligence at the University of Toronto.","tags":null,"title":"Nick Jia","type":"authors"},{"authors":"sebastien-paquet","categories":null,"content":"Sébastien Paquet received a Ph.D. in Computer Science from Université de Montréal. He is a research manager at ServiceNow Research, after holding positions as scientific affairs manager and applied research chapter lead. He has longstanding research interests in collaboration technology and culture, knowledge sharing, the evolution of scientific practice and scholarly publishing, and the use of AI and collaborative technology to augment human’s ability to think individually and collectively. Prior to joining ServiceNow, he worked in scientific research and teaching (research officer at National Research Council Canada, professor at Université du Québec à Montréal, Society for Arts and Technology) and was involved in several technology startups.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"df5823dc771a5a89f88bb46d331e3087","permalink":"https://elementai.github.io/servicenowresearch/fr/author/sebastien-paquet/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/sebastien-paquet/","section":"authors","summary":"Sébastien Paquet received a Ph.D. in Computer Science from Université de Montréal. He is a research manager at ServiceNow Research, after holding positions as scientific affairs manager and applied research chapter lead.","tags":null,"title":"Sébastien Paquet","type":"authors"},{"authors":"stefania-raimondo","categories":null,"content":"Stefania is an Applied Research Scientist in the Emerging Technologies Lab, with expertise in machine learning and Natural Language Processing.\nShe holds a Masters degree from the University of Toronto in Computer Science and Computational Linguistics. Her prior research focused on assistive language technologies, conversational robots, miscommunication, and language changes associated with dementia and aphasia.\nAt ElementAI, she worked on entity extraction, summarization, and language modelling for core products. She has experience in client-facing roles, engaging with scoping in pre-sales, delivering on and leading consulting projects.\nHer current work focuses on bias in NLP and integrating robustness into NLP systems, with a special focus on dialogue. In the Emerging Technologies Lab she helps bridge the gap between fundamental research and productization.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"c8a49de6fa1de5b64ae6ae5b9ae61f42","permalink":"https://elementai.github.io/servicenowresearch/fr/author/stefania-raimondo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/stefania-raimondo/","section":"authors","summary":"Stefania is an Applied Research Scientist in the Emerging Technologies Lab, with expertise in machine learning and Natural Language Processing.\nShe holds a Masters degree from the University of Toronto in Computer Science and Computational Linguistics.","tags":null,"title":"Stefania Raimondo","type":"authors"},{"authors":"stefano-ermon","categories":null,"content":"I am an Associate Professor in the Department of Computer Science at Stanford University, where I am affiliated with the Artificial Intelligence Laboratory and a fellow of the Woods Institute for the Environment.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"15469066c8dc473dfa7a04f08f8f91d4","permalink":"https://elementai.github.io/servicenowresearch/fr/author/stefano-ermon/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/stefano-ermon/","section":"authors","summary":"I am an Associate Professor in the Department of Computer Science at Stanford University, where I am affiliated with the Artificial Intelligence Laboratory and a fellow of the Woods Institute for the Environment.","tags":null,"title":"Stefano Ermon","type":"authors"},{"authors":"tianyi-chen","categories":null,"content":"Tianyi is an Applied Research Scientist in the Emerging Technologies Lab. She has a background in Computer Science and Natural Language Processing. At ServiceNow Research, her research has focused on using Bayesian methods to estimate uncertainty in structured sequence generation with large language models (LLMs). On the applied side, she works on data augmentation and uses LLMs to disambiguate user input for a Product team. Her current research interest is in LLMs, uncertainty and text2code. Tianyi holds a master’s degree in Computer Science and AI. Prior to joining ServiceNow, she was at Element AI working on various text embedding/signal extraction tasks using language models. Tianyi also has experience in AI consultancy on AI adoption for non-tech clients.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"942b6e201f1929dd2425042be6bc06b6","permalink":"https://elementai.github.io/servicenowresearch/fr/author/tianyi-chen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/tianyi-chen/","section":"authors","summary":"Tianyi is an Applied Research Scientist in the Emerging Technologies Lab. She has a background in Computer Science and Natural Language Processing. At ServiceNow Research, her research has focused on using Bayesian methods to estimate uncertainty in structured sequence generation with large language models (LLMs).","tags":null,"title":"Tianyi Chen","type":"authors"},{"authors":"valerie-becaert","categories":null,"content":"Valérie is the Sr Director of Research at ServiceNow Research. She oversees the AI Research team since 2017, building the team from the initial group of 5 researchers at the Montreal Startup ElementAI to the scientific innovation machine that is now ServiceNow Research. She holds a PhD from Polytechnique Montreal in Chemical Engineering and has broad experience across academic research and tech transfer including previous roles such as:\nExecutive director of CIRAIG, a research center in Life Cycle Assessment, bringing the latest development in the LCA field to industry.\nDirector and co-founder of CIRODD, a research center in sustainable development, bridging engineering, design and social science to operationalize sustainability in various industries.\nExecutive director of IVADO an organization bringing together industry professionals and academic researchers to develop cutting-edge expertise in data science, operational research and artificial intelligence.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"9a020e6b3c25b252039d4cecee2482c9","permalink":"https://elementai.github.io/servicenowresearch/fr/author/valerie-becaert/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/valerie-becaert/","section":"authors","summary":"Valérie is the Sr Director of Research at ServiceNow Research. She oversees the AI Research team since 2017, building the team from the initial group of 5 researchers at the Montreal Startup ElementAI to the scientific innovation machine that is now ServiceNow Research.","tags":null,"title":"Valérie Bécaert","type":"authors"},{"authors":"xiaotian-liu","categories":null,"content":"Xiaotian Liu is MSc student studying computer science at Queen’s University, supervised by Dr. Christian Muise. His research interests are Machine Learning, Reinforcement Learning, Automated Planning, Neural Symbolic AI, Partially Observable Planning/RL, Embodied Agent Design etc. His current work involves building a neural symbolic agent that uses Planning as a high-level system to guide low-level tasks learned through deep learning. Xiaotian also has experience in image segmentation, information extraction in NLP and source code translation. Currently, Xiaotian is visiting researcher supervised by Dr. Hector Palacios at ServiceNow Research.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"23081e9d28e9c1ed9949a0eb20ba4a94","permalink":"https://elementai.github.io/servicenowresearch/fr/author/xiaotian-liu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/xiaotian-liu/","section":"authors","summary":"Xiaotian Liu is MSc student studying computer science at Queen’s University, supervised by Dr. Christian Muise. His research interests are Machine Learning, Reinforcement Learning, Automated Planning, Neural Symbolic AI, Partially Observable Planning/RL, Embodied Agent Design etc.","tags":null,"title":"Xiaotian Liu","type":"authors"},{"authors":"xing-han-lu","categories":null,"content":"I am a graduate student at McGill University and Mila, where I work on NLP research under the supervision of Dr. Siva Reddy. Previously, I was at Plotly, where I lead various ML initiatives, developed open-source libraries, and contributed to Dash core components. Before that, I spent a summer as a data science intern at Deloitte working on summarization engines, and another at the McGill Clinical and Health Informatics lab as a research assistant in ML for Taxation Modelling. I also share notebooks on Kaggle, where I am a Kernels Grandmaster.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"1bca7578b9ff720996ce5f655f39b8e6","permalink":"https://elementai.github.io/servicenowresearch/fr/author/xing-han-lu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/xing-han-lu/","section":"authors","summary":"I am a graduate student at McGill University and Mila, where I work on NLP research under the supervision of Dr. Siva Reddy. Previously, I was at Plotly, where I lead various ML initiatives, developed open-source libraries, and contributed to Dash core components.","tags":null,"title":"Xing Han Lu","type":"authors"},{"authors":"yanick-chenard","categories":null,"content":"Yanick is a developper with a broad background in computer vision, game engines, applied ML, backend, desktop, mobile and web applications.\nHolding a B. Ing. in CS from École Polytechnique Montréal, he enjoys working with applied and research scientists to bring their research to life.\nPreviously at ElementAI, he worked on various consultancy projects with the Applied research lab, providing programming support and supervision.\nHe fosters a rapid prototyping mindset so teams can quickly test the feasibility of ideas and de-risk difficult technical and scientific aspects of projects. With a full-stack toolkit, he can help from project inception to delivery.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"fr","lastmod":-62135596800,"objectID":"cb314bcf0716e9789ea09ff4abd7c37e","permalink":"https://elementai.github.io/servicenowresearch/fr/author/yanick-chenard/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/author/yanick-chenard/","section":"authors","summary":"Yanick is a developper with a broad background in computer vision, game engines, applied ML, backend, desktop, mobile and web applications.\nHolding a B. Ing. in CS from École Polytechnique Montréal, he enjoys working with applied and research scientists to bring their research to life.","tags":null,"title":"Yanick Chénard","type":"authors"},{"authors":[],"categories":null,"content":"Slides can be added in a few ways:\n Create slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://elementai.github.io/servicenowresearch/fr/event/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/event/example/","section":"event","summary":"An example event.","tags":[],"title":"Example Event","type":"event"},{"authors":["David Berger","Alexandre Drouin","Alexandre Lacoste","Laurent Charlin"],"categories":null,"content":"’ \u0026#39;\n","date":1654214400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1654214400,"objectID":"8cce059d4537a6224206c58e922a4aaf","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/davidbergerdecossc2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/davidbergerdecossc2022/","section":"publication","summary":"Counterfactual prediction under sequences of actions is a fundamental problem in decision-making. Existing methods in causal inference suppose that there are no unobserved confounders, a strong assumption that cannot be tested in practice and which can lead to biased counterfactual conclusions. We present the Dynamic Deconfounder, a method based on the work of Wang and Blei (2018)that takes advantage of sequences of actions in order to estimate substitute confounders. Such substitutes are derived from a factor model estimated using a variational auto-encoder. We present extensive theoretical results establishing the validity of such substitutes and show that they can be used to predict unbiased counterfactual outcomes under sequences of actions. In doing so, we characterize graph structures under which it is either possible or provably impossible to use factor models to estimate substitute confounders in dynamic treatment regimes. Finally, we support our theoretical results with extensive simulations.","tags":["Causality","Time Series"],"title":"Deconfounding Dynamic Treatment Regimes","type":"publication"},{"authors":["Roger Girgis","Florian Golemo","Felipe Codevilla","Martin Weiss","Jim Aldon D'Souza","Samira Ebrahimi Kahou","Felix Heide","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1650844800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1650844800,"objectID":"c19dd49bb9f6281373f4d1df6304ede0","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/rogergirgislateiclr2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/rogergirgislateiclr2022/","section":"publication","summary":"Robust multi-agent trajectory prediction is essential for the safe control of robotic systems. A major challenge is to efficiently learn a representation that approximates the true joint distribution of contextual, social, and temporal information to enable planning. We propose Latent Variable Sequential Set Transformers which are encoder-decoder architectures that generate scene-consistent multi-agent trajectories. We refer to these architectures as \"AutoBots\". The encoder is a stack of interleaved temporal and social multi-head self-attention (MHSA) modules which alternately perform equivariant processing across the temporal and social dimensions. The decoder employs learnable seed parameters in combination with temporal and social MHSA modules allowing it to perform inference over the entire future scene in a single forward pass efficiently. AutoBots can produce either the trajectory of one ego-agent or a distribution over the future trajectories for all agents in the scene. For the single-agent prediction case, our model achieves top results on the global nuScenes vehicle motion prediction leaderboard, and produces strong results on the Argoverse vehicle prediction challenge. In the multi-agent setting, we evaluate on the synthetic partition of TrajNet++ dataset to showcase the model's socially-consistent predictions. We also demonstrate our model on general sequences of sets and provide illustrative experiments modelling the sequential structure of the multiple strokes that make up symbols in the Omniglot data. A distinguishing feature of AutoBots is that all models are trainable on a single desktop GPU (1080 Ti) in under 48h.","tags":["Robotics","Transformers"],"title":"Latent Variable Sequential Set Transformers for Joint Multi-Agent Motion Prediction","type":"publication"},{"authors":["Paul Barde","Tristan Karch","Derek Nowrouzezahrai","Clément Moulin-Frier","Christopher Pal","Pierre-Yves Oudeyer"],"categories":null,"content":"’ \u0026#39;\n","date":1650844800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1650844800,"objectID":"51522a18a55416f5bf7aeace85904f69","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/paulbardeleariclr2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/paulbardeleariclr2022/","section":"publication","summary":"We are interested in interactive agents that learn to coordinate, namely, a \nbuilder -- which performs actions but ignores the goal of the task, i.e. has no access to rewards -- and an  architect which guides the builder towards the goal of the task. \nWe define and explore a formal setting where artificial agents are equipped with mechanisms that allow them to simultaneously learn a task while at the same time evolving a shared communication protocol.  \nIdeally, such learning should only rely on high-level communication priors and be able to handle a large variety of tasks and meanings while deriving communication protocols that can be reused across tasks.\nThe field of Experimental Semiotics has shown the extent of human proficiency at learning from a priori unknown instructions meanings. Therefore, we take inspiration from it and present the Architect-Builder Problem (ABP): an asymmetrical setting in which an architect must learn to guide a builder towards constructing a specific structure. The architect knows the target structure but cannot act in the environment and can only send arbitrary messages to the builder. The builder on the other hand can act in the environment, but receives no rewards nor has any knowledge about the task, and must learn to solve it relying only on the messages sent by the architect. Crucially, the meaning of messages is initially not defined nor shared between the agents but must be negotiated throughout learning.\nUnder these constraints, we propose Architect-Builder Iterated Guiding (ABIG), a solution to the Architect-Builder Problem where the architect leverages a learned model of the builder to guide it while the builder uses self-imitation learning to reinforce its guided behavior. To palliate to the non-stationarity induced by the two agents concurrently learning, ABIG structures the sequence of interactions between the agents into interaction frames. We analyze the key learning mechanisms of ABIG and test it in a 2-dimensional instantiation of the ABP where tasks involve grasping cubes, placing them at a given location, or building various shapes. In this environment, ABIG results in a low-level, high-frequency, guiding communication protocol that not only enables an architect-builder pair to solve the task at hand, but that can also generalize to unseen tasks. ","tags":null,"title":"Learning to Guide and to Be Guided in the Architect-Builder Problem","type":"publication"},{"authors":null,"categories":null,"content":"‘The 60th annual meeting of the Association for Computational Linguistics, ACL 2022, will take place in Dublin, Ireland, from May 22-27, 2022. ACL is the premier international scientific and professional society for people working on computational problems involving human language, a field often referred to as either computational linguistics or natural language processing (NLP).\nAt ServiceNow Research, the Human Machine Interaction Through Language team (HMITL) works on advancing AI technology to solve language-related questions. We are excited to announce that, in collaboration with other experts in the field, many HMITL researchers will present their work during the ACL 2022 conference.\nPapers accepted to the main conference:\n  Compositional Generalization in Dependency Parsing (Emily Goodwin, Siva Reddy, Timothy J. O’Donnell, Dzmitry Bahdanau) (PDF)\n  LAGr: Labeling Aligned Graphs for Improving Systematic Generalization in Semantic Parsing (Dora Jambor, Dzmitry Bahdanau) (PDF)\n  The Power of Prompt Tuning for Low-Resource Semantic Parsing (Nathan Schucher, Siva Reddy, Harm de Vries) (PDF)\n  TopiOCQA: Open-domain Conversational Question Answering with Topic Switching (Vaibhav Adlakha, Shehzaad Dhuliawala, Kaheer Suleman, Harm de Vries, Siva Reddy) (PDF)\n  We are excited to announce that this paper will also be published in Transactions of the Association for Computational Linguistics, an ACL-sponsored journal published by MIT Press!\n  The following paper will be presented at the 4th Workshop on NLP for Conversational AI:\n Data Augmentation for Intent Classification with Off-the-shelf Large Language Models (Gaurav Sahu, Pau Rodriguez, Parmida Atighhehchian, Issam H. Laradji, David Vazquez, Dzmitry Bahdanau) (PDF)  In addition to the main conference that will be held from May 23-25, ACL will host an exciting line-up of tutorials (May 22) as well as workshops and co-located events (May 26-27). We would like to thank the ACL 2022 organizing committee, including all Senior Area Chairs, Chairs, and partners for hosting this conference.\nCongratulations to all the researchers whose papers have been accepted. We wish you all the best at the conference!\nJoin ServiceNow Research to help advance the state-of-the-art in Enterprise AI\nIf you’re a researcher interested in learning about research internships, and full-time or part-time career opportunities with ServiceNow Research, please fill out this form.\n\u0026#39;\n","date":1650499200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1650499200,"objectID":"df6903f529870d4f0e77b4b0afdd006e","permalink":"https://elementai.github.io/servicenowresearch/fr/post/2022-04-21servicen/","publishdate":"2022-04-21T00:00:00Z","relpermalink":"/servicenowresearch/fr/post/2022-04-21servicen/","section":"post","summary":"We are delighted to share details of our papers accepted at ACL 2022, the 60th Annual Meeting of the Association for Computational Linguistics. We hope to see you at the conference. Please get in touch if you would like to explore full-time or part-time research opportunities at ServiceNow.","tags":null,"title":"ServiceNow Research spotlight: Papers accepted at ACL 2022","type":"post"},{"authors":["Sébastien Lachapelle","Pau Rodriguez","Yash Sharma","Katie Everett ","Rémi Le Priol","Alexandre Lacoste","Simon Lacoste-Julien"],"categories":null,"content":"’ \u0026#39;\n","date":1649635200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1649635200,"objectID":"8e0a563da5edce2bb0903f4821d13c77","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/sebastienlachapellediseclear2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/sebastienlachapellediseclear2022/","section":"publication","summary":"This work introduces a novel principle we call disentanglement via mechanism sparsity regularization, which can be applied when the latent factors of interest depend sparsely on past latent factors and/or observed auxiliary variables. We propose a representation learning method that induces disentanglement by simultaneously learning the latent factors and the sparse causal graphical model that relates them. We develop a rigorous identifiability theory, building on recent nonlinear independent component analysis (ICA) results, that formalizes this principle and shows how the latent variables can be recovered up to permutation if one regularizes the latent mechanisms to be sparse and if some graph connectivity criterion is satisfied by the data generating process. As a special case of our framework, we show how one can leverage unknown-target interventions on the latent factors to disentangle them, thereby drawing further connections between ICA and causality. We propose a VAE-based method in which the latent mechanisms are learned and regularized via binary masks, and validate our theory by showing it learns disentangled representations in simulations.","tags":["Representation Learning","Identifiability","Sparsity"],"title":"Disentanglement via Mechanism Sparsity Regularization: A New Principle for Nonlinear ICA","type":"publication"},{"authors":["Rim Assouel","Lluis Castrejon","Aaron Courville","Nicolas Ballas","Yoshua Bengio"],"categories":null,"content":"’ \u0026#39;\n","date":1649635200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1649635200,"objectID":"d40edec8b8b41aa1d3fc1e7c574a9bd8","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/rimassouelvimclear2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/rimassouelvimclear2022/","section":"publication","summary":"We introduce a variational inference model called VIM, for Variational Independent Modules, for sequential data that learns and infers latent representations as a set of objects and discovers modular causal mechanisms over these objects. These mechanisms - which we call modules - are independently parametrized, define the stochastic transitions of entities and are shared across entities.  At each time step, our model infers from a low-level input sequence a high-level sequence of categorical latent variables to select which transition modules to apply to which high-level object. We evaluate this model in video prediction tasks where the goal is to predict multi-modal future events given previous observations. We demonstrate empirically that VIM can model 2D visual sequences in an interpretable way and is able to identify the underlying dynamically instantiated mechanisms of the generation process.  We additionally show that the learnt modules can be composed at test time to generalize to out-of-distribution observations.","tags":["Video Prediction","Variational Learning"],"title":"VIM: Variational Independent Modules for Video Prediction","type":"publication"},{"authors":["Issam H. Laradji"],"categories":null,"content":"’ \u0026#39;\n","date":1648339200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1648339200,"objectID":"c79d415b22ee965e27a9b5b01b1525a2","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/issamh.laradjiasofar2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/issamh.laradjiasofar2022/","section":"publication","summary":"Hard data labels for automated algorithm training are binary and\ncannot incorporate uncertainty between labels. We proposed and evaluated a soft labeling\nmethodology to quantify opacification and percent well-aerated lung (%WAL) on chest CT, that\nconsiders uncertainty in segmenting pulmonary opacifications and reduces labeling burden.","tags":["Computer Vision","Weak Supervision","Semantic Segmentation"],"title":"A Soft Labeling Approach to Develop Automated Algorithms that Incorporate Uncertainty in Pulmonary Opacification on Chest CT using COVID-19 Pneumonia","type":"publication"},{"authors":null,"categories":null,"content":"‘The 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)will take place from June 19-24, 2022 in New Orleans, Louisiana. The Conference is planned to be held in person, with an online option offered to those who cannot travel. First held in 1985, CVPR has become the premier annual computer vision event for the brightest minds in the field, attracting participation and collaboration across industry and academia. We are excited to announce that, in partnership with external collaborators, researchers from the ServiceNow Research Low-Data Learning program team will present their papers at the main conference. Low Data Learning studies Machine Learning methods that enable adapting efficiently to varied and changing datasets. ServiceNow Research focuses on a wide range of downstream tasks such as language understanding, computer vision, robotic automation, and learning workflows.\nPapers accepted to the main conference:\n  Multi-label Iterated Learning for Image Classification with Label Ambiguity (Sai Rajeswar, Pau Rodriguez, Soumye Singhal, David Vazquez, Aaron Courville) [PDF]\n  Kubric: A scalable dataset generator (Klaus Greff, Francois Belletti, Lucas Beyer, Carl Doersch, Yilun Du, Daniel Duckworth, David J. Fleet, Dan Gnanapragasam, Florian Golemo, Charles Herrmann, Thomas Kipf, Abhijit Kundu, Dmitry Lagun, Issam Laradji, Hsueh-Ti (Derek)Liu, Henning Meyer, Yishu Miao, Derek Nowrouzezahrai, Cengiz Oztireli, Etienne Pot, Noha Radwan, Daniel Rebain, Sara Sabour, Mehdi S. M. Sajjadi, Matan Sela, Vincent Sitzmann, Austin Stone, Deqing Sun, Suhani Vora, Ziyu Wang, Tianhao Wu, Kwang Moo Yi, Fangcheng Zhong, Andrea Tagliasacchi) [PDF]\n  Neural Point Light Fields (Julian Ost, Issam Laradji, Alejandro Newell, Yuval Bahat, Felix Heide) [PDF]\n  In addition to the main conference, CVPR will host an exciting line-up of workshops (June 19-20), short courses, as well as an exhibition (June 21-23). Learn more at the CVPR 2022 conference website. We are delighted to be supporting the following workshops that members of the ServiceNow Research team are co-hosting:\n  Workshop on Continual Learning in Computer Vision (David Vazquez, Pau Rodriguez, and external collaborators) [More information]\n  Workshop on Learning from Limited Labelled Data for Image and Video Understanding (David Vazquez, Issam H. Laradji, Pau Rodriguez, and external collaborators) [More information]   We would like to thank the CVPR 2022 organizing committee, including all Chairs and partners for hosting this conference.\nCongratulations to all the researchers whose papers and workshops have been accepted. We wish you all the best at the conference!\nJoin ServiceNow Research to help advance the state-of-the-art in Enterprise AI If you’’re a researcher interested in learning about full-time and part-time career opportunities with ServiceNow Research, please fill out this form.\n\u0026#39;\n","date":1647216000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1647216000,"objectID":"76dac2f7836092ab1158ce5a2a5cb9fc","permalink":"https://elementai.github.io/servicenowresearch/fr/post/2022-03-14servicen/","publishdate":"2022-03-14T00:00:00Z","relpermalink":"/servicenowresearch/fr/post/2022-03-14servicen/","section":"post","summary":"The 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) will take place from June 19-24, 2022 in New Orleans, Louisiana. We are excited to announce that, in partnership with external collaborators, researchers from the ServiceNow Research Low-Data Learning program team will present their papers at the main conference. Learn more about the papers in this article.","tags":null,"title":"ServiceNow Research spotlight: Papers accepted at the 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","type":"post"},{"authors":["Rim Assouel","Perouz Taslakian","David Vazquez","Pau Rodriguez","Yoshua Bengio"],"categories":null,"content":"’ \u0026#39;\n","date":1646092800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1646092800,"objectID":"6e9b8f8cc4824e0536cd4de7dc542059","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/rimassouelobjeiclrworkshops2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/rimassouelobjeiclrworkshops2022/","section":"publication","summary":"Like humans devoid of imagination, current machine learning systems lack the ability to adapt to new, unexpected situations by foreseeing them, which makes them unable to solve new tasks by analogical reasoning. In this work, we introduce a new compositional imagination framework that improves a model's ability to generalize out-of-distribution. One of the key components of our framework is object-centric inductive biases that enables models to perceive the environment as a series of objects, properties, and transformations. By composing these key ingredients, it is possible to generate new unseen tasks that, when used to train the model, improve systematic generalization. Experiments on a simplified version of the \\emph{Abstraction and Reasoning Corpus (ARC)} demonstrate the effectiveness of our framework.","tags":["Compositional Generalization","Computer Vision"],"title":"Object-centric Compositional Imagination for Visual Abstract Reasoning","type":"publication"},{"authors":["Fabio Casati","Pierre-André Noël","Jie Yang"],"categories":null,"content":"’ \u0026#39;\n","date":1639440000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1639440000,"objectID":"a65b51949fdd3da2f01d6002a271c40d","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/fabiocasationthneuripsworkshops2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/fabiocasationthneuripsworkshops2021/","section":"publication","summary":"We argue that, when establishing and benchmarking Machine Learning (ML) models, the research community should favour evaluation metrics that better capture the value delivered by their model in practical applications. For a specific class of use cases -- selective classification -- we show that not only can it be simple enough to do, but that it has import consequences and provides insights what to look for in a ``good'' ML model.","tags":null,"title":"On the Value of ML Models","type":"publication"},{"authors":["Lee Zamparo","Marc-Etienne Brunet ","Thomas George","Sepideh Kharaghani","Gintare Karolina Dziugaite"],"categories":null,"content":"’ \u0026#39;\n","date":1639440000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1639440000,"objectID":"9ab61f469e53e90c44517f9164cff900","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/leezamparothedneurips2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/leezamparothedneurips2021/","section":"publication","summary":"Deep ensembles offer consistent performance gains, both in terms of reduced generalization error and improved predictive uncertainty estimates. These performance gains are attributed to functional diversity among the components that make up the ensembles: ensemble performance increases with the diversity of the components. A standard way to generate a diversity of components from a single data set is to train multiple networks on the same data, but different minibatch orders (and augmentations, etc.). In this work, we study when and how this type of diversity decreases during deep neural network training. Using couplings of multiple training runs, we find that diversity rapidly decreases at the start of training, and that increased training time does not restore this lost diversity, implying that early stages of training make irreversible commitments. In particular, our findings provide further evidence that there is less diversity among functions once linear mode connectivity sets in. This motivates studying perturbations to training that upset linear mode connectivity. We then study how functional diversity is affected by retraining after reinitializing the weights in some layers. We find that we recover significantly more diversity by reinitializing layers closer to the input layer, compared to reinitializing layers closer to the output, also restoring the error barrier.","tags":["Diversity"],"title":"The Dynamics of Functional Diversity throughout Neural Network Training","type":"publication"},{"authors":["Torsten Scholak","Jonathan Pilault","Joey Velez-Ginorio"],"categories":null,"content":"’ \u0026#39;\n","date":1639440000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1639440000,"objectID":"18e19928d476b4a8c5582c26071b4ab8","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/torstenscholaktowaneurips2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/torstenscholaktowaneurips2021/","section":"publication","summary":"This paper explores the capabilities of current transformer-based language models for program evaluation of simple functional programming languages. We introduce a new program generation mechanism that allows control over syntactic sugar for semantically equivalent programs. T5 experiments reveal that neural functional program evaluation performs surprisingly well, achieving high 90% exact program match scores for most in-distribution and out-of-distribution tests. Using pretrained T5 weights has significant advantages over random initialization. We present and evaluate on three datasets to study generalization abilities that are specific to functional programs based on: type, function composition, and reduction steps. Code and data are publicly available at this https URL.","tags":null,"title":"Towards Neural Functional Program Evaluation","type":"publication"},{"authors":["Philippe Brouillard","Perouz Taslakian","Alexandre Lacoste","Sébastien Lachapelle","Alexandre Drouin"],"categories":null,"content":"’ \u0026#39;\n","date":1639267200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1639267200,"objectID":"4719c30d8b0f9a573f05949cd5127d73","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/philippebrouillardtypineurips2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/philippebrouillardtypineurips2021/","section":"publication","summary":"Causal discovery from observational data is a challenging task that can only be solved up to a set of equivalent solutions, called an equivalence class. Such classes, which are often large in size, encode uncertainties about the orientation of some edges in the causal graph. In this work, we propose a new set of assumptions that constrain possible causal relationships based on the nature of variables, thus circumscribing the equivalence class. Namely, we introduce typed directed acyclic graphs, in which variable types are used to determine the validity of causal relationships. We demonstrate, both theoretically and empirically, that the proposed assumptions can result in significant gains in the identification of the causal graph. We also propose causal discovery algorithms that make use of these assumptions and demonstrate their benefits on simulated and pseudo-real data.","tags":["Causality","Causal Discovery"],"title":"Typing assumptions improve identification in causal discovery - Report and comments on future directions","type":"publication"},{"authors":["Sébastien Lachapelle","Pau Rodriguez","Yash Sharma","Katie Everett ","Rémi Le Priol","Alexandre Lacoste","Simon Lacoste-Julien"],"categories":null,"content":"’ \u0026#39;\n","date":1639180800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1639180800,"objectID":"a31a6a676ff61974bd646309c35bf005","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/sebastienlachapellediseneurips2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/sebastienlachapellediseneurips2021/","section":"publication","summary":"This work introduces a novel principle we call disentanglement via mechanism sparsity regularization, which can be applied when the latent factors of interest depend sparsely on past latent factors and/or observed auxiliary variables. We propose a representation learning method that induces disentanglement by simultaneously learning the latent factors and the sparse causal graphical model that relates them. We develop a rigorous identifiability theory, building on recent nonlinear independent component analysis (ICA) results, that formalizes this principle and shows how the latent variables can be recovered up to permutation if one regularizes the latent mechanisms to be sparse and if some graph connectivity criterion is satisfied by the data generating process. As a special case of our framework, we show how one can leverage unknown-target interventions on the latent factors to disentangle them, thereby drawing further connections between ICA and causality. We propose a VAE-based method in which the latent mechanisms are learned and regularized via binary masks, and validate our theory by showing it learns disentangled representations in simulations.","tags":["Disentanglement"],"title":"Disentanglement via Mechanism Sparsity Regularization: A New Principle for Nonlinear ICA","type":"publication"},{"authors":["Alexandre Lacoste","Evan David Sherwin","Hannah Kerner","Hamed Alemohammad","Björn Lütjens","Jeremy Irvin","David Dao","Alex Chang","Mehmet Gunturkun","Alexandre Drouin","Pau Rodriguez","David Vazquez"],"categories":null,"content":"’ \u0026#39;\n","date":1639180800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1639180800,"objectID":"3319d6a3f29436b38bde2f1f4f86884f","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/alexandrelacostetowaneuripsworkshops2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/alexandrelacostetowaneuripsworkshops2021/","section":"publication","summary":"Recent progress in self-supervision shows that pre-training large neural networks on vast amounts of unsupervised data can lead to impressive increases in generalisation for downstream tasks. Such models, recently coined as foundation models, have been transformational to the field of natural language processing. While similar models have also been trained on large corpuses of images, they are not well suited for remote sensing data. To stimulate the development of foundation models for Earth monitoring, we propose to develop a new benchmark comprised of a variety of downstream tasks related to climate change. We believe that this can lead to substantial improvements in many existing applications and facilitate the development of new applications. This proposal is also a call for collaboration with the aim of developing a better evaluation process to mitigate potential downsides of foundation models for Earth monitoring.","tags":["Computer Vision","Climate Change","Remote Sensing"],"title":"Toward Foundation Models for Earth Monitoring: Proposal for a Climate Change Benchmark","type":"publication"},{"authors":["David Rolnick","Priya L. Donti","Lynn H. Kaack","Kelly Kochanski","Alexandre Lacoste","Kris Sankaran","Andrew Slavin Ross","Nikola Milojevic-Dupont","Natasha Jaques","Anna Waldman-Brown","Alexandra Luccioni","Tegan Maharaj","Evan D. Sherwin","S. Karthik Mukkavilli","Konrad P. Kording","Carla Gomes","Andrew Y. Ng","Demis Hassabis","John C. Platt","Felix Creutzig","Jennifer Chayes","Yoshua Bengio"],"categories":null,"content":"’ \u0026#39;\n","date":1639094400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1639094400,"objectID":"4ccc222a95645085506c5da7102b585b","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/davidrolnicktackacmcs2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/davidrolnicktackacmcs2022/","section":"publication","summary":"Climate change is one of the greatest challenges facing humanity, and we, as machine learning experts, may wonder how we can help. Here we describe how machine learning can be a powerful tool in reducing greenhouse gas emissions and helping society adapt to a changing climate. From smart grids to disaster management, we identify high impact problems where existing gaps can be filled by machine learning, in collaboration with other fields. Our recommendations encompass exciting research questions as well as promising business opportunities. We call on the machine learning community to join the global effort against climate change.","tags":["Climate Change"],"title":"Tackling Climate Change with Machine Learning","type":"publication"},{"authors":["Oleksiy Ostapenko","Pau Rodriguez","Massimo Caccia","Laurent Charlin"],"categories":null,"content":"’ \u0026#39;\n","date":1638748800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1638748800,"objectID":"29d0f84eaa906e55f25c714c3578f6bf","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/oleksiyostapenkocontneurips2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/oleksiyostapenkocontneurips2021/","section":"publication","summary":"Modularity is a compelling solution to continual learning (CL), the problem of modeling sequences of related tasks. Learning and then composing modules to solve different tasks provides an abstraction to address the principal challenges of CL including catastrophic forgetting, backward and forward transfer across tasks, and sub-linear model growth. We introduce local module composition (LMC), an approach to modular CL where each module is provided a local structural component that estimates a module's relevance to the input. Dynamic module composition is performed layer-wise based on local relevance scores. We demonstrate that agnosticity to task identities (IDs) arises from (local) structural learning that is module-specific as opposed to the task- and/or model-specific as in previous works, making LMC applicable to more CL settings compared to previous works. In addition, LMC also tracks statistics about the input distribution and adds new modules when outlier samples are detected. In the first set of experiments, LMC performs favorably compared to existing methods on the recent Continual Transfer-learning Benchmark without requiring task identities. In another study, we show that the locality of structural learning allows LMC to interpolate to related but unseen tasks (OOD), as well as to compose modular networks trained independently on different task sequences into a third modular network without any fine-tuning. Finally, in search for limitations of LMC we study it on more challenging sequences of 30 and 100 tasks, demonstrating that local module selection becomes much more challenging in presence of a large number of candidate modules. In this setting best performing LMC spawns much fewer modules compared to an oracle based baseline, however, it reaches a lower overall accuracy. The codebase is available under this https URL.","tags":["Continual Learning","Compositional Generalization"],"title":"Continual Learning via Local Module Composition","type":"publication"},{"authors":["Klaus Greff","Francois Belletti","Lucas Beyer","Carl Doersch","Yilun Du","Daniel Duckworth","David J. Fleet","Dan Gnanapragasam","Florian Golemo","Charles Herrmann","Thomas Kipf","Abhijit Kundu","Dmitry Lagun","Issam H. Laradji","Hsueh-Ti (Derek)Liu","Henning Meyer","Yishu Miao","Derek Nowrouzezahrai","Cengiz Oztireli","Etienne Pot","Noha Radwan","Daniel Rebain","Sara Sabour","Mehdi S. M. Sajjadi","Matan Sela","Vincent Sitzmann","Austin Stone","Deqing Sun","Suhani Vora","Ziyu Wang","Tianhao Wu","Kwang Moo Yi","Fangcheng Zhong","Andrea Tagliasacchi"],"categories":null,"content":"’ \u0026#39;\n","date":1637625600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1637625600,"objectID":"3a6fc4485843816f11ce1f4b2375eea2","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/klausgreffkubrcvpr2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/klausgreffkubrcvpr2022/","section":"publication","summary":"Data is the driving force of machine learning, with the amount and quality of training data often being more important for the performance of a system than architecture and training details. But collecting, processing and annotating real data at scale is difficult, expensive, and frequently raises additional privacy, fairness and legal concerns. Synthetic data is a powerful tool with the potential to address these shortcomings: 1) it is cheap 2) supports rich ground-truth annotations 3) offers full control over data and 4) can circumvent or mitigate problems regarding bias, privacy and licensing. Unfortunately, software tools for effective data generation are less mature than those for architecture design and training, which leads to fragmented generation efforts. To address these problems we introduce Kubric, an open-source Python framework that interfaces with PyBullet and Blender to generate photo-realistic scenes, with rich annotations, and seamlessly scales to large jobs distributed over thousands of machines, and generating TBs of data. We demonstrate the effectiveness of Kubric by presenting a series of 13 different generated datasets for tasks ranging from studying 3D NeRF models to optical flow estimation. We release Kubric, the used assets, all of the generation code, as well as the rendered datasets for reuse and modification.","tags":["Dataset","Synthetic Data","3D"],"title":"Kubric: A scalable dataset generator","type":"publication"},{"authors":["Julian Ost","Issam H. Laradji","Alejandro Newell","Yuval Bahat","Felix Heide"],"categories":null,"content":"’ \u0026#39;\n","date":1637625600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1637625600,"objectID":"717e9a36f53f0e23b30fba764d5a497f","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/julianostneurcvpr2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/julianostneurcvpr2022/","section":"publication","summary":"We introduce Neural Point Light Fields that represent scenes implicitly with a light field living on a sparse point cloud. Combining differentiable volume rendering with learned implicit density representations has made it possible to synthesize photo-realistic images for novel views of small scenes. As neural volumetric rendering methods require dense sampling of the underlying functional scene representation, at hundreds of samples along a ray cast through the volume, they are fundamentally limited to small scenes with the same objects projected to hundreds of training views. Promoting sparse point clouds to neural implicit light fields allows us to represent large scenes effectively with only a single implicit sampling operation per ray. These point light fields are as a function of the ray direction, and local point feature neighborhood, allowing us to interpolate the light field conditioned training images without dense object coverage and parallax. We assess the proposed method for novel view synthesis on large driving scenarios, where we synthesize realistic unseen views that existing implicit approaches fail to represent. We validate that Neural Point Light Fields make it possible to predict videos along unseen trajectories previously only feasible to generate by explicitly modeling the scene.","tags":["3D","Computer Vision"],"title":"Neural Point Light Fields","type":"publication"},{"authors":["Sai Rajeswar Mudumba","Pau Rodriguez","Soumye Singhal","David Vazquez","Aaron Courville"],"categories":null,"content":"’ \u0026#39;\n","date":1637020800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1637020800,"objectID":"1206020d5439880e8ceef5bde926ab5e","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/sairajeswarmudumbamultcvpr2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/sairajeswarmudumbamultcvpr2022/","section":"publication","summary":"Transfer learning from large-scale pre-trained models has become essential for many computer vision tasks. Recent studies have shown that datasets like ImageNet are weakly labeled since images with multiple object classes present are assigned a single label. This ambiguity biases models towards a single prediction, which could result in the suppression of classes that tend to co-occur in the data. Inspired by language emergence literature, we propose multi-label iterated learning (MILe) to incorporate the inductive biases of multi-label learning from single labels using the framework of iterated learning. MILe is a simple yet effective procedure that builds a multi-label description of the image by propagating binary predictions through successive generations of teacher and student networks with a learning bottleneck. Experiments show that our approach exhibits systematic benefits on ImageNet accuracy as well as ReaL F1 score, which indicates that MILe deals better with label ambiguity than the standard training procedure, even when fine-tuning from self-supervised weights. We also show that MILe is effective reducing label noise, achieving state-of-the-art performance on real-world large-scale noisy data such as WebVision. Furthermore, MILe improves performance in class incremental settings such as IIRC and it is robust to distribution shifts. Code: this https URL","tags":["Computer Vision","Image Classification","Label Ambiguity"],"title":"Multi-label Iterated Learning for Image Classification with Label Ambiguity","type":"publication"},{"authors":["Emily Goodwin","Siva Reddy","Timothy J. O'Donnell","Dzmitry Bahdanau"],"categories":null,"content":"’ \u0026#39;\n","date":1636934400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1636934400,"objectID":"ad7eebf415cc960b5e52b92706461073","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/emilygoodwincompacl2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/emilygoodwincompacl2022/","section":"publication","summary":"Compositionality, or the ability to combine familiar units like words into novel phrases and sentences, has been the focus of intense interest in artificial intelligence in recent years. To test compositional generalization in semantic parsing, Keysers et al. (2020) introduced Compositional Freebase Queries (CFQ). This dataset maximizes the similarity between the test and train distributions over primitive units, like words, while maximizing the compound divergence: the dissimilarity between test and train distributions over larger structures, like phrases. Dependency parsing, however, lacks a compositional generalization benchmark. In this work, we introduce a gold-standard set of dependency parses for CFQ, and use this to analyze the behavior of a state-of-the art dependency parser (Qi et al., 2020) on the CFQ dataset. We find that increasing compound divergence degrades dependency parsing performance, although not as dramatically as semantic parsing performance. Additionally, we find the performance of the dependency parser does not uniformly degrade relative to compound divergence, and the parser performs differently on different splits with the same compound divergence. We explore a number of hypotheses for what causes the non-uniform degradation in dependency parsing performance, and identify a number of syntactic structures that drive the dependency parser's lower performance on the most challenging splits.","tags":["Compositional Generalization","Dependency Parsing"],"title":"Compositional Generalization in Dependency Parsing","type":"publication"},{"authors":["Gaurav Sahu","Pau Rodriguez","Parmida Atighhehchian","Issam H. Laradji","David Vazquez","Dzmitry Bahdanau"],"categories":null,"content":"’ \u0026#39;\n","date":1636934400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1636934400,"objectID":"20164bfee5add9745ee0ab16f1658142","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/gauravsahudataaclworkshops2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/gauravsahudataaclworkshops2022/","section":"publication","summary":"Data augmentation alleviates the problem of data scarcity when training language models (LMs) by generating new examples based on the existing data. A successful approach to generate new samples is to fine-tune a pretrained LM on the task-specific data and then sample from the label-conditioned LM. However, fine-tuning can be difficult when task-specific data is scarce. In this work, we explore whether large pretrained LMs can be used to generate new useful samples without fine-tuning. For a given class, we propose concatenating few examples and prompt them to GPT-3 to generate new examples. We evaluate this method for few-shot intent classification on CLINC150 and SNIPS and find that data generated by GPT-3 greatly improves the performance of the intent classifiers. Importantly, we find that, without any LM fine-tuning, the gains brought by data augmentation with GPT-3 are similar to those reported in prior work on LM-based data augmentation. Experiments with models of different sizes show that larger LMs generate higher quality samples that yield higher accuracy gains. ","tags":["Data Augmentation","Natural Language Processing","Intent Classification"],"title":"Data Augmentation for Intent Classification with Off-the-shelf Large Language Models","type":"publication"},{"authors":["Dora Jambor","Dzmitry Bahdanau"],"categories":null,"content":"’ \u0026#39;\n","date":1636934400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1636934400,"objectID":"e5594630cadce8a4382a2bce187cc704","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/dorajamborlagracl2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/dorajamborlagracl2022/","section":"publication","summary":"Semantic parsing is the task of producing a structured meaning representation for natural language utterances or questions. Recent research has pointed out that the commonly-used sequence-to-sequence (seq2seq) semantic parsers struggle to generalize systematically, i.e. to handle examples that require recombining known knowledge in novel settings. In this work, we show that better systematic generalization can be achieved by producing the meaning representation (MR) directly as a graph and not as a sequence. To this end we propose LAGr, the Labeling Aligned Graphs algorithm that produces semantic parses by predicting node and edge labels for a complete multi-layer input-aligned graph. The strongly-supervised LAGr algorithm requires aligned graphs as inputs, whereas weakly-supervised LAGr infers alignments for originally unaligned target graphs using an approximate MAP inference procedure. On the COGS and CFQ compositional generalization benchmarks the strongly- and weakly- supervised LAGr algorithms achieve significant improvements upon the baseline seq2seq parsers.","tags":["Systematic Generalization","Graphs"],"title":"LAGr: Labeling Aligned Graphs for Improving Systematic Generalization in Semantic Parsing","type":"publication"},{"authors":["Alzayat Saleh","Issam H. Laradji","Corey Lammie","David Vazquez","Carol A Flavell","Mostafa Rahimi Azghadi"],"categories":null,"content":"’ \u0026#39;\n","date":1635120000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1635120000,"objectID":"09bb0fb46fb00fc3b15417c7b02134b7","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/alzayatsalehadeenaturesr2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/alzayatsalehadeenaturesr2021/","section":"publication","summary":"Health professionals extensively use Two-Dimensional (2D) Ultrasound (US) videos and images to visualize and measure internal organs for various purposes including evaluation of muscle architectural changes. US images can be used to measure abdominal muscles dimensions for the diagnosis and creation of customized treatment plans for patients with Low Back Pain (LBP), however, they are difficult to interpret. Due to high variability, skilled professionals with specialized training are required to take measurements to avoid low intra-observer reliability. This variability stems from the challenging nature of accurately finding the correct spatial location of measurement endpoints in abdominal US images. In this paper, we use a Deep Learning (DL) approach to automate the measurement of the abdominal muscle thickness in 2D US images. By treating the problem as a localization task, we develop a modified Fully Convolutional Network (FCN) architecture to generate blobs of coordinate locations of measurement endpoints, similar to what a human operator does. We demonstrate that using the TrA400 US image dataset, our network achieves a Mean Absolute Error (MAE) of 0.3125 on the test set, which almost matches the performance of skilled ultrasound technicians. Our approach can facilitate next steps for automating the process of measurements in 2D US images, while reducing inter-observer as well as intra-observer variability for more effective clinical outcomes.","tags":["Computer Vision","Localization","Medical Imaging"],"title":"A Deep Learning Localization Method for Measuring Abdominal Muscle Dimensions in Ultrasound Images","type":"publication"},{"authors":["Philippe Brouillard","Perouz Taslakian","Alexandre Lacoste","Sébastien Lachapelle","Alexandre Drouin"],"categories":null,"content":"’ \u0026#39;\n","date":1634860800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1634860800,"objectID":"2bd40aa092b7cb62d5c1a348a8a467f1","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/philippebrouillardtypiclear2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/philippebrouillardtypiclear2022/","section":"publication","summary":"Causal discovery from observational data is a challenging task that can only be solved up to a set of equivalent solutions, called an equivalence class. Such classes, which are often large in size, encode uncertainties about the orientation of some edges in the causal graph. In this work, we propose a new set of assumptions that constrain possible causal relationships based on the nature of variables, thus circumscribing the equivalence class. Namely, we introduce typed directed acyclic graphs, in which variable types are used to determine the validity of causal relationships. We demonstrate, both theoretically and empirically, that the proposed assumptions can result in significant gains in the identification of the causal graph. We also propose causal discovery algorithms that make use of these assumptions and demonstrate their benefits on simulated and pseudo-real data.","tags":["Causality","Causal Discovery"],"title":"Typing assumptions improve identification in causal discovery - theory and algorithms","type":"publication"},{"authors":["Nathan Schucher","Siva Reddy","Harm de Vries"],"categories":null,"content":"’ \u0026#39;\n","date":1634256000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1634256000,"objectID":"9ebc02ffec151bee15c76897b088a579","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/nathanschucherthepacl2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/nathanschucherthepacl2022/","section":"publication","summary":"Prompt tuning has recently emerged as an effective method for adapting pre-trained language models to a number of language tasks. In this paper, we investigate prompt tuning for semantic parsing, the task of mapping natural language utterances onto formal meaning representations. For large T5 models we find (i) that prompt tuning significantly outperforms fine-tuning in the low data regime and (ii) that canonicalization -- i.e. naturalizing the meaning representations -- barely improves performance. This last result is surprising as it suggests that large T5 models can be modulated to generate sequences that are far from the pre-training distribution.","tags":["Semantic Parsing","Prompting"],"title":"The Power of Prompt Tuning for Low-Resource Semantic Parsing","type":"publication"},{"authors":["Pau Rodriguez","Massimo Caccia","Alexandre Lacoste","Lee Zamparo","Issam H. Laradji","Laurent Charlin","David Vazquez"],"categories":null,"content":"’ \u0026#39;\n","date":1633910400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1633910400,"objectID":"9203309804cfb1d7e17cdec1e2b2e29f","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/paurodriguezbeyoiccv2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/paurodriguezbeyoiccv2021/","section":"publication","summary":"Explainability for machine learning models has gained considerable attention within the research community given the importance of deploying more reliable machine-learning systems. In computer vision applications, generative counterfactual methods indicate how to perturb a model's input to change its prediction, providing details about the model's decision-making. Current methods tend to generate trivial counterfactuals about a model's decisions, as they often suggest to exaggerate or remove the presence of the attribute being classified. For the machine learning practitioner, these types of counterfactuals offer little value, since they provide no new information about undesired model or data biases. In this work, we identify the problem of trivial counterfactual generation and we propose DiVE to alleviate it. DiVE learns a perturbation in a disentangled latent space that is constrained using a diversity-enforcing loss to uncover multiple valuable explanations about the model's prediction. Further, we introduce a mechanism to prevent the model from producing trivial explanations. Experiments on CelebA and Synbols demonstrate that our model improves the success rate of producing high-quality valuable explanations when compared to previous state-of-the-art methods. Code is available at this https URL.","tags":["Computer Vision","Explainability"],"title":"Beyond Trivial Counterfactual Explanations with Diverse Valuable Explanations","type":"publication"},{"authors":["Boris Knyazev","Harm de Vries","Cătălina Cangea","Graham W. Taylor","Aaron Courville","Eugene Belilovsky"],"categories":null,"content":"’ \u0026#39;\n","date":1633910400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1633910400,"objectID":"1af21ad43a11bf51cbaea78f14697664","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/borisknyazevgeneiccv2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/borisknyazevgeneiccv2021/","section":"publication","summary":"Inferring objects and their relationships from an image in the form of a scene graph is useful in many applications at the intersection of vision and language. We consider a challenging problem of compositional generalization that emerges in this task due to a long tail data distribution. Current scene graph generation models are trained on a tiny fraction of the distribution corresponding to the most frequent compositions, e.g. . However, test images might contain zero- and few-shot compositions of objects and relationships, e.g. . Despite each of the object categories and the predicate (e.g. 'on') being frequent in the training data, the models often fail to properly understand such unseen or rare compositions. To improve generalization, it is natural to attempt increasing the diversity of the training distribution. However, in the graph domain this is non-trivial. To that end, we propose a method to synthesize rare yet plausible scene graphs by perturbing real ones. We then propose and empirically study a model based on conditional generative adversarial networks (GANs) that allows us to generate visual features of perturbed scene graphs and learn from them in a joint fashion. When evaluated on the Visual Genome dataset, our approach yields marginal, but consistent improvements in zero- and few-shot metrics. We analyze the limitations of our approach indicating promising directions for future research.","tags":["Graphs","Compositional Generalization"],"title":"Generative Compositional Augmentations for Scene Graph Prediction","type":"publication"},{"authors":["Oscar Manas","Alexandre Lacoste","Xavier Giro-i-Nieto","David Vazquez","Pau Rodriguez"],"categories":null,"content":"’ \u0026#39;\n","date":1633910400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1633910400,"objectID":"4279f53234d6bf565a49f6fe0781242d","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/oscarmanasseasiccv2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/oscarmanasseasiccv2021/","section":"publication","summary":"Remote sensing and automatic earth monitoring are key to solve global-scale challenges such as disaster prevention, land use monitoring, or tackling climate change. Although there exist vast amounts of remote sensing data, most of it remains unlabeled and thus inaccessible for supervised learning algorithms. Transfer learning approaches can reduce the data requirements of deep learning algorithms. However, most of these methods are pre-trained on ImageNet and their generalization to remote sensing imagery is not guaranteed due to the domain gap. In this work, we propose Seasonal Contrast (SeCo), an effective pipeline to leverage unlabeled data for in-domain pre-training of remote sensing representations. The SeCo pipeline is composed of two parts. First, a principled procedure to gather large-scale, unlabeled and uncurated remote sensing datasets containing images from multiple Earth locations at different timestamps. Second, a self-supervised algorithm that takes advantage of time and position invariance to learn transferable representations for remote sensing applications. We empirically show that models trained with SeCo achieve better performance than their ImageNet pre-trained counterparts and state-of-the-art self-supervised learning methods on multiple downstream tasks. The datasets and models in SeCo will be made public to facilitate transfer learning and enable rapid progress in remote sensing applications.","tags":["Computer Vision","Remote Sensing","Self-supervised Learning","Unsupervised Learning","Image Classification","Semantic Segmentation"],"title":"Seasonal Contrast: Unsupervised Pre-Training from Uncurated Remote Sensing Data","type":"publication"},{"authors":["Issam H. Laradji","Pau Rodriguez","David Vazquez","Derek Nowrouzezahrai"],"categories":null,"content":"’ \u0026#39;\n","date":1633910400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1633910400,"objectID":"f812d7b655f8116b13f06c5abc1f11a0","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/issamh.laradjissriccvworkshops2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/issamh.laradjissriccvworkshops2021/","section":"publication","summary":"Recent work has made significant progress in learning object meshes with weak supervision. Soft Rasterization methods have achieved accurate 3D reconstruction from 2D images with viewpoint supervision only. In this work, we further reduce the labeling effort by allowing such 3D reconstruction methods leverage unlabeled images. In order to obtain the viewpoints for these unlabeled images, we propose to use a Siamese network that takes two images as input and outputs whether they correspond to the same viewpoint. During training, we minimize the cross entropy loss to maximize the probability of predicting whether a pair of images belong to the same viewpoint or not. To get the viewpoint of a new image, we compare it against different viewpoints obtained from the training samples and select the viewpoint with the highest matching probability. We finally label the unlabeled images with the most confident predicted viewpoint and train a deep network that has a differentiable rasterization layer. Our experiments show that even labeling only two objects yields significant improvement in IoU for ShapeNet when leveraging unlabeled examples. Code is available at this https URL.","tags":["Computer Vision","3D","Semi-supervised Learning"],"title":"SSR: Semi-supervised Soft Rasterizer for single-view 2D to 3D Reconstruction","type":"publication"},{"authors":["Vaibhav Adlakha","Shehzaad Dhuliawala","Kaheer Suleman","Harm de Vries","Siva Reddy"],"categories":null,"content":"’ \u0026#39;\n","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1633046400,"objectID":"bf7537b8499f804de4a2cc3291b05bfb","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/vaibhavadlakhatopiacl2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/vaibhavadlakhatopiacl2022/","section":"publication","summary":"In a conversational question answering scenario, a questioner seeks to extract information about a topic through a series of interdependent questions and answers. As the conversation progresses, they may switch to related topics, a phenomenon commonly observed in information-seeking search sessions. However, current datasets for conversational question answering are limiting in two ways: 1) they do not contain topic switches; and 2) they assume the reference text for the conversation is given, i.e., the setting is not open-domain. We introduce TopiOCQA (pronounced Tapioca), an open-domain conversational dataset with topic switches on Wikipedia. TopiOCQA contains 3,920 conversations with information-seeking questions and free-form answers. On average, a conversation in our dataset spans 13 question-answer turns and involves four topics (documents). TopiOCQA poses a challenging test-bed for models, where efficient retrieval is required on multiple turns of the same conversation, in conjunction with constructing valid responses using conversational history. We evaluate several baselines, by combining state-of-the-art document retrieval methods with neural reader models. Our best model achieves F1 of 55.8, falling short of human performance by 14.2 points, indicating the difficulty of our dataset. Our dataset and code is available at this https URL","tags":["Natural Language Processing","Question Answering","Dialogs"],"title":"TopiOCQA: Open-domain Conversational Question Answering with Topic Switching","type":"publication"},{"authors":["Leon Bergen","Timothy J. O'Donnell","Dzmitry Bahdanau"],"categories":null,"content":"’ \u0026#39;\n","date":1632787200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1632787200,"objectID":"2dde0ddbad7015108cb855a9ef2fb218","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/leonbergensystneurips2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/leonbergensystneurips2021/","section":"publication","summary":"Recent research suggests that systematic generalization in natural language understanding remains a challenge for state-of-the-art neural models such as Transformers and Graph Neural Networks. To tackle this challenge, we propose Edge Transformer, a new model that combines inspiration from Transformers and rule-based symbolic AI. The first key idea in Edge Transformers is to associate vector states with every edge, that is, with every pair of input nodes -- as opposed to just every node, as it is done in the Transformer model. The second major innovation is a triangular attention mechanism that updates edge representations in a way that is inspired by unification from logic programming. We evaluate Edge Transformer on compositional generalization benchmarks in relational reasoning, semantic parsing, and dependency parsing. In all three settings, the Edge Transformer outperforms Relation-aware, Universal and classical Transformer baselines.","tags":["Systematic Generalization","Graphs","Transformers"],"title":"Systematic Generalization with Edge Transformers","type":"publication"},{"authors":["Torsten Scholak","Nathan Schucher","Dzmitry Bahdanau"],"categories":null,"content":"’ \u0026#39;\n","date":1632528000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1632528000,"objectID":"39a30615aa31486dbb42ff335ef85af3","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/torstenscholakpicaemnlp2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/torstenscholakpicaemnlp2021/","section":"publication","summary":"Large pre-trained language models for textual data have an unconstrained output space; at each decoding step, they can produce any of 10,000s of sub-word tokens. When fine-tuned to target constrained formal languages like SQL, these models often generate invalid code, rendering it unusable. We propose PICARD (code and trained models available at this https URL), a method for constraining auto-regressive decoders of language models through incremental parsing. PICARD helps to find valid output sequences by rejecting inadmissible tokens at each decoding step. On the challenging Spider and CoSQL text-to-SQL translation tasks, we show that PICARD transforms fine-tuned T5 models with passable performance into state-of-the-art solutions.","tags":["Natural Language Processing","Code Generation"],"title":"Picard: Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models","type":"publication"},{"authors":["Issam H. Laradji","Alzayat Saleh","Pau Rodriguez","Derek Nowrouzezahrai","Mostafa Rahimi Azghadi","David Vazquez"],"categories":null,"content":"’ \u0026#39;\n","date":1630281600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1630281600,"objectID":"f0c4ef55c5ffc6cb7515409ccd69c719","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/issamh.laradjiweaknaturesr2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/issamh.laradjiweaknaturesr2021/","section":"publication","summary":"Estimating fish body measurements like length, width, and mass has received considerable research due to its potential in boosting productivity in marine and aquaculture applications. Some methods are based on manual collection of these measurements using tools like a ruler which is time consuming and labour intensive. Others rely on fully-supervised segmentation models to automatically acquire these measurements but require collecting per-pixel labels which are also time consuming. It can take up to 2 minutes per fish to acquire accurate segmentation labels. To address this problem, we propose a segmentation model that can efficiently train on images labeled with point-level supervision, where each fish is annotated with a single click. This labeling scheme takes an average of only 1 second per fish. Our model uses a fully convolutional neural network with one branch that outputs per-pixel scores and another that outputs an affinity matrix. These two outputs are aggregated using a random walk to get the final, refined per-pixel output. The whole model is trained end-to-end using the localization-based counting fully convolutional neural network (LCFCN) loss and thus we call our method Affinity-LCFCN (A-LCFCN). We conduct experiments on the DeepFish dataset, which contains several fish habitats from north-eastern Australia. The results show that A-LCFCN outperforms a fully-supervised segmentation model when the annotation budget is fixed. They also show that A-LCFCN achieves better segmentation results than LCFCN and a standard baseline.","tags":["Computer Vision","Semantic Segmentation","Yea"],"title":"Weakly Supervised Underwater Fish Segmentation Using Affinity LCFCN","type":"publication"},{"authors":["Thibaud Godon","Pier-Luc Plante","Baptiste Bauvin","Élina Francovic-Fontaine","Alexandre Drouin","François Laviolette","Jacques Corbeil"],"categories":null,"content":"’ \u0026#39;\n","date":1627171200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1627171200,"objectID":"6dcf1568d0db4b59abfed62bf7248f33","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/thibaudgodonrandismb/eccb2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/thibaudgodonrandismb/eccb2021/","section":"publication","summary":"Recent metabolomics measurement devices, such as mass spectrometers, produce extremely high-dimensional data. Together with small sample sizes, this setting is known as the fat data (or p  n) problem. Biomarker discovery in this configuration is a challenge. Classical statistical methods fail and common Machine Learning (ML) algorithms produce models too complex to be interpretable. ML algorithms that rely on sparsity to predict phenotypes using very few covariates have been shown to thrive in this setting. While sparsity helps to avoid overfitting, it also leads to concise models that are easier to interpret for biomarker discovery. The Set Covering Machine (SCM) algorithm produces sparse models based on simple decision rules. Recent work has applied SCMs to the genotype-to-phenotype prediction of antibiotic resistance and achieved state-of-the-art accuracy. To adapt this approach to metabolomics (fat) data, we developed a bootstrap aggregation of SCM models: RandomSCM. We explored applications of RandomSCM beyond genotype-to-phenotype prediction by applying it to five metabolomics datasets. Predictions performances are at state-of-the-art level. Furthermore, the study of the decision rules in RandomSCM revealed valid biomarkers of the phenotypes. These results demonstrate the high potential of the RandomSCM algorithm for biomarker discovery in omics sciences.","tags":["Interpretability","Symbolic/Rule-based models","Ensembles","Bioinformatics"],"title":"RandomSCM: interpretable ensembles of sparse classifiers tailored for omics data","type":"publication"},{"authors":["Philippe Brouillard","Perouz Taslakian","Alexandre Lacoste","Sébastien Lachapelle","Alexandre Drouin"],"categories":null,"content":"’ \u0026#39;\n","date":1626998400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1626998400,"objectID":"9a759009824cfd96be30c5ab91d9f1d5","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/philippebrouillardtypiicml2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/philippebrouillardtypiicml2021/","section":"publication","summary":"Causal discovery from observational data is a challenging task that can only be solved up to a set of equivalent solutions, called an equivalence class. Such classes, which are often large in size, encode uncertainties about the orientation of some edges in the causal graph. In this work, we propose a new set of assumptions that constrain possible causal relationships based on the nature of variables, thus circumscribing the equivalence class. Namely, we introduce typed directed acyclic graphs, in which variable types are used to determine the validity of causal relationships. We demonstrate, both theoretically and empirically, that the proposed assumptions can result in significant gains in the identification of the causal graph. We also propose causal discovery algorithms that make use of these assumptions and demonstrate their benefits on simulated and pseudo-real data.","tags":["Causality","Causal Discovery"],"title":"Typing assumptions improve identification in causal discovery","type":"publication"},{"authors":["Frédéric Branchaud-Charron","Parmida Atighhehchian","Pau Rodriguez","Grace Abuhamad","Alexandre Lacoste"],"categories":null,"content":"’ \u0026#39;\n","date":1618358400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1618358400,"objectID":"b9a93cfb59606f65e3db6d96bb45ee35","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/fredericbranchaud-charroncanaiclrworkshops2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/fredericbranchaud-charroncanaiclrworkshops2021/","section":"publication","summary":"Dataset bias is one of the prevailing causes of unfairness in machine learning. Addressing fairness at the data collection and dataset preparation stages therefore becomes an essential part of training fairer algorithms. In particular, active learning (AL) algorithms show promise for the task by drawing importance to the most informative training samples. However, the effect and interaction between existing AL algorithms and algorithmic fairness remain under-explored. In this paper, we study whether models trained with uncertainty-based AL heuristics such as BALD are fairer in their decisions with respect to a protected class than those trained with identically independently distributed (i.i.d.) sampling. We found a significant improvement on predictive parity when using BALD, while also improving accuracy compared to i.i.d. sampling. We also explore the interaction of algorithmic fairness methods such as gradient reversal (GRAD) and BALD. We found that, while addressing different fairness issues, their interaction further improves the results on most benchmarks and metrics we explored.","tags":["Active Learning","Fairness"],"title":"Can Active Learning Preemptively Mitigate Fairness Issues?","type":"publication"},{"authors":["Nicolas Loizou","Sharan Vaswani","Issam H. Laradji","Simon Lacoste-Julien"],"categories":null,"content":"’ \u0026#39;\n","date":1618272000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1618272000,"objectID":"d432f458a29ef144049db877ff8a25b2","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/nicolasloizoustocaistats2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/nicolasloizoustocaistats2021/","section":"publication","summary":"We propose a stochastic variant of the classical Polyak step-size (Polyak, 1987) commonly used in the subgradient method. Although computing the Polyak step-size requires knowledge of the optimal function values, this information is readily available for typical modern machine learning applications. Consequently, the proposed stochastic Polyak step-size (SPS) is an attractive choice for setting the learning rate for stochastic gradient descent (SGD). We provide theoretical convergence guarantees for SGD equipped with SPS in different settings, including strongly convex, convex and non-convex functions. Furthermore, our analysis results in novel convergence guarantees for SGD with a constant step-size. We show that SPS is particularly effective when training over-parameterized models capable of interpolating the training data. In this setting, we prove that SPS enables SGD to converge to the true solution at a fast rate without requiring the knowledge of any problem-dependent constants or additional computational overhead. We experimentally validate our theoretical results via extensive experiments on synthetic and real datasets. We demonstrate the strong performance of SGD with SPS compared to state-of-the-art optimization methods when training over-parameterized models.","tags":["Optimization"],"title":"Stochastic polyak step-size for sgd: An adaptive learning rate for fast convergence","type":"publication"},{"authors":null,"categories":null,"content":"‘The SeCo dataset is collected from Sentinel-2 with a principled procedure to gather large-scale, unlabeled, and uncurated remote sensing datasets containing images from multiple Earth locations at different timestamps.\n\u0026#39;\n","date":1617062400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1617062400,"objectID":"8562fea5794aa696e004cf97b2e632ef","permalink":"https://elementai.github.io/servicenowresearch/fr/datasets/seco-seasonal-c/","publishdate":"2021-03-30T00:00:00Z","relpermalink":"/servicenowresearch/fr/datasets/seco-seasonal-c/","section":"datasets","summary":"The SeCo dataset is collected from Sentinel-2 with a principled procedure to gather large-scale, unlabeled, and uncurated remote sensing datasets containing images from multiple Earth locations at different timestamps.","tags":null,"title":"SeCo: Seasonal Contrast Remote Sensing Dataset","type":"datasets"},{"authors":["Torsten Scholak","Raymond Li","Dzmitry Bahdanau","Harm de Vries","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1609891200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1609891200,"objectID":"9f441983370e5ba48e5e9e9217f64653","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/torstenscholakduornaacl2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/torstenscholakduornaacl2021/","section":"publication","summary":"Recent neural text-to-SQL models can effectively translate natural language questions to corresponding SQL queries on unseen databases. Working mostly on the Spider dataset, researchers have proposed increasingly sophisticated solutions to the problem. Contrary to this trend, in this paper we focus on simplifications. We begin by building DuoRAT, a re-implementation of the state-of-the-art RAT-SQL model that unlike RAT-SQL is using only relation-aware or vanilla transformers as the building blocks. We perform several ablation experiments using DuoRAT as the baseline model. Our experiments confirm the usefulness of some techniques and point out the redundancy of others, including structural SQL features and features that link the question with the schema.","tags":["Natural Language Processing","Code Generation"],"title":"DuoRAT: Towards Simpler Text-to-SQL Models","type":"publication"},{"authors":["Arian Hosseini","Siva Reddy","Dzmitry Bahdanau","R Devon Hjelm","Alessandro Sordoni","Aaron Courville"],"categories":null,"content":"’ \u0026#39;\n","date":1609891200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1609891200,"objectID":"3aea976b36f8e0675a91b04e76d698aa","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/arianhosseiniundenaacl2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/arianhosseiniundenaacl2021/","section":"publication","summary":"Negation is a core construction in natural language. Despite being very successful on many tasks, state-of-the-art pre-trained language models often handle negation incorrectly. To improve language models in this regard, we propose to augment the language modeling objective with an unlikelihood objective that is based on negated generic sentences from a raw text corpus. By training BERT with the resulting combined objective we reduce the mean top~1 error rate to 4% on the negated LAMA dataset. We also see some improvements on the negated NLI benchmarks.","tags":["Natural Language Processing"],"title":"Understanding by Understanding Not: Modeling Negation in Language Models","type":"publication"},{"authors":["Parichehr Behjati","Pau Rodriguez","Armin Mehri","Isabelle Hupont","Jordi Gonzalez","Carles Fernandez"],"categories":null,"content":"’ \u0026#39;\n","date":1609718400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1609718400,"objectID":"f59ec463564d6048af3b84b3299f9850","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/parichehrbehjatioverwacv2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/parichehrbehjatioverwacv2021/","section":"publication","summary":"Super-resolution (SR) has achieved great success due to the development of deep convolutional neural networks (CNNs). However, as the depth and width of the networks increase, CNN-based SR methods have been faced with the challenge of computational complexity in practice. Moreover, most of them train a dedicated model for each target resolution, losing generality and increasing memory requirements. To address these limitations we introduce OverNet, a deep but lightweight convolutional network to solve SISR at arbitrary scale factors with a single model. We make the following contributions: first, we introduce a lightweight recursive feature extractor that enforces efficient reuse of information through a novel recursive structure of skip and dense connections. Second, to maximize the performance of the feature extractor we propose a reconstruction module that generates accurate high-resolution images from overscaled feature maps and can be independently used to improve existing architectures. Third, we introduce a multi-scale loss function to achieve generalization across scales. Through extensive experiments, we demonstrate that our network outperforms previous state-of-the-art results in standard benchmarks while using fewer parameters than previous approaches.","tags":["Computer Vision","Super-Resolution"],"title":"Overnet: Lightweight multi-scale super-resolution with overscaling network","type":"publication"},{"authors":["Lachlan McCalman","Daniel Steinberg"],"categories":null,"content":"’ \u0026#39;\n","date":1608249600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1608249600,"objectID":"7e9e8404348dc1dbe6de18a73e2cc406","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/lachlanmccalmanusinacmfacct2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/lachlanmccalmanusinacmfacct2021/","section":"publication","summary":"’ '","tags":["Fairness"],"title":"Using Harms and Benefits to Ground Practical AI Fairness Assessments in Finance","type":"publication"},{"authors":["Philippe Brouillard","Sébastien Lachapelle","Alexandre Lacoste","Simon Lacoste-Julien","Alexandre Drouin"],"categories":null,"content":"’ \u0026#39;\n","date":1607212800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1607212800,"objectID":"d6f131cf6005ca22d01289ea71e62b41","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/philippebrouillarddiffneurips2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/philippebrouillarddiffneurips2020/","section":"publication","summary":"Learning a causal directed acyclic graph from data is a challenging task that involves solving a combinatorial problem for which the solution is not always identifiable. A new line of work reformulates this problem as a continuous constrained optimization one, which is solved via the augmented Lagrangian method. However, most methods based on this idea do not make use of interventional data, which can significantly alleviate identifiability issues. This work constitutes a new step in this direction by proposing a theoretically-grounded method based on neural networks that can leverage interventional data. We illustrate the flexibility of the continuous-constrained framework by taking advantage of expressive neural architectures such as normalizing flows. We show that our approach compares favorably to the state of the art in a variety of settings, including perfect and imperfect interventions for which the targeted nodes may even be unknown.","tags":["Causality","Causal Discovery","Differentiable Optimization","Interventions"],"title":"Differentiable Causal Discovery from Interventional Data","type":"publication"},{"authors":["Gintare Karolina Dziugaite","Alexandre Drouin","Brayden (Brady) Neal","Nitarshan Rajkumar","Ethan Victor Caballero","Linbo Wang","Ioannis Mitliagkas","Daniel M. Roy"],"categories":null,"content":"’ \u0026#39;\n","date":1607212800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1607212800,"objectID":"3cabad6b3a84e0eb7a19abd5ddc8453b","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/gintarekarolinadziugaiteinseneurips2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/gintarekarolinadziugaiteinseneurips2020/","section":"publication","summary":"One of the principal scientific challenges in deep learning is explaining generalization, i.e., why the particular way the community now trains networks to achieve small training error also leads to small error on held-out data from the same population. It is widely appreciated that some worst-case theories -- such as those based on the VC dimension of the class of predictors induced by modern neural network architectures -- are unable to explain empirical performance. A large volume of work aims to close this gap, primarily by developing bounds on generalization error, optimization error, and excess risk. When evaluated empirically, however, most of these bounds are numerically vacuous. Focusing on generalization bounds, this work addresses the question of how to evaluate such bounds empirically. Jiang et al. (2020) recently described a large-scale empirical study aimed at uncovering potential causal relationships between bounds/measures and generalization. Building on their study, we highlight where their proposed methods can obscure failures and successes of generalization measures in explaining generalization. We argue that generalization measures should instead be evaluated within the framework of distributional robustness.","tags":["Deep Learning","Generalization Guarranties","Benchmark"],"title":"In search of robust measures of generalization","type":"publication"},{"authors":["Grace Abuhamad","Claudel Rheault"],"categories":null,"content":"’ \u0026#39;\n","date":1606694400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1606694400,"objectID":"6d2ba83f2074ed4c13845c98cfee5f77","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/graceabuhamadlikeneuripsworkshops2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/graceabuhamadlikeneuripsworkshops2020/","section":"publication","summary":"In requiring that a statement of broader impact accompany all submissions for this year's conference, the NeurIPS program chairs made ethics part of the stake in groundbreaking AI research. While there is precedent from other fields and increasing awareness within the NeurIPS community, this paper seeks to answer the question of how individual researchers reacted to the new requirement, including not just their views, but also their experience in drafting and their reflections after paper acceptances. We present survey results and considerations to inform the next iteration of the broader impact requirement should it remain a requirement for future NeurIPS conferences.","tags":["Broarder Impact Assesment"],"title":"Like A Researcher Stating Broader Impact for the Very First Time","type":"publication"},{"authors":["Mahdi Haghifam","Gintare Karolina Dziugaite","Shay Moran","Daniel M. Roy"],"categories":null,"content":"’ \u0026#39;\n","date":1604534400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1604534400,"objectID":"b940a0cd197b9eac60ba0011dd6916a1","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/mahdihaghifamontharxiv2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/mahdihaghifamontharxiv2020/","section":"publication","summary":"We provide a negative resolution to a conjecture of Steinke and Zakynthinou (2020a), by showing that their bound on the conditional mutual information (CMI) of proper learners of Vapnik--Chervonenkis (VC) classes cannot be improved from d logn + 2 to O(d), where n is the number of i.i.d. training examples. In fact, we exhibit VC classes for which the CMI of any proper learner cannot be bounded by any real-valued function of the VC dimension only.","tags":["Guarranties"],"title":"On the Information Complexity of Proper Learners for VC Classes in the Realizable Case","type":"publication"},{"authors":["Issam H. Laradji","Pau Rodriguez","Alfredo Kalaitzis","David Vazquez","Ross Young","Ed Davey","Alexandre Lacoste"],"categories":null,"content":"’ \u0026#39;\n","date":1601942400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1601942400,"objectID":"fc4c7c7fa1cfe70b69f946db1cf18000","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/issamh.laradjicounneuripsworkshops2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/issamh.laradjicounneuripsworkshops2020/","section":"publication","summary":"Cattle farming is responsible for 8.8\\% of greenhouse gas emissions worldwide. In addition to the methane emitted due to their digestive process, the growing need for grazing areas is an important driver of deforestation. While some regulations are in place for preserving the Amazon against deforestation, these are being flouted in various ways, hence the need to scale and automate the monitoring of cattle ranching activities. Through a partnership with \\textit{Global Witness}, we explore the feasibility of tracking and counting cattle at the continental scale from satellite imagery. With a license from Maxar Technologies, we obtained satellite imagery of the Amazon at 40cm resolution, and compiled a dataset of 903 images containing a total of 28498 cattle. Our experiments show promising results and highlight important directions for the next steps on both counting algorithms and the data collection process for solving such challenges. The code is available at \\url{this https URL}.","tags":["Computer Vision","Climate Change","Remote Sensing","Object Counting"],"title":"Counting Cows: Tracking Illegal Cattle RanchingFrom High-Resolution Satellite Imagery","type":"publication"},{"authors":["Vincenzo Lomonaco","Lorenzo Pellegrini","Pau Rodriguez","Massimo Caccia","Qi She","Yu Chen","Quentin Jodelet","Ruiping Wang","Zheda Mai","David Vazquez","German I. Parisi","Nikhil Churamani","Marc Pickett","Issam H. Laradji","Davide Maltoni"],"categories":null,"content":"’ \u0026#39;\n","date":1600214400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1600214400,"objectID":"cd08242087ecb1f47bfb6623c49e9b39","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/vincenzolomonacocvpraij2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/vincenzolomonacocvpraij2022/","section":"publication","summary":"In the last few years, we have witnessed a renewed and fast-growing interest in continual learning with deep neural networks with the shared objective of making current AI systems more adaptive, efficient and autonomous. However, despite the significant and undoubted progress of the field in addressing the issue of catastrophic forgetting, benchmarking different continual learning approaches is a difficult task by itself. In fact, given the proliferation of different settings, training and evaluation protocols, metrics and nomenclature, it is often tricky to properly characterize a continual learning algorithm, relate it to other solutions and gauge its real-world applicability. The first Continual Learning in Computer Vision challenge held at CVPR in 2020 has been one of the first opportunities to evaluate different continual learning algorithms on a common hardware with a large set of shared evaluation metrics and 3 different settings based on the realistic CORe50 video benchmark. In this paper, we report the main results of the competition, which counted more than 79 teams registered, 11 finalists and 2300$ in prizes. We also summarize the winning approaches, current challenges and future research directions.","tags":["Continual Learning"],"title":"CVPR 2020 Continual Learning in Computer Vision Competition: Approaches, Results, Current Challenges and Future Directions ","type":"publication"},{"authors":["Parmida Atighhehchian","Frederic Branchaud","Alexandre Lacoste"],"categories":null,"content":"’ \u0026#39;\n","date":1594166400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1594166400,"objectID":"b8ac829910fc3695c5f457838e59df2d","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/parmidaatighhehchianbayeicmlworkshops2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/parmidaatighhehchianbayeicmlworkshops2020/","section":"publication","summary":"Active learning is able to reduce the amount of labelling effort by using a machine learning model to query the user for specific inputs. ","tags":["Active Learning"],"title":" Bayesian active learning for production, a systematic study and a reusable library","type":"publication"},{"authors":["Boris Knyazev","Harm de Vries","Cătălina Cangea","Graham Taylor","Aaron Courville","Eugene Belilovsky"],"categories":null,"content":"’ \u0026#39;\n","date":1593648000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1593648000,"objectID":"d3108097bef0e0ee0cb848d594877064","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/borisknyazevgrapbmvc2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/borisknyazevgrapbmvc2020/","section":"publication","summary":"Scene graph generation (SGG) aims to predict graph-structured descriptions of input images, in the form of objects and relationships between them. This task is becoming increasingly useful for progress at the interface of vision and language. Here, it is important - yet challenging - to perform well on novel (zero-shot) or rare (few-shot) compositions of objects and relationships. In this paper, we identify two key issues that limit such generalization. Firstly, we show that the standard loss used in this task is unintentionally a function of scene graph density. This leads to the neglect of individual edges in large sparse graphs during training, even though these contain diverse few-shot examples that are important for generalization. Secondly, the frequency of relationships can create a strong bias in this task, such that a blind model predicting the most frequent relationship achieves good performance. Consequently, some state-of-the-art models exploit this bias to improve results. We show that such models can suffer the most in their ability to generalize to rare compositions, evaluating two different models on the Visual Genome dataset and its more recent, improved version, GQA. To address these issues, we introduce a density-normalized edge loss, which provides more than a two-fold improvement in certain generalization metrics. Compared to other works in this direction, our enhancements require only a few lines of code and no added computational cost. We also highlight the difficulty of accurately evaluating models using existing metrics, especially on zero/few shots, and introduce a novel weighted metric.","tags":["Graphs"],"title":"Graph-Density Aware Losses for Novel Compositions in Scene Graph Generation","type":"publication"},{"authors":["Issam H. Laradji","Pau Rodriguez","Oscar Manas","Keegan Lensink","Marco Law","Lironne Kurzman","William Parker","David Vazquez","Derek Nowrouzezahrai"],"categories":null,"content":"’ \u0026#39;\n","date":1592956800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1592956800,"objectID":"151d31210a9ffe2a3ec624e3ff075dc0","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/issamh.laradjiaweawacv2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/issamh.laradjiaweawacv2021/","section":"publication","summary":"Coronavirus Disease 2019 (COVID-19) has spread aggressively across the world causing an existential health crisis. Thus, having a system that automatically detects COVID-19 in tomography (CT) images can assist in quantifying the severity of the illness. Unfortunately, labelling chest CT scans requires significant domain expertise, time, and effort. We address these labelling challenges by only requiring point annotations, a single pixel for each infected region on a CT image. This labeling scheme allows annotators to label a pixel in a likely infected region, only taking 1-3 seconds, as opposed to 10-15 seconds to segment a region. Conventionally, segmentation models train on point-level annotations using the cross-entropy loss function on these labels. However, these models often suffer from low precision. Thus, we propose a consistency-based (CB) loss function that encourages the output predictions to be consistent with spatial transformations of the input images. The experiments on 3 open-source COVID-19 datasets show that this loss function yields significant improvement over conventional point-level loss functions and almost matches the performance of models trained with full supervision with much less human effort. Code is available at: \\url{this https URL}.","tags":["Computer Vision","Medical Imaging","Weak Supervision","Semantic Segmentation"],"title":"A Weakly Supervised Consistency-based Learning Method for COVID-19 Segmentation in CT Images","type":"publication"},{"authors":["Lucas Caccia","Eugene Belilovsky","Massimo Caccia","Joelle Pineau"],"categories":null,"content":"’ \u0026#39;\n","date":1592352000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1592352000,"objectID":"5f1f70c4ffcd67e2d3260517497245fc","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/lucascacciaonliicml2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/lucascacciaonliicml2020/","section":"publication","summary":"We introduce and study the problem of Online Continual Compression, where one attempts to simultaneously learn to compress and store a representative dataset from a non i.i.d data stream, while only observing each sample once. A naive application of auto-encoders in this setting encounters a major challenge: representations derived from earlier encoder states must be usable by later decoder states. We show how to use discrete auto-encoders to effectively address this challenge and introduce Adaptive Quantization Modules (AQM) to control variation in the compression ability of the module at any given stage of learning. This enables selecting an appropriate compression for incoming samples, while taking into account overall memory constraints and current progress of the learned compression. Unlike previous methods, our approach does not require any pretraining, even on challenging datasets. We show that using AQM to replace standard episodic memory in continual learning settings leads to significant gains on continual learning benchmarks. Furthermore we demonstrate this approach with larger images, LiDAR, and reinforcement learning environments.","tags":["Continual Learning","Compression"],"title":"Online Learned Continual Compression with Adaptive Quantization Modules","type":"publication"},{"authors":["Alexandre Lacoste","Pau Rodriguez","Frédéric Branchaud-Charron","Parmida Atighhehchian","Massimo Caccia","Issam H. Laradji","Alexandre Drouin","Matt Craddock","Laurent Charlin","David Vazquez"],"categories":null,"content":"’ \u0026#39;\n","date":1591142400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1591142400,"objectID":"ad1fa65ea5ed99a1bdcb51e2c2ddcb39","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/alexandrelacostesynbmais2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/alexandrelacostesynbmais2018/","section":"publication","summary":"Progress in the field of machine learning has been fueled by the introduction of benchmark datasets pushing the limits of existing algorithms. Enabling the design of datasets to test specific properties and failure modes of learning algorithms is thus a problem of high interest, as it has a direct impact on innovation in the field. In this sense, we introduce Synbols -- Synthetic Symbols -- a tool for rapidly generating new datasets with a rich composition of latent features rendered in low resolution images. Synbols leverages the large amount of symbols available in the Unicode standard and the wide range of artistic font provided by the open font community. Our tool's high-level interface provides a language for rapidly generating new distributions on the latent features, including various types of textures and occlusions. To showcase the versatility of Synbols, we use it to dissect the limitations and flaws in standard learning algorithms in various learning setups including supervised learning, active learning, out of distribution generalization, unsupervised representation learning, and object counting.","tags":["Dataset","Computer Vision","Active Learning","Few-shot Learning","Continual Learning","Object Counting"],"title":"Synbols: Probing Learning Algorithms with Synthetic Datasets","type":"publication"},{"authors":["Alexandre Lacoste","Pau Rodriguez","Frederic Branchaud","Parmida Atighhehchian","Massimo Caccia","Issam H. Laradji","Alexandre Drouin","Matt Craddock","Laurent Charlin","David Vazquez"],"categories":null,"content":"’ \u0026#39;\n","date":1591142400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1591142400,"objectID":"9be4cea7a36b13789f6d528f5c6b1a20","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/alexandrelacostesynbneurips2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/alexandrelacostesynbneurips2020/","section":"publication","summary":"Progress in the field of machine learning has been fueled by the introduction of benchmark datasets pushing the limits of existing algorithms. Enabling the design of datasets to test specific properties and failure modes of learning algorithms is thus a problem of high interest, as it has a direct impact on innovation in the field. In this sense, we introduce Synbols -- Synthetic Symbols -- a tool for rapidly generating new datasets with a rich composition of latent features rendered in low resolution images. Synbols leverages the large amount of symbols available in the Unicode standard and the wide range of artistic font provided by the open font community. Our tool's high-level interface provides a language for rapidly generating new distributions on the latent features, including various types of textures and occlusions. To showcase the versatility of Synbols, we use it to dissect the limitations and flaws in standard learning algorithms in various learning setups including supervised learning, active learning, out of distribution generalization, unsupervised representation learning, and object counting.","tags":["Dataset","Computer Vision","Active Learning","Few-shot Learning","Continual Learning","Object Counting"],"title":"Synbols: Probing Learning Algorithms with Synthetic Datasets","type":"publication"},{"authors":["Pedro O. Pinheiro","Amjad Almahairi","Ryan Benmalek","Florian Golemo","Aaron Courville"],"categories":null,"content":"’ \u0026#39;\n","date":1591142400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1591142400,"objectID":"2a7557fb13bff66c98a7a2cb850dfa14","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/pedroo.pinheirounsuneurips2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/pedroo.pinheirounsuneurips2020/","section":"publication","summary":"Contrastive self-supervised learning has emerged as a promising approach to unsupervised visual representation learning. In general, these methods learn global (image-level) representations that are invariant to different views (i.e., compositions of data augmentation) of the same image. However, many visual understanding tasks require dense (pixel-level) representations. In this paper, we propose View-Agnostic Dense Representation (VADeR) for unsupervised learning of dense representations. VADeR learns pixelwise representations by forcing local features to remain constant over different viewing conditions. Specifically, this is achieved through pixel-level contrastive learning: matching features (that is, features that describes the same location of the scene on different views) should be close in an embedding space, while non-matching features should be apart. VADeR provides a natural representation for dense prediction tasks and transfers well to downstream tasks. Our method outperforms ImageNet supervised pretraining (and strong unsupervised baselines) in multiple dense prediction tasks.","tags":["Unsupervised Learning","Representation Learning"],"title":"Unsupervised Learning of Dense Visual Representations","type":"publication"},{"authors":["Faizy Ahsan","Alexandre Drouin","François Laviolette","Doina Precup","Mathieu Blanchette"],"categories":null,"content":"’ \u0026#39;\n","date":1587772800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1587772800,"objectID":"41221e030b60a8223975529f63483232","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/faizyahsanphylieeebibm2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/faizyahsanphylieeebibm2020/","section":"publication","summary":"The computational prediction of transcription factor binding sites remains a challenging problems in bioinformatics, despite significant methodological developments from the field of machine learning. Such computational models are essential to help interpret the non-coding portion of human genomes, and to learn more about the regulatory mechanisms controlling gene expression. In parallel, massive genome sequencing efforts have produced assembled genomes for hundred of vertebrate species, but this data is underused. We present PhyloReg, a new semi-supervised learning approach that can be used for a wide variety of sequence-to-function prediction problems, and that takes advantage of hundreds of millions of years of evolution to regularize predictors and improve accuracy. We demonstrate that PhyloReg can be used to better train a previously proposed deep learning model of transcription factor binding. Simulation studies further help delineate the benefits of the a pproach. G ains in prediction accuracy are obtained over a broad set of transcription factors and cell types.","tags":["Bioinformatics","Data Augmentation","Deep Learning","Graphs","Transfer Learning"],"title":"Phylogenetic Manifold Regularization: a semi-supervised approach to predict transcription factor binding sites","type":"publication"},{"authors":["Pau Rodriguez","Issam H. Laradji","Alexandre Drouin","Alexandre Lacoste"],"categories":null,"content":"’ \u0026#39;\n","date":1583366400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1583366400,"objectID":"368223d8217a8f59e962302fb51eff6b","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/paurodriguezembeeccv2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/paurodriguezembeeccv2020/","section":"publication","summary":"Few-shot classification is challenging because the data distribution of the training set can be widely different to the test set as their classes are disjoint. This distribution shift often results in poor generalization. Manifold smoothing has been shown to address the distribution shift problem by extending the decision boundaries and reducing the noise of the class representations. Moreover, manifold smoothness is a key factor for semi-supervised learning and transductive learning algorithms. In this work, we propose to use embedding propagation as an unsupervised non-parametric regularizer for manifold smoothing in few-shot classification. Embedding propagation leverages interpolations between the extracted features of a neural network based on a similarity graph. We empirically show that embedding propagation yields a smoother embedding manifold. We also show that applying embedding propagation to a transductive classifier achieves new state-of-the-art results in mini-Imagenet, tiered-Imagenet, Imagenet-FS, and CUB. Furthermore, we show that embedding propagation consistently improves the accuracy of the models in multiple semi-supervised learning scenarios by up to 16\\% points. The proposed embedding propagation operation can be easily integrated as a non-parametric layer into a neural network. We provide the training code and usage examples at this https URL.","tags":["Computer Vision","Image Classification","Few-shot Learning"],"title":"Embedding Propagation: Smoother Manifold for Few-Shot Classification","type":"publication"},{"authors":["Jonathan Frankle","Gintare Karolina Dziugaite","Daniel M. Roy","Michael Carbin"],"categories":null,"content":"’ \u0026#39;\n","date":1582156800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1582156800,"objectID":"f137ec0871132c58cc1fc62c6f04672b","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/jonathanfranklelineicml2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/jonathanfranklelineicml2020/","section":"publication","summary":"We study whether a neural network optimizes to the same, linearly connected minimum under different samples of SGD noise (e.g., random data order and augmentation). We find that standard vision models become stable to SGD noise in this way early in training. From then on, the outcome of optimization is determined to a linearly connected region. We use this technique to study iterative magnitude pruning (IMP), the procedure used by work on the lottery ticket hypothesis to identify subnetworks that could have trained in isolation to full accuracy. We find that these subnetworks only reach full accuracy when they are stable to SGD noise, which either occurs at initialization for small-scale settings (MNIST) or early in training for large-scale settings (ResNet-50 and Inception-v3 on ImageNet).","tags":["Guarranties"],"title":"Linear Mode Connectivity and the Lottery Ticket Hypothesis","type":"publication"},{"authors":["Issam H. Laradji","Rafael Pardinas","Pau Rodriguez","David Vazquez"],"categories":null,"content":"’ \u0026#39;\n","date":1581033600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1581033600,"objectID":"9670565ed0e26cc4408761df85762206","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/issamh.laradjiloocicip2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/issamh.laradjiloocicip2020/","section":"publication","summary":"Acquiring count annotations generally requires less human effort than point-level and bounding box annotations. Thus, we propose the novel problem setup of localizing objects in dense scenes under this weaker supervision. We propose LOOC, a method to Localize Overlapping Objects with Count supervision. We train LOOC by alternating between two stages. In the first stage, LOOC learns to generate pseudo point-level annotations in a semi-supervised manner. In the second stage, LOOC uses a fully-supervised localization method that trains on these pseudo labels. The localization method is used to progressively improve the quality of the pseudo labels. We conducted experiments on popular counting datasets. For localization, LOOC achieves a strong new baseline in the novel problem setup where only count supervision is available. For counting, LOOC outperforms current state-of-the-art methods that only use count as their supervision. Code is available at: this https URL.","tags":["Object Localization","Computer Vision","Weak Supervision"],"title":"LOOC: Localize Overlapping Objects with Count Supervision","type":"publication"},{"authors":["Issam H. Laradji","Negar Rostamzadeh","Pedro O. Pinheiro","David Vazquez","Mark Schmidt"],"categories":null,"content":"’ \u0026#39;\n","date":1581033600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1581033600,"objectID":"ecf349ea8abeb9b4e8d1b99cdd940464","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/issamh.laradjipropicip2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/issamh.laradjipropicip2020/","section":"publication","summary":"Instance segmentation methods often require costly per-pixel labels. We propose a method called WISE-Net that only requires point-level annotations. During training, the model only has access to a single pixel label per object, yet the task is to output full segmentation masks. To address this challenge, we construct a network with two branches: (1) a 10-calization network (L-Net) that predicts the location of each object; and (2) an embedding network (E-Net) that learns an embedding space where pixels of the same object are close. The segmentation masks for the located objects are obtained by grouping pixels with similar embeddings. We evaluate our approach on PASCAL VOC, COCO, KITTI and CityScapes datasets. The experiments show that our method (1) obtains competitive results compared to fully-supervised methods in certain scenarios; (2) outperforms fully-and weakly-supervised methods with a fixed annotation budget; and (3) establishes a first strong baseline for instance segmentation with point-level supervision.","tags":["Computer Vision","Instance Segmentation","Weak Supervision"],"title":"Proposal-based Instance Segmentation with Point Supervision","type":"publication"},{"authors":["Jae Hyun Lim","Aaron Courville","Christopher Pal","Chin-Wei Huang"],"categories":null,"content":"’ \u0026#39;\n","date":1580947200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1580947200,"objectID":"c539b94407c1f096d30a32704863c18b","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/jaehyunlimar-dicml2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/jaehyunlimar-dicml2020/","section":"publication","summary":"Entropy is ubiquitous in machine learning, but it is in general intractable to compute the entropy of the distribution of an arbitrary continuous random variable. In this paper, we propose the amortized residual denoising autoencoder (AR-DAE) to approximate the gradient of the log density function, which can be used to estimate the gradient of entropy. Amortization allows us to significantly reduce the error of the gradient approximator by approaching asymptotic optimality of a regular DAE, in which case the estimation is in theory unbiased. We conduct theoretical and experimental analyses on the approximation error of the proposed method, as well as extensive studies on heuristics to ensure its robustness. Finally, using the proposed gradient approximator to estimate the gradient of entropy, we demonstrate state-of-the-art performance on density estimation with variational autoencoders and continuous control with soft actor-critic.","tags":["Optimization"],"title":"AR-DAE: Towards Unbiased Neural Entropy Gradient Estimation","type":"publication"},{"authors":["Massimo Caccia","Pau Rodriguez","Oleksiy Ostapenko","Fabrice Normandin","Min Lin","Lucas Caccia","Issam H. Laradji","Irina Rish","Alexandre Lacoste","David Vazquez","Laurent Charlin"],"categories":null,"content":"’ \u0026#39;\n","date":1580947200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1580947200,"objectID":"4b25e91e8c47e2376d4cdbf57d9deb3d","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/massimocacciaonlineurips2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/massimocacciaonlineurips2020/","section":"publication","summary":"Continual learning studies agents that learn from streams of tasks without forgetting previous ones while adapting to new ones. Two recent continual-learning scenarios have opened new avenues of research. In meta-continual learning, the model is pre-trained to minimize catastrophic forgetting of previous tasks. In continual-meta learning, the aim is to train agents for faster remembering of previous tasks through adaptation. In their original formulations, both methods have limitations. We stand on their shoulders to propose a more general scenario, OSAKA, where an agent must quickly solve new (out-of-distribution) tasks, while also requiring fast remembering. We show that current continual learning, meta-learning, meta-continual learning, and continual-meta learning techniques fail in this new scenario. We propose Continual-MAML, an online extension of the popular MAML algorithm as a strong baseline for this scenario. We empirically show that Continual-MAML is better suited to the new scenario than the aforementioned methodologies, as well as standard continual learning and meta-learning approaches.","tags":["Continual Learning","Dataset"],"title":"Online Fast Adaptation and Knowledge Accumulation: a New Approach to Continual Learning","type":"publication"},{"authors":["Jeffrey Negrea","Gintare Karolina Dziugaite","Daniel M. Roy"],"categories":null,"content":"’ \u0026#39;\n","date":1580428800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1580428800,"objectID":"a3f9accfcf7a4c99909c67143392ea50","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/jeffreynegreaindeicml2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/jeffreynegreaindeicml2020/","section":"publication","summary":"We propose to study the generalization error of a learned predictor ĥ in terms of that of a surrogate (potentially randomized) predictor that is coupled to ĥ and designed to trade empirical risk for control of generalization error. In the case where ĥ interpolates the data, it is interesting to consider theoretical surrogate classifiers that are partially derandomized or rerandomized, e.g., fit to the training data but with modified label noise. We also show that replacing ĥ by its conditional distribution with respect to an arbitrary σ-field is a convenient way to derandomize. We study two examples, inspired by the work of Nagarajan and Kolter (2019) and Bartlett et al. (2019), where the learned classifier ĥ interpolates the training data with high probability, has small risk, and, yet, does not belong to a nonrandom class with a tight uniform bound on two-sided generalization error. At the same time, we bound the risk of ĥ in terms of surrogates constructed by conditioning and denoising, respectively, and shown to belong to nonrandom classes with uniformly small generalization error.","tags":["Guarranties"],"title":"In Defense of Uniform Convergence: Generalization via derandomization with an application to interpolating predictors","type":"publication"},{"authors":["Bahare Fatemi","Perouz Taslakian","David Vazquez","David Poole"],"categories":null,"content":"’ \u0026#39;\n","date":1579564800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1579564800,"objectID":"04fdd069ce47d8729caecc9d416d678f","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/baharefatemiknowijcai2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/baharefatemiknowijcai2020/","section":"publication","summary":"Knowledge graphs store facts using relations between two entities. In this work, we address the question of link prediction in knowledge hypergraphs where relations are defined on any number of entities. While techniques exist (such as reification) that convert non-binary relations into binary ones, we show that current embedding-based methods for knowledge graph completion do not work well out of the box for knowledge graphs obtained through these techniques. To overcome this, we introduce HSimplE and HypE, two embedding-based methods that work directly with knowledge hypergraphs. In both models, the prediction is a function of the relation embedding, the entity embeddings and their corresponding positions in the relation. We also develop public datasets, benchmarks and baselines for hypergraph prediction and show experimentally that the proposed models are more effective than the baselines.","tags":["Knowledge Graphs","Graphs"],"title":"Knowledge Hypergraphs: Prediction Beyond Binary Relations","type":"publication"},{"authors":["Alzayat Saleh","Issam H. Laradji","Dmitry A Konovalov","Michael Bradley","David Vazquez","Marcus Sheaves"],"categories":null,"content":"’ \u0026#39;\n","date":1578096000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1578096000,"objectID":"0ff9ae40d5cd78576a956d19a084e38d","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/alzayatsalehareanaturesr2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/alzayatsalehareanaturesr2021/","section":"publication","summary":"Visual analysis of complex fish habitats is an important step towards sustainable fisheries for human consumption and environmental protection. Deep Learning methods have shown great promise for scene analysis when trained on large-scale datasets. However, current datasets for fish analysis tend to focus on the classification task within constrained, plain environments which do not capture the complexity of underwater fish habitats. To address this limitation, we present DeepFish as a benchmark suite with a large-scale dataset to train and test methods for several computer vision tasks. The dataset consists of approximately 40 thousand images collected underwater from 20 habitats in the marine-environments of tropical Australia. The dataset originally contained only classification labels. Thus, we collected point-level and segmentation labels to have a more comprehensive fish analysis benchmark. These labels enable models to learn to automatically monitor fish count, identify their locations, and estimate their sizes. Our experiments provide an in-depth analysis of the dataset characteristics, and the performance evaluation of several state-of-the-art approaches based on our benchmark. Although models pre-trained on ImageNet have successfully performed on this benchmark, there is still room for improvement. Therefore, this benchmark serves as a testbed to motivate further development in this challenging domain of underwater computer vision.","tags":["Computer Vision","Dataset","Localization","Semantic Segmentation"],"title":"A realistic fish-habitat dataset to evaluate algorithms for underwater visual analysis","type":"publication"},{"authors":["Massimo Caccia","Pau Rodriguez","Oleksiy Ostapenko","Fabrice Normandin","Min Lin","Lucas Caccia","Issam H. Laradji","Irina Rish","Alexandre Lacoste","David Vazquez","Laurent Charlin"],"categories":null,"content":"’ \u0026#39;\n","date":1573776000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1573776000,"objectID":"ad6ae44dccfc1e4adb9d65e4af41b0bd","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/massimocacciaonlicvprworkshops2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/massimocacciaonlicvprworkshops2020/","section":"publication","summary":"Continual learning studies agents that learn from streams of tasks without forgetting previous ones while adapting to new ones. Two recent continual-learning scenarios have opened new avenues of research. In meta-continual learning, the model is pre-trained to minimize catastrophic forgetting of previous tasks. In continual-meta learning, the aim is to train agents for faster remembering of previous tasks through adaptation. In their original formulations, both methods have limitations. We stand on their shoulders to propose a more general scenario, OSAKA, where an agent must quickly solve new (out-of-distribution) tasks, while also requiring fast remembering. We show that current continual learning, meta-learning, meta-continual learning, and continual-meta learning techniques fail in this new scenario. We propose Continual-MAML, an online extension of the popular MAML algorithm as a strong baseline for this scenario. We empirically show that Continual-MAML is better suited to the new scenario than the aforementioned methodologies, as well as standard continual learning and meta-learning approaches.","tags":["Continual Learning"],"title":"Online Fast Adaptation and Knowledge Accumulation: a New Approach to Continual Learning","type":"publication"},{"authors":["Si Yi Meng","Sharan Vaswani","Issam H. Laradji","Mark Schmidt","Simon Lacoste-Julien"],"categories":null,"content":"’ \u0026#39;\n","date":1570579200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1570579200,"objectID":"1f0d075553d45afc7b14d0b5ccae1bfb","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/siyimengfastaistats2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/siyimengfastaistats2020/","section":"publication","summary":"We consider stochastic second-order methods for minimizing smooth and strongly-convex functions under an interpolation condition satisfied by over-parameterized models. Under this condition, we show that the regularized subsampled Newton method (R-SSN) achieves global linear convergence with an adaptive step-size and a constant batch-size. By growing the batch size for both the subsampled gradient and Hessian, we show that R-SSN can converge at a quadratic rate in a local neighbourhood of the solution. We also show that R-SSN attains local linear convergence for the family of self-concordant functions. Furthermore, we analyze stochastic BFGS algorithms in the interpolation setting and prove their global linear convergence. We empirically evaluate stochastic L-BFGS and a \"Hessian-free\" implementation of R-SSN for binary classification on synthetic, linearly-separable datasets and real datasets under a kernel mapping. Our experimental results demonstrate the fast convergence of these methods, both in terms of the number of iterations and wall-clock time.","tags":["Optimization"],"title":"Fast and Furious Convergence: Stochastic Second Order Methods under Interpolation","type":"publication"},{"authors":["Elnaz Barshan","Marc-Etienne Brunet ","Gintare Karolina Dziugaite"],"categories":null,"content":"’ \u0026#39;\n","date":1570579200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1570579200,"objectID":"3cce95f90020331fe0f4c9f07bc78993","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/elnazbarshanrelaaistats2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/elnazbarshanrelaaistats2020/","section":"publication","summary":"In this work, we focus on the use of influence functions to identify relevant training examples that one might hope \"explain\" the predictions of a machine learning model. One shortcoming of influence functions is that the training examples deemed most \"influential\" are often outliers or mislabelled, making them poor choices for explanation. In order to address this shortcoming, we separate the role of global versus local influence. We introduce RelatIF, a new class of criteria for choosing relevant training examples by way of an optimization objective that places a constraint on global influence. RelatIF considers the local influence that an explanatory example has on a prediction relative to its global effects on the model. In empirical evaluations, we find that the examples returned by RelatIF are more intuitive when compared to those found using influence functions.","tags":["Explainability"],"title":"RelatIF: Identifying Explanatory Training Examples via Relative Influence","type":"publication"},{"authors":["Chin-Wei Huang","Ahmed Touati","Pascal Vincent","Gintare Karolina Dziugaite","Alexandre Lacoste","Aaron Courville"],"categories":null,"content":"’ \u0026#39;\n","date":1570579200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1570579200,"objectID":"42c029d828012788170a10e778fd4231","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/chin-weihuangstocaistats2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/chin-weihuangstocaistats2020/","section":"publication","summary":"Recent advances in variational inference enable the modelling of highly structured joint distributions, but are limited in their capacity to scale to the high-dimensional setting of stochastic neural networks. This limitation motivates a need for scalable parameterizations of the noise generation process, in a manner that adequately captures the dependencies among the various parameters. In this work, we address this need and present the Kronecker Flow, a generalization of the Kronecker product to invertible mappings designed for stochastic neural networks. We apply our method to variational Bayesian neural networks on predictive tasks, PAC-Bayes generalization bound estimation, and approximate Thompson sampling in contextual bandits. In all setups, our methods prove to be competitive with existing methods and better than the baselines.","tags":null,"title":"Stochastic Neural Network with Kronecker Flow","type":"publication"},{"authors":["Hugo Berard","Gauthier Gidel","Amjad Almahairi","Pascal Vincent","Simon Lacoste-Julien"],"categories":null,"content":"’ \u0026#39;\n","date":1569369600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1569369600,"objectID":"ae609066e33efaae48537747d5fcb3d8","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/hugoberardacloiclr2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/hugoberardacloiclr2020/","section":"publication","summary":"Generative adversarial networks have been very successful in generative modeling, however they remain relatively challenging to train compared to standard deep neural networks. In this paper, we propose new visualization techniques for the optimization landscapes of GANs that enable us to study the game vector field resulting from the concatenation of the gradient of both players. Using these visualization techniques we try to bridge the gap between theory and practice by showing empirically that the training of GANs exhibits significant rotations around Local Stable Stationary Points (LSSP), similar to the one predicted by theory on toy examples. Moreover, we provide empirical evidence that GAN training converge to a stable stationary point which is a saddle point for the generator loss, not a minimum, while still achieving excellent performance.","tags":["Optimization","Unsupervised Learning","GANs"],"title":"A Closer Look at the Optimization Landscapes of Generative Adversarial Networks","type":"publication"},{"authors":["Christian Rupprecht","Cyril Ibrahim","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1569369600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1569369600,"objectID":"f305660c0b80c9c9c69199a68a480e31","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/christianrupprechtfindiclr2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/christianrupprechtfindiclr2020/","section":"publication","summary":"As deep reinforcement learning driven by visual perception becomes more widely used there is a growing need to better understand and probe the learned agents. Understanding the decision making process and its relationship to visual inputs can be very valuable to identify problems in learned behavior. However, this topic has been relatively under-explored in the research community. In this work we present a method for synthesizing visual inputs of interest for a trained agent. Such inputs or states could be situations in which specific actions are necessary. Further, critical states in which a very high or a very low reward can be achieved are often interesting to understand the situational awareness of the system as they can correspond to risky states. To this end, we learn a generative model over the state space of the environment and use its latent space to optimize a target function for the state of interest. In our experiments we show that this method can generate insights for a variety of environments and reinforcement learning methods. We explore results in the standard Atari benchmark games as well as in an autonomous driving simulator. Based on the efficiency with which we have been able to identify behavioural weaknesses with this technique, we believe this general approach could serve as an important tool for AI safety applications.","tags":["Reinforcement Learning"],"title":"Finding and Visualizing Weaknesses of Deep Reinforcement Learning Agents","type":"publication"},{"authors":["Philippe Brouillard","Alexandre Drouin","Sébastien Lachapelle","Alexandre Lacoste","Simon Lacoste-Julien"],"categories":null,"content":"’ \u0026#39;\n","date":1569369600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1569369600,"objectID":"c4994446ace4157544cdbeb5db8a260e","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/philippebrouillardgradiclrworkshops2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/philippebrouillardgradiclrworkshops2020/","section":"publication","summary":"Decision making based on statistical association alone can be a dangerous en- deavor due to non-causal associations. Ideally, one would rely on causal rela- tionships that enable reasoning about the effect of interventions. Several methods have been proposed to discover such relationships from observational and inter- ventional data. Among them, GraN-DAG, a method that relies on the constrained optimization of neural networks, was shown to produce state-of-the-art results among algorithms relying purely on observational data. However, it is limited to observational data and cannot make use of interventions. In this work, we extend GraN-DAG to support interventional data and show that this improves its ability to infer causal structures.","tags":["Interventions","Causal Discovery","Causality","Differentiable Optimization"],"title":"Gradient-Based Neural DAG Learning with Interventions","type":"publication"},{"authors":["Arantxa Casanova","Pedro O. Pinheiro","Negar Rostamzadeh","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1569369600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1569369600,"objectID":"ba7094233d0ad3e65082a16023119ba0","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/arantxacasanovareiniclr2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/arantxacasanovareiniclr2020/","section":"publication","summary":"Learning-based approaches for semantic segmentation have two inherent challenges. First, acquiring pixel-wise labels is expensive and time-consuming. Second, realistic segmentation datasets are highly unbalanced: some categories are much more abundant than others, biasing the performance to the most represented ones. In this paper, we are interested in focusing human labelling effort on a small subset of a larger pool of data, minimizing this effort while maximizing performance of a segmentation model on a hold-out set. We present a new active learning strategy for semantic segmentation based on deep reinforcement learning (RL). An agent learns a policy to select a subset of small informative image regions -- opposed to entire images -- to be labeled, from a pool of unlabeled data. The region selection decision is made based on predictions and uncertainties of the segmentation model being trained. Our method proposes a new modification of the deep Q-network (DQN) formulation for active learning, adapting it to the large-scale nature of semantic segmentation problems. We test the proof of concept in CamVid and provide results in the large-scale dataset Cityscapes. On Cityscapes, our deep RL region-based DQN approach requires roughly 30% less additional labeled data than our most competitive baseline to reach the same performance. Moreover, we find that our method asks for more labels of under-represented categories compared to the baselines, improving their performance and helping to mitigate class imbalance.","tags":["Reinforcement Learning","Active Learning","Semantic Segmentation"],"title":"Reinforced Active Learning for Image Segmentation","type":"publication"},{"authors":["Anirudh Goyal","Yoshua Bengio","Matthew Botvinick","Sergey Levine"],"categories":null,"content":"’ \u0026#39;\n","date":1569369600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1569369600,"objectID":"50875ce73009b402fb517d27c24e317c","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/anirudhgoyaltheviclr2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/anirudhgoyaltheviclr2020/","section":"publication","summary":"In many applications, it is desirable to extract only the relevant information from complex input data, which involves making a decision about which input features are relevant. The information bottleneck method formalizes this as an information- theoretic optimization problem by maintaining an optimal tradeoff between com- pression (throwing away irrelevant input information), and predicting the target. In many problem settings, including the reinforcement learning problems we consider in this work, we might prefer to compress only part of the input. This is typically the case when we have a standard conditioning input, such as a state observation, and a “privileged” input, which might correspond to the goal of a task, the output of a costly planning algorithm, or communication with another agent. In such cases, we might prefer to compress the privileged input, either to achieve better gener- alization (e.g., with respect to goals) or to minimize access to costly information (e.g., in the case of communication). Practical implementations of the information bottleneck based on variational inference require access to the privileged input in order to compute the bottleneck variable, so although they perform compression, this compression operation itself needs unrestricted, lossless access. In this work, we propose the variational bandwidth bottleneck, which decides for each example on the estimated value of the privileged information before seeing it, i.e., only based on the standard input, and then accordingly chooses stochastically, whether to access the privileged input or not. We formulate a tractable approximation to this framework and demonstrate in a series of reinforcement learning experiments that it can improve generalization and reduce access to computationally costly information.","tags":null,"title":"The Variational Bandwidth Bottleneck: Stochastic Evaluation on an Information Budget","type":"publication"},{"authors":["Bahare Fatemi","Perouz Taslakian","David Vazquez","David Poole"],"categories":null,"content":"’ \u0026#39;\n","date":1567641600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1567641600,"objectID":"e6fc43c200f5d86f6879cadf60a3fea8","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/baharefatemiknowaaaiworkshops2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/baharefatemiknowaaaiworkshops2020/","section":"publication","summary":"Knowledge graphs store facts using relations between two entities. In this work, we address the question of link prediction in knowledge hypergraphs where relations are defined on any number of entities. While techniques exist (such as reification) that convert non-binary relations into binary ones, we show that current embedding-based methods for knowledge graph completion do not work well out of the box for knowledge graphs obtained through these techniques. To overcome this, we introduce HSimplE and HypE, two embedding-based methods that work directly with knowledge hypergraphs. In both models, the prediction is a function of the relation embedding, the entity embeddings and their corresponding positions in the relation. We also develop public datasets, benchmarks and baselines for hypergraph prediction and show experimentally that the proposed models are more effective than the baselines.","tags":["Knowledge Graphs","Graphs"],"title":"Knowledge Hypergraphs: Prediction Beyond Binary Relations","type":"publication"},{"authors":["Sandeep Subramanian","Raymond Li","Jonathan Pilault","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1567641600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1567641600,"objectID":"ee9dcada9f83bc0a36212b17b0cd12bf","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/sandeepsubramanianonexemnlp2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/sandeepsubramanianonexemnlp2020/","section":"publication","summary":"We present a method to produce abstractive summaries of long documents that exceed several thousand words via neural abstractive summarization. We perform a simple extractive step before generating a summary, which is then used to condition the transformer language model on relevant information before being tasked with generating a summary. We show that this extractive step significantly improves summarization results. We also show that this approach produces more abstractive summaries compared to prior work that employs a copy mechanism while still achieving higher rouge scores. Note: The abstract above was not written by the authors, it was generated by one of the models presented in this paper.","tags":["Natural Language Processing","Summarization","Transformers"],"title":"On Extractive and Abstractive Neural Document Summarization with Transformer Language Models","type":"publication"},{"authors":["Jonathan Frankle","Gintare Karolina Dziugaite","Daniel M. Roy","Michael Carbin"],"categories":null,"content":"’ \u0026#39;\n","date":1567641600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1567641600,"objectID":"26dc21980742088bb02fdaf363b566f6","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/jonathanfranklestabaaai2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/jonathanfranklestabaaai2020/","section":"publication","summary":"Pruning is a well-established technique for removing unnecessary structure from neural networks after training to improve the performance of inference. Several recent results have explored the possibility of pruning at initialization time to provide similar benefits during training. In particular, the \"lottery ticket hypothesis\" conjectures that typical neural networks contain small subnetworks that can train to similar accuracy in a commensurate number of steps. The evidence for this claim is that a procedure based on iterative magnitude pruning (IMP) reliably finds such subnetworks retroactively on small vision tasks. However, IMP fails on deeper networks, and proposed methods to prune before training or train pruned networks encounter similar scaling limitations. In this paper, we argue that these efforts have struggled on deeper networks because they have focused on pruning precisely at initialization. We modify IMP to search for subnetworks that could have been obtained by pruning early in training (0.1% to 7% through) rather than at iteration 0. With this change, it finds small subnetworks of deeper networks (e.g., 80% sparsity on Resnet-50) that can complete the training process to match the accuracy of the original network on more challenging tasks (e.g., ImageNet). In situations where IMP fails at iteration 0, the accuracy benefits of delaying pruning accrue rapidly over the earliest iterations of training. To explain these behaviors, we study subnetwork \"stability,\" finding that - as accuracy improves in this fashion - IMP subnetworks train to parameters closer to those of the full network and do so with improved consistency in the face of gradient noise. These results offer new insights into the opportunity to prune large-scale networks early in training and the behaviors underlying the lottery ticket hypothesis","tags":["Guarranties"],"title":"Stabilizing the Lottery Ticket Hypothesis","type":"publication"},{"authors":["Kris Y. Hong","Pedro O. Pinheiro","Laura Minet","Marianne Hatzopoulou","Scott Weichenthal"],"categories":null,"content":"’ \u0026#39;\n","date":1567209600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1567209600,"objectID":"3425d25a423b041bec0fc1dd24cb3844","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/krisy.hongextejes2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/krisy.hongextejes2019/","section":"publication","summary":"We paired existing land use regression (LUR) models for ambient ultrafine particles in Montreal and Toronto, Canada with satellite images and deep convolutional neural networks as a means of extending the spatial coverage of these models. Our findings demonstrate that this method can be used to expand the spatial scale of LUR models, thus providing exposure estimates for larger populations. The cost of this approach is a small loss in precision as the training data are themselves modelled values.","tags":["Remote Sensing"],"title":"Extending the Spatial Scale of Land Use Regression Models for Ambient Ultrafine Particles using Satellite Images and Deep Convolutional Neural Networks","type":"publication"},{"authors":["Lironne Kurzman","David Vazquez","Issam H. Laradji"],"categories":null,"content":"’ \u0026#39;\n","date":1565827200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1565827200,"objectID":"2c6252c9ec847c297c2d7be76a0996af","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/lironnekurzmanclaswiml2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/lironnekurzmanclaswiml2019/","section":"publication","summary":"We propose a Class-Based Styling method (CBS) that can map different styles for different object classes in real-time. CBS achieves real-time performance by carrying out two steps simultaneously. While a semantic segmentation method is used to obtain the mask of each object class in a video frame, a styling method is used to style that frame globally. Then an object class can be styled by combining the segmentation mask and the styled image. The user can also select multiple styles so that different object classes can have different styles in a single frame. For semantic segmentation, we leverage DABNet that achieves high accuracy, yet only has 0.76 million parameters and runs at 104 FPS. For the style transfer step, we use a popular real-time method proposed by Johnson et al. [7]. We evaluated CBS on a video of the CityScapes dataset and observed high-quality localized style transfer results for different object classes and real-time performance.","tags":["Computer Vision","Style Transfer","Semantic Segmentation"],"title":"Class-Based Styling: Real-time Localized Style Transfer with Semantic Segmentation","type":"publication"},{"authors":["Bahare Fatemi","Perouz Taslakian","David Vazquez","David Poole"],"categories":null,"content":"’ \u0026#39;\n","date":1565827200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1565827200,"objectID":"0dd107baf85f5f149b6b013a755aa35c","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/baharefatemiknowwiml2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/baharefatemiknowwiml2019/","section":"publication","summary":"Knowledge graphs store facts using relations between two entities. In this work, we address the question of link prediction in knowledge hypergraphs where relations are defined on any number of entities. While techniques exist (such as reification) that convert non-binary relations into binary ones, we show that current embedding-based methods for knowledge graph completion do not work well out of the box for knowledge graphs obtained through these techniques. To overcome this, we introduce HSimplE and HypE, two embedding-based methods that work directly with knowledge hypergraphs. In both models, the prediction is a function of the relation embedding, the entity embeddings and their corresponding positions in the relation. We also develop public datasets, benchmarks and baselines for hypergraph prediction and show experimentally that the proposed models are more effective than the baselines.","tags":["Knowledge Graphs","Graphs"],"title":"Knowledge Hypergraphs: Prediction Beyond Binary Relations","type":"publication"},{"authors":["Jonathan Frankle","Gintare Karolina Dziugaite","Daniel M. Roy","Michael Carbin"],"categories":null,"content":"’ \u0026#39;\n","date":1565827200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1565827200,"objectID":"2eb3749db9f21bc6106ed8bcc36b682d","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/jonathanfranklelinewiml2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/jonathanfranklelinewiml2019/","section":"publication","summary":"We study whether a neural network optimizes to the same, linearly connected minimum under different samples of SGD noise (e.g., random data order and augmentation). We find that standard vision models become stable to SGD noise in this way early in training. From then on, the outcome of optimization is determined to a linearly connected region. We use this technique to study iterative magnitude pruning (IMP), the procedure used by work on the lottery ticket hypothesis to identify subnetworks that could have trained in isolation to full accuracy. We find that these subnetworks only reach full accuracy when they are stable to SGD noise, which either occurs at initialization for small-scale settings (MNIST) or early in training for large-scale settings (ResNet-50 and Inception-v3 on ImageNet).","tags":["Guarranties"],"title":"Linear Mode Connectivity and the Lottery Ticket Hypothesis","type":"publication"},{"authors":["Kyle Hsu","Waseem Gharbieh","Daniel M. Roy","Gintare Karolina Dziugaite"],"categories":null,"content":"’ \u0026#39;\n","date":1565827200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1565827200,"objectID":"e8b174228a16a4cee77be42a6ad9e0ac","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/kylehsuoptiwiml2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/kylehsuoptiwiml2019/","section":"publication","summary":"’ '","tags":null,"title":"Optimal PAC-Bayes bounds require distribution- and data-dependent priors","type":"publication"},{"authors":["Bhairav Mehta","Manfred Diaz","Florian Golemo","Christopher Pal","Liam Paull"],"categories":null,"content":"’ \u0026#39;\n","date":1562457600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1562457600,"objectID":"ddb45983158eef6d8b3c4bed97dc25b0","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/bhairavmehtaacticorl2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/bhairavmehtaacticorl2019/","section":"publication","summary":"Domain randomization is a popular technique for improving domain transfer, often used in a zero-shot setting when the target domain is unknown or cannot easily be used for training. In this work, we empirically examine the effects of domain randomization on agent generalization. Our experiments show that domain randomization may lead to suboptimal, high-variance policies, which we attribute to the uniform sampling of environment parameters. We propose Active Domain Randomization, a novel algorithm that learns a parameter sampling strategy. Our method looks for the most informative environment variations within the given randomization ranges by leveraging the discrepancies of policy rollouts in randomized and reference environment instances. We find that training more frequently on these instances leads to better overall agent generalization. Our experiments across various physics-based simulated and real-robot tasks show that this enhancement leads to more robust, consistent policies.","tags":["Active Learning","Domain Adaptation","Domain Randomization"],"title":"Active Domain Randomization","type":"publication"},{"authors":["Martin Weiss","Simon Chamorro","Roger Girgis","Margaux Luck","Samira Ebrahimi Kahou","Joseph P. Cohen","Derek Nowrouzezahrai","Doina Precup","Florian Golemo","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1562457600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1562457600,"objectID":"fca76e5cb30cfd70fd60bc57df215ef5","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/martinweisssevncorl2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/martinweisssevncorl2019/","section":"publication","summary":"Millions of blind and visually-impaired (BVI) people navigate urban environments every day, using smartphones for high-level path-planning and white canes or guide dogs for local information. However, many BVI people still struggle to travel to new places. In our endeavor to create a navigation assistant for the BVI, we found that existing Reinforcement Learning (RL) environments were unsuitable for the task. This work introduces SEVN, a sidewalk simulation environment and a neural network-based approach to creating a navigation agent. SEVN contains panoramic images with labels for house numbers, doors, and street name signs, and formulations for several navigation tasks. We study the performance of an RL algorithm (PPO) in this setting. Our policy model fuses multi-modal observations in the form of variable resolution images, visible text, and simulated GPS data to navigate to a goal door. We hope that this dataset, simulator, and experimental results will provide a foundation for further research into the creation of agents that can assist members of the BVI community with outdoor navigation.","tags":["Synthetic Data","Planning","Dataset"],"title":"SEVN: A Sidewalk Simulation Environment for Visual Navigation","type":"publication"},{"authors":["Jacob Leygonie","Jennifer She","Amjad Almahairi","Sai Rajeswar Mudumba","Aaron Courville"],"categories":null,"content":"’ \u0026#39;\n","date":1561334400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1561334400,"objectID":"8490efacb7c06f905e5f27d7ff423977","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/jacobleygonieadvearxiv2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/jacobleygonieadvearxiv2019/","section":"publication","summary":"Computing optimal transport maps between high-dimensional and continuous distributions is a challenging problem in optimal transport (OT). Generative adversarial networks (GANs) are powerful generative models which have been successfully applied to learn maps across high-dimensional domains. However, little is known about the nature of the map learned with a GAN objective. To address this problem, we propose a generative adversarial model in which the discriminator's objective is the 2-Wasserstein metric. We show that during training, our generator follows the W2-geodesic between the initial and the target distributions. As a consequence, it reproduces an optimal map at the end of training. We validate our approach empirically in both low-dimensional and high-dimensional continuous settings, and show that it outperforms prior methods on image data.","tags":["Unsupervised Learning","Adversarial Learning"],"title":"Adversarial Computation of Optimal Transport Maps","type":"publication"},{"authors":["Chen Xing","Negar Rostamzadeh","Boris N. Oreshkin","Pedro O. Pinheiro"],"categories":null,"content":"’ \u0026#39;\n","date":1558569600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1558569600,"objectID":"9d99eccffa02de56664b4d4e35053f19","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/chenxingadapneurips2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/chenxingadapneurips2019/","section":"publication","summary":"Metric-based meta-learning techniques have successfully been applied to few-shot classification problems. In this paper, we propose to leverage cross-modal information to enhance metric-based few-shot learning methods. Visual and semantic feature spaces have different structures by definition. For certain concepts, visual features might be richer and more discriminative than text ones. While for others, the inverse might be true. Moreover, when the support from visual information is limited in image classification, semantic representations (learned from unsupervised text corpora) can provide strong prior knowledge and context to help learning. Based on these two intuitions, we propose a mechanism that can adaptively combine information from both modalities according to new image categories to be learned. Through a series of experiments, we show that by this adaptive combination of the two modalities, our model outperforms current uni-modality few-shot learning methods and modality-alignment methods by a large margin on all benchmarks and few-shot scenarios tested. Experiments also show that our model can effectively adjust its focus on the two modalities. The improvement in performance is particularly large when the number of shots is very small.","tags":["Multi-modal Learning","Few-shot Learning"],"title":"Adaptive Cross-Modal Few-shot Learning","type":"publication"},{"authors":["Ousmane Amadou Dia"],"categories":null,"content":"’ \u0026#39;\n","date":1558569600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1558569600,"objectID":"944ded23402a975144bf7982c5491b5e","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/ousmaneamadoudiaadveneuripsworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/ousmaneamadoudiaadveneuripsworkshops2019/","section":"publication","summary":"’ '","tags":["Cybersecurity","Adversarial Learning"],"title":"Adversarial Functionality-Preserving Training in the Malware Domain","type":"publication"},{"authors":["Dzmitry Bahdanau","Harm de Vries","Timothy J. O'Donnell","Shikhar Murty","Philippe Beaudoin","Yoshua Bengio","Aaron Courville"],"categories":null,"content":"’ \u0026#39;\n","date":1558569600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1558569600,"objectID":"ee3776bd5936252f0bbce7090afa06c7","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/dzmitrybahdanauclosneuripsworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/dzmitrybahdanauclosneuripsworkshops2019/","section":"publication","summary":"The CLEVR dataset of natural-looking questions about 3D-rendered scenes has recently received much attention from the research community. A number of models have been proposed for this task, many of which achieved very high accuracies of around 97-99%. In this work, we study how systematic the generalization of such models is, that is to which extent they are capable of handling novel combinations of known linguistic constructs. To this end, we test models' understanding of referring expressions based on matching object properties (such as e.g. \"another cube that is the same size as the brown cube\") in novel contexts. Our experiments on the thereby constructed CLOSURE benchmark show that state-of-the-art models often do not exhibit systematicity after being trained on CLEVR. Surprisingly, we find that an explicitly compositional Neural Module Network model also generalizes badly on CLOSURE, even when it has access to the ground-truth programs at test time. We improve the NMN's systematic generalization by developing a novel Vector-NMN module architecture with vector-valued inputs and outputs. Lastly, we investigate how much few-shot transfer learning can help models that are pretrained on CLEVR to adapt to CLOSURE. Our few-shot learning experiments contrast the adaptation behavior of the models with intermediate discrete programs with that of the end-to-end continuous models.","tags":["Systematic Generalization"],"title":"CLOSURE: Assessing Systematic Generalization of CLEVR models","type":"publication"},{"authors":["Christopher Pal","Negar Rostamzadeh","Ying Zhang","Olexa Bilaniuk","Chiheb Trabelsi"],"categories":null,"content":"’ \u0026#39;\n","date":1558569600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1558569600,"objectID":"957c1ae6dc85a9e101b3a0bf79fd9b1f","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/christopherpaldeepneuripsworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/christopherpaldeepneuripsworkshops2019/","section":"publication","summary":"’ '","tags":null,"title":"Deep Complex Separators","type":"publication"},{"authors":["Jeffrey Negrea","Mahdi Haghifam","Gintare Karolina Dziugaite","Ashish Khisti","Daniel M. Roy"],"categories":null,"content":"’ \u0026#39;\n","date":1558569600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1558569600,"objectID":"51c20fcd7cefc6a5325dbb3ce656a04d","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/jeffreynegreainfoneurips2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/jeffreynegreainfoneurips2019/","section":"publication","summary":"In this work, we improve upon the stepwise analysis of noisy iterative learning algorithms initiated by Pensia, Jog, and Loh (2018) and recently extended by Bu, Zou, and Veeravalli (2019). Our main contributions are significantly improved mutual information bounds for Stochastic Gradient Langevin Dynamics via data-dependent estimates. Our approach is based on the variational characterization of mutual information and the use of data-dependent priors that forecast the mini-batch gradient based on a subset of the training samples. Our approach is broadly applicable within the information-theoretic framework of Russo and Zou (2015) and Xu and Raginsky (2017). Our bound can be tied to a measure of flatness of the empirical risk surface. As compared with other bounds that depend on the squared norms of gradients, empirical investigations show that the terms in our bounds are orders of magnitude smaller.","tags":["Guarranties"],"title":"Information-Theoretic Generalization Bounds for SGLD via Data-Dependent Estimates","type":"publication"},{"authors":["Rodrigo Toro Icarte","Ethan Waldie","Toryn Q. Klassen","Richard Valenzano","Margarita P. Castro","Sheila A. McIlraith"],"categories":null,"content":"’ \u0026#39;\n","date":1558569600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1558569600,"objectID":"20a1ebbdf0ae1d7a513a619841970273","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/rodrigotoroicartelearneurips2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/rodrigotoroicartelearneurips2019/","section":"publication","summary":"Reward Machines (RMs) provide a structured, automata-based representation of a reward function that enables a Reinforcement Learning (RL) agent to decompose an RL problem into structured subproblems that can be efficiently learned via off-policy learning. Here we show that RMs can be learned from experience, instead of being specified by the user, and that the resulting problem decomposition can be used to effectively solve partially observable RL problems. We pose the task of learning RMs as a discrete optimization problem where the objective is to find an RM that decomposes the problem into a set of subproblems such that the combination of their optimal memoryless policies is an optimal policy for the original problem. We show the effectiveness of this approach on three partially observable domains, where it significantly outperforms A3C, PPO, and ACER, and discuss its advantages, limitations, and broader potential.1","tags":["Reinforcement Learning"],"title":"Learning Reward Machines for Partially Observable Reinforcement Learning","type":"publication"},{"authors":["Eilif Muller","Philippe Beaudoin"],"categories":null,"content":"’ \u0026#39;\n","date":1558569600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1558569600,"objectID":"c06aba923245ea6c02c7a71ddfa5a0ee","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/eilifmullerneocneuripsworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/eilifmullerneocneuripsworkshops2019/","section":"publication","summary":"The fields of artificial intelligence and neuroscience have a long history of fertile bi-directional interactions. On the one hand, important inspiration for the development of artificial intelligence systems has come from the study of natural systems of intelligence, the mammalian neocortex in particular. On the other, important inspiration for models and theories of the brain have emerged from artificial intelligence research. A central question at the intersection of these two areas is concerned with the processes by which neocortex learns, and the extent to which they are analogous to the back-propagation training algorithm of deep networks. Matching the data efficiency, transfer and generalization properties of neocortical learning remains an area of active research in the field of deep learning. Recent advances in our understanding of neuronal, synaptic and dendritic physiology of the neocortex suggest new approaches for unsupervised representation learning, perhaps through a new class of objective functions, which could act alongside or in lieu of back-propagation. Such local learning rules have implicit rather than explicit objectives with respect to the training data, facilitating domain adaptation and generalization. Incorporating them into deep networks for representation learning could better leverage unlabelled datasets to offer significant improvements in data efficiency of downstream supervised readout learning, and reduce susceptibility to adversarial perturbations, at the cost of a more restricted domain of applicability.","tags":["Unsupervised Learning"],"title":"Neocortical plasticity: an unsupervised cake but no free lunch","type":"publication"},{"authors":["Jae Hyun Lim","Pedro O. Pinheiro","Negar Rostamzadeh","Christopher Pal","Sungjin Ahn"],"categories":null,"content":"’ \u0026#39;\n","date":1558569600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1558569600,"objectID":"9abaf6a54717ff419e5e202ffb506980","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/jaehyunlimneurneurips2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/jaehyunlimneurneurips2019/","section":"publication","summary":"For embodied agents to infer representations of the underlying 3D physical world they inhabit, they should efficiently combine multisensory cues from numerous trials, e.g., by looking at and touching objects. Despite its importance, multisensory 3D scene representation learning has received less attention compared to the unimodal setting. In this paper, we propose the Generative Multisensory Network (GMN) for learning latent representations of 3D scenes which are partially observable through multiple sensory modalities. We also introduce a novel method, called the Amortized Product-of-Experts, to improve the computational efficiency and the robustness to unseen combinations of modalities at test time. Experimental results demonstrate that the proposed model can efficiently infer robust modality-invariant 3D-scene representations from arbitrary combinations of modalities and perform accurate cross-modal generation. To perform this exploration, we also develop the Multisensory Embodied 3D-Scene Environment (MESE).","tags":["Multi-modal Learning"],"title":"Neural Multisensory Scene Inference","type":"publication"},{"authors":["Lachlan Kermode","Jan Freyberg","Alican Akturk","Robert Trafford","Denis Kochetkov","Rafael Pardinas","Eyal Weizman","Julien Cornebise"],"categories":null,"content":"’ \u0026#39;\n","date":1558569600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1558569600,"objectID":"01dd8b718f012d44bd1ac0e1959f9ec0","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/lachlankermodeobjeneuripsworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/lachlankermodeobjeneuripsworkshops2019/","section":"publication","summary":"We introduce a machine learning workflow to search for, identify, and meaningfully triage videos and images of munitions, weapons, and military equipment, even when limited training data exists for the object of interest. This workflow is designed to expedite the work of OSINT (\"open source intelligence\") researchers in human rights investigations. It consists of three components: automatic rendering and annotating of synthetic datasets that make up for a lack of training data; training image classifiers from combined sets of photographic and synthetic data; and mtriage, an open source software that orchestrates these classifiers' deployment to triage public domain media, and visualise predictions in a web interface. We show that synthetic data helps to train classifiers more effectively, and that certain approaches yield better results for different architectures. We then demonstrate our workflow in two real-world human rights investigations: the use of the Triple-Chaser tear gas grenade against civilians, and the verification of allegations of military presence in Ukraine in 2014.","tags":["Ethics"],"title":"Objects of violence: synthetic data for practical ML in human rights investigations","type":"publication"},{"authors":["Christopher Beckham","Sina Honari","Vikas Verma","Alex Lamb","Farnoosh Ghadiri","R Devon Hjelm","Yoshua Bengio","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1558569600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1558569600,"objectID":"be9dd0ac442ea045ee70a3d017e78d76","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/christopherbeckhamonadneurips2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/christopherbeckhamonadneurips2019/","section":"publication","summary":"In this paper, we explore new approaches to combining information encoded within the learned representations of auto-encoders. We explore models that are capable of combining the attributes of multiple inputs such that a resynthesised output is trained to fool an adversarial discriminator for real versus synthesised data. Furthermore, we explore the use of such an architecture in the context of semi-supervised learning, where we learn a mixing function whose objective is to produce interpolations of hidden states, or masked combinations of latent representations that are consistent with a conditioned class label. We show quantitative and qualitative evidence that such a formulation is an interesting avenue of research.","tags":["Adversarial Learning","Unsupervised Learning"],"title":"On Adversarial Mixup Resynthesis","type":"publication"},{"authors":["Kyle Hsu","Waseem Gharbieh","Daniel M. Roy","Gintare Karolina Dziugaite"],"categories":null,"content":"’ \u0026#39;\n","date":1558569600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1558569600,"objectID":"ae9ce54bce25e8b8071462f862bb582a","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/kylehsuoptineuripsworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/kylehsuoptineuripsworkshops2019/","section":"publication","summary":"’ '","tags":null,"title":"Optimal PAC-Bayes bounds require distribution- and data-dependent priors","type":"publication"},{"authors":["Sharan Vaswani","Aaron Mishkin","Issam H. Laradji","Mark Schmidt","Gauthier Gidel","Simon Lacoste-Julien"],"categories":null,"content":"’ \u0026#39;\n","date":1558569600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1558569600,"objectID":"5a4328c39719122926a697392420290c","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/sharanvaswanipainneurips2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/sharanvaswanipainneurips2019/","section":"publication","summary":"Recent works have shown that stochastic gradient descent (SGD) achieves the fast convergence rates of full-batch gradient descent for over-parameterized models satisfying certain interpolation conditions. However, the step-size used in these works depends on unknown quantities and SGD's practical performance heavily relies on the choice of this step-size. We propose to use line-search techniques to automatically set the step-size when training models that can interpolate the data. In the interpolation setting, we prove that SGD with a stochastic variant of the classic Armijo line-search attains the deterministic convergence rates for both convex and strongly-convex functions. Under additional assumptions, SGD with Armijo line-search is shown to achieve fast convergence for non-convex functions. Furthermore, we show that stochastic extra-gradient with a Lipschitz line-search attains linear convergence for an important class of non-convex functions and saddle-point problems satisfying interpolation. To improve the proposed methods' practical performance, we give heuristics to use larger step-sizes and acceleration. We compare the proposed algorithms against numerous optimization methods on standard classification tasks using both kernel methods and deep networks. The proposed methods result in competitive performance across all models and datasets, while being robust to the precise choices of hyper-parameters. For multi-class classification using deep networks, SGD with Armijo line-search results in both faster convergence and better generalization.","tags":["Optimization","Guarranties"],"title":"Painless Stochastic Gradient: Interpolation, Line-Search, and Convergence Rates","type":"publication"},{"authors":["Simon Ramstedt","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1558569600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1558569600,"objectID":"ff12448146e1b4c46029d9ba96fb7125","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/simonramstedtrealneurips2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/simonramstedtrealneurips2019/","section":"publication","summary":"Markov Decision Processes (MDPs), the mathematical framework underlying most algorithms in Reinforcement Learning (RL), are often used in a way that wrongfully assumes that the state of an agent's environment does not change during action selection. As RL systems based on MDPs begin to find application in real-world safety critical situations, this mismatch between the assumptions underlying classical MDPs and the reality of real-time computation may lead to undesirable outcomes. In this paper, we introduce a new framework, in which states and actions evolve simultaneously and show how it is related to the classical MDP formulation. We analyze existing algorithms under the new real-time formulation and show why they are suboptimal when used in real-time. We then use those insights to create a new algorithm Real-Time Actor-Critic (RTAC) that outperforms the existing state-of-the-art continuous control algorithm Soft Actor-Critic both in real-time and non-real-time settings. Code and videos can be found at this https URL.","tags":["Reinforcement Learning"],"title":"Real-Time Reinforcement Learning","type":"publication"},{"authors":["Tatjana Chavdarova","Gauthier Gidel","François Fleuret","Simon Lacoste-Julien"],"categories":null,"content":"’ \u0026#39;\n","date":1558569600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1558569600,"objectID":"4121686c8322ad0499f16c63d764dcf7","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/tatjanachavdarovareduneurips2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/tatjanachavdarovareduneurips2019/","section":"publication","summary":"We study the effect of the stochastic gradient noise on the training of generative adversarial networks (GANs) and show that it can prevent the convergence of standard game optimization methods, while the batch version converges. We address this issue with a novel stochastic variance-reduced extragradient (SVRE) optimization algorithm, which for a large class of games improves upon the previous convergence rates proposed in the literature. We observe empirically that SVRE performs similarly to a batch method on MNIST while being computationally cheaper, and that SVRE yields more stable GAN training on standard datasets.","tags":["Unsupervised Learning","GANs","Optimization"],"title":"Reducing Noise in GAN Training with Variance Reduced Extragradient","type":"publication"},{"authors":["Chiheb Trabelsi","Olexa Bilaniuk","Ousmane Amadou Dia","Ying Zhang","Mirco Ravanelli","Jonathan Binas","Negar Rostamzadeh","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1558569600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1558569600,"objectID":"f05bfdfde43f99a57894842417173fed","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/chihebtrabelsiretrneuripsworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/chihebtrabelsiretrneuripsworkshops2019/","section":"publication","summary":"Recent advances have made it possible to create deep complex-valued neural networks. Despite this progress, the potential power of fully complex intermediate computations and representations has not yet been explored for many challenging learning problems. Building on recent advances, we propose a novel mechanism for extracting signals in the frequency domain. As a case study, we perform audio source separation in the Fourier domain. Our extraction mechanism could be regarded as a local ensembling method that combines a complex-valued convolutional version of Feature-Wise Linear Modulation (FiLM) and a signal averaging operation. We also introduce a new explicit amplitude and phase-aware loss, which is scale and time invariant, taking into account the complex-valued components of the spectrogram. Using the Wall Street Journal Dataset, we compare our phase-aware loss to several others that operate both in the time and frequency domains and demonstrate the effectiveness of our proposed signal extraction method and proposed loss. When operating in the complex-valued frequency domain, our deep complex-valued network substantially outperforms its real-valued counterparts even with half the depth and a third of the parameters. Our proposed mechanism improves significantly deep complex-valued networks' performance and we demonstrate the usefulness of its regularizing effect.\n","tags":null,"title":"Retrieving Signals in the Frequency Domain with Deep Complex Extractors","type":"publication"},{"authors":["David Rolnick","Priya L. Donti","Lynn H. Kaack","Kelly Kochanski","Alexandre Lacoste","Kris Sankaran","Andrew Slavin Ross","Nikola Milojevic-Dupont","Natasha Jaques","Anna Waldman-Brown","Alexandra Luccioni","Tegan Maharaj","Evan D. Sherwin","S. Karthik Mukkavilli","Konrad P. Kording","Carla Gomes","Andrew Y. Ng","Demis Hassabis","John C. Platt","Felix Creutzig","Jennifer Chayes","Yoshua Bengio"],"categories":null,"content":"’ \u0026#39;\n","date":1558569600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1558569600,"objectID":"1af6e9228eac777fef4b788c043b6baa","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/davidrolnicktackneuripsworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/davidrolnicktackneuripsworkshops2019/","section":"publication","summary":"Climate change is one of the greatest challenges facing humanity, and we, as machine learning experts, may wonder how we can help. Here we describe how machine learning can be a powerful tool in reducing greenhouse gas emissions and helping society adapt to a changing climate. From smart grids to disaster management, we identify high impact problems where existing gaps can be filled by machine learning, in collaboration with other fields. Our recommendations encompass exciting research questions as well as promising business opportunities. We call on the machine learning community to join the global effort against climate change.","tags":["Climate Change"],"title":"Tackling Climate Change with Machine Learning","type":"publication"},{"authors":["Gabriel Arpino","Daniel M. Roy","Gintare Karolina Dziugaite"],"categories":null,"content":"’ \u0026#39;\n","date":1558569600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1558569600,"objectID":"dbc73fe8519fb0c6163b64283d337b4a","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/gabrielarpinotowaneuripsworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/gabrielarpinotowaneuripsworkshops2019/","section":"publication","summary":"’ '","tags":["Guarranties"],"title":"Towards generalization guarantees for SGD: Data-dependent PAC-Bayes priors","type":"publication"},{"authors":["Sai Rajeswar Mudumba","Fahim Mannan","Florian Golemo","Jérôme Parent-Lévesque","David Vazquez","Derek Nowrouzezahrai","Aaron Courville"],"categories":null,"content":"’ \u0026#39;\n","date":1557878400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1557878400,"objectID":"2daccef4e3f7c52248bd992b7f30d449","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/sairajeswarmudumbapix2ijcv2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/sairajeswarmudumbapix2ijcv2020/","section":"publication","summary":"We infer and generate three-dimensional (3D) scene information from a single input image and without supervision. This problem is under-explored, with most prior work relying on supervision from, e.g., 3D ground-truth, multiple images of a scene, image silhouettes or key-points. We propose Pix2Shape, an approach to solve this problem with four components: (i) an encoder that infers the latent 3D representation from an image, (ii) a decoder that generates an explicit 2.5D surfel-based reconstruction of a scene from the latent code (iii) a differentiable renderer that synthesizes a 2D image from the surfel representation, and (iv) a critic network trained to discriminate between images generated by the decoder-renderer and those from a training distribution. Pix2Shape can generate complex 3D scenes that scale with the view-dependent on-screen resolution, unlike representations that capture world-space resolution, i.e., voxels or meshes. We show that Pix2Shape learns a consistent scene representation in its encoded latent space and that the decoder can then be applied to this latent representation in order to synthesize the scene from a novel viewpoint. We evaluate Pix2Shape with experiments on the ShapeNet dataset as well as on a novel benchmark we developed, called 3D-IQTT, to evaluate models based on their ability to enable 3d spatial reasoning. Qualitative and quantitative evaluation demonstrate Pix2Shape's ability to solve scene reconstruction, generation, and understanding tasks.","tags":["Computer Vision","3D"],"title":"Pix2Shape: Towards Unsupervised Learning of 3D Scenesfrom Images using a View-based Representation","type":"publication"},{"authors":["Issam H. Laradji","David Vazquez","Mark Schmidt"],"categories":null,"content":"’ \u0026#39;\n","date":1556496000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1556496000,"objectID":"f2af10de6a8c9727cb9985e0879bc8aa","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/issamh.laradjiwherbmvc2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/issamh.laradjiwherbmvc2019/","section":"publication","summary":"A major obstacle in instance segmentation is that existing methods often need many per-pixel labels in order to be effective. These labels require large human effort and for certain applications, such labels are not readily available. To address this limitation, we propose a novel framework that can effectively train with image-level labels, which are significantly cheaper to acquire. For instance, one can do an internet search for the term \"car\" and obtain many images where a car is present with minimal effort. Our framework consists of two stages: (1) train a classifier to generate pseudo masks for the objects of interest; (2) train a fully supervised Mask R-CNN on these pseudo masks. Our two main contribution are proposing a pipeline that is simple to implement and is amenable to different segmentation methods; and achieves new state-of-the-art results for this problem setup. Our results are based on evaluating our method on PASCAL VOC 2012, a standard dataset for weakly supervised methods, where we demonstrate major performance gains compared to existing methods with respect to mean average precision.","tags":["Computer Vision","Instance Segmentation","Weak Supervision"],"title":"Where are the Masks: Instance Segmentation with Image-level Supervision ","type":"publication"},{"authors":["Mai Oudah","Amjad Almahairi","Nizar Habash"],"categories":null,"content":"’ \u0026#39;\n","date":1555459200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1555459200,"objectID":"2106c931616c4d12ca654438546ae7a1","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/maioudahtheimtsummit2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/maioudahtheimtsummit2019/","section":"publication","summary":"Neural networks have become the state-of-the-art approach for machine translation (MT) in many languages. While linguistically-motivated tokenization techniques were shown to have significant effects on the performance of statistical MT, it remains unclear if those techniques are well suited for neural MT. In this paper, we systematically compare neural and statistical MT models for Arabic-English translation on data preprecossed by various prominent tokenization schemes. Furthermore, we consider a range of data and vocabulary sizes and compare their effect on both approaches. Our empirical results show that the best choice of tokenization scheme is largely based on the type of model and the size of data. We also show that we can gain significant improvements using a system selection that combines the output from neural and statistical MT.","tags":["Machine Translation"],"title":"The Impact of Preprocessing on Arabic-English Statistical and Neural Machine Translation","type":"publication"},{"authors":["Mennatullah Siam","Boris N. Oreshkin","Martin Jagersand"],"categories":null,"content":"’ \u0026#39;\n","date":1553212800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1553212800,"objectID":"c2c6b38023dc10dab033f9fa9a5b819f","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/mennatullahsiamadapiccv2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/mennatullahsiamadapiccv2019/","section":"publication","summary":"Deep learning has thrived by training on large-scale datasets. However, in robotics applications sample efficiency is critical. We propose a novel adaptive masked proxies method that constructs the final segmentation layer weights from few labelled samples. It utilizes multi-resolution average pooling on base embeddings masked with the label to act as a positive proxy for the new class, while fusing it with the previously learned class signatures. Our method is evaluated on PASCAL-5i dataset and outperforms the state-of-the-art in the few-shot semantic segmentation. Unlike previous methods, our approach does not require a second branch to estimate parameters or prototypes, which enables it to be used with 2-stream motion and appearance based segmentation networks. We further propose a novel setup for evaluating continual learning of object segmentation which we name incremental PASCAL (iPASCAL) where our method outperforms the baseline method. Our code is publicly available at this https URL.","tags":["Few-shot Learning","Semantic Segmentation"],"title":"Adaptive Masked Proxies for Few-Shot Segmentation","type":"publication"},{"authors":["Lironne Kurzman","David Vazquez","Issam H. Laradji"],"categories":null,"content":"’ \u0026#39;\n","date":1553212800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1553212800,"objectID":"fba6d4bf9e9a61810bc23c5ca844574c","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/lironnekurzmanclasiccvworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/lironnekurzmanclasiccvworkshops2019/","section":"publication","summary":"We propose a Class-Based Styling method (CBS) that can map different styles for different object classes in real-time. CBS achieves real-time performance by carrying out two steps simultaneously. While a semantic segmentation method is used to obtain the mask of each object class in a video frame, a styling method is used to style that frame globally. Then an object class can be styled by combining the segmentation mask and the styled image. The user can also select multiple styles so that different object classes can have different styles in a single frame. For semantic segmentation, we leverage DABNet that achieves high accuracy, yet only has 0.76 million parameters and runs at 104 FPS. For the style transfer step, we use a popular real-time method proposed by Johnson et al. [7]. We evaluated CBS on a video of the CityScapes dataset and observed high-quality localized style transfer results for different object classes and real-time performance.","tags":["Computer Vision","Style Transfer","Semantic Segmentation"],"title":"Class-Based Styling: Real-time Localized Style Transfer with Semantic Segmentation","type":"publication"},{"authors":["Pedro O. Pinheiro","Negar Rostamzadeh","Sungjin Ahn"],"categories":null,"content":"’ \u0026#39;\n","date":1553212800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1553212800,"objectID":"4f2a0433ec4163d370ce3f6b98973a1a","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/pedroo.pinheirodomaiccv2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/pedroo.pinheirodomaiccv2019/","section":"publication","summary":"Single-view 3D shape reconstruction is an important but challenging problem, mainly for two reasons. First, as shape annotation is very expensive to acquire, current methods rely on synthetic data, in which ground-truth 3D annotation is easy to obtain. However, this results in domain adaptation problem when applied to natural images. The second challenge is that there are multiple shapes that can explain a given 2D image. In this paper, we propose a framework to improve over these challenges using adversarial training. On one hand, we impose domain confusion between natural and synthetic image representations to reduce the distribution gap. On the other hand, we impose the reconstruction to be `realistic' by forcing it to lie on a (learned) manifold of realistic object shapes. Our experiments show that these constraints improve performance by a large margin over baseline reconstruction models. We achieve results competitive with the state of the art with a much simpler architecture.","tags":["Domain Adaptation","3D"],"title":"Domain-Adaptive Single-view 3D Reconstruction","type":"publication"},{"authors":["Mattie Tesfaldet","Xavier Snelgrove","David Vazquez"],"categories":null,"content":"’ \u0026#39;\n","date":1553212800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1553212800,"objectID":"e8f601b7dc02020ca514cc673fe680e1","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/mattietesfaldetfouriccvworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/mattietesfaldetfouriccvworkshops2019/","section":"publication","summary":"Compositional Pattern Producing Networks (CPPNs) are differentiable networks that independently map (x, y) pixel coordinates to (r, g, b) colour values. Recently, CPPNs have been used for creating interesting imagery for creative purposes, e.g., neural art. However their architecture biases generated images to be overly smooth, lacking high-frequency detail. In this work, we extend CPPNs to explicitly model the frequency information for each pixel output, capturing frequencies beyond the DC component. We show that our Fourier-CPPNs (F-CPPNs) provide improved visual detail for image synthesis.","tags":["Unsupervised Learning"],"title":"Fourier-CPPNs for Image Synthesis","type":"publication"},{"authors":["Saypraseuth Mounsaveng","Issam H. Laradji","Ismail Ben Ayed","David Vazquez","Marco Pedersoli"],"categories":null,"content":"’ \u0026#39;\n","date":1553212800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1553212800,"objectID":"f26af8d8127ea3688353e30d783dc417","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/saypraseuthmounsavenglearwacv2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/saypraseuthmounsavenglearwacv2021/","section":"publication","summary":"Data augmentation is a key practice in machine learning for improving generalization performance. However, finding the best data augmentation hyperparameters requires domain knowledge or a computationally demanding search. We address this issue by proposing an efficient approach to automatically train a network that learns an effective distribution of transformations to improve its generalization. Using bilevel optimization, we directly optimize the data augmentation parameters using a validation set. This framework can be used as a general solution to learn the optimal data augmentation jointly with an end task model like a classifier. Results show that our joint training method produces an image classification accuracy that is comparable to or better than carefully hand-crafted data augmentation. Yet, it does not need an expensive external validation loop on the data augmentation hyperparameters.","tags":["Computer Vision","Image Classification","Optimization","Data Augmentation"],"title":"Learning Data Augmentation with Online Bilevel Optimization for Image Classification","type":"publication"},{"authors":["Rey Reza Wiyatno","Anqi Xu"],"categories":null,"content":"’ \u0026#39;\n","date":1553212800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1553212800,"objectID":"e8058ff4c817590a08792e0cef303920","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/reyrezawiyatnophysiccv2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/reyrezawiyatnophysiccv2019/","section":"publication","summary":"We present a system for generating inconspicuous-looking textures that, when displayed in the physical world as digital or printed posters, cause visual object tracking systems to become confused. For instance, as a target being tracked by a robot's camera moves in front of such a poster, our generated texture makes the tracker lock onto it and allows the target to evade. This work aims to fool seldom-targeted regression tasks, and in particular compares diverse optimization strategies: non-targeted, targeted, and a new family of guided adversarial losses. While we use the Expectation Over Transformation (EOT) algorithm to generate physical adversaries that fool tracking models when imaged under diverse conditions, we compare the impacts of different conditioning variables, including viewpoint, lighting, and appearances, to find practical attack setups with high resulting adversarial strength and convergence speed. We further showcase textures optimized solely using simulated scenes can confuse real-world tracking systems.","tags":["Object Tracking","Adversarial Learning"],"title":"Physical Adversarial Textures that Fool Visual Object Tracking","type":"publication"},{"authors":["Ousmane Amadou Dia","Elnaz Barshan","Reza Babanezhad"],"categories":null,"content":"’ \u0026#39;\n","date":1552176000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1552176000,"objectID":"a818b24874ec33a090479b952eee4b87","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/ousmaneamadoudiasemaarxiv2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/ousmaneamadoudiasemaarxiv2019/","section":"publication","summary":"While progress has been made in crafting visually imperceptible adversarial examples, constructing semantically meaningful ones remains a challenge. In this paper, we propose a framework to generate semantics preserving adversarial examples. First, we present a manifold learning method to capture the semantics of the inputs. The motivating principle is to learn the low-dimensional geometric summaries of the inputs via statistical inference. Then, we perturb the elements of the learned manifold using the Gram-Schmidt process to induce the perturbed elements to remain in the manifold. To produce adversarial examples, we propose an efficient algorithm whereby we leverage the semantics of the inputs as a source of knowledge upon which we impose adversarial constraints. We apply our approach on toy data, images and text, and show its effectiveness in producing semantics preserving adversarial examples which evade existing defenses against adversarial attacks.","tags":["Adversarial Learning"],"title":"Semantics Preserving Adversarial Learning","type":"publication"},{"authors":["Jonathan Frankle","Gintare Karolina Dziugaite","Daniel M. Roy","Michael Carbin"],"categories":null,"content":"’ \u0026#39;\n","date":1551744000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1551744000,"objectID":"0f32b419dc78132fc364910464375d23","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/jonathanfranklethelarxiv2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/jonathanfranklethelarxiv2019/","section":"publication","summary":"Pruning is a well-established technique for removing unnecessary structure from neural networks after training to improve the performance of inference. Several recent results have explored the possibility of pruning at initialization time to provide similar benefits during training. In particular, the \"lottery ticket hypothesis\" conjectures that typical neural networks contain small subnetworks that can train to similar accuracy in a commensurate number of steps. The evidence for this claim is that a procedure based on iterative magnitude pruning (IMP) reliably finds such subnetworks retroactively on small vision tasks. However, IMP fails on deeper networks, and proposed methods to prune before training or train pruned networks encounter similar scaling limitations. In this paper, we argue that these efforts have struggled on deeper networks because they have focused on pruning precisely at initialization. We modify IMP to search for subnetworks that could have been obtained by pruning early in training (0.1% to 7% through) rather than at iteration 0. With this change, it finds small subnetworks of deeper networks (e.g., 80% sparsity on Resnet-50) that can complete the training process to match the accuracy of the original network on more challenging tasks (e.g., ImageNet). In situations where IMP fails at iteration 0, the accuracy benefits of delaying pruning accrue rapidly over the earliest iterations of training. To explain these behaviors, we study subnetwork \"stability,\" finding that - as accuracy improves in this fashion - IMP subnetworks train to parameters closer to those of the full network and do so with improved consistency in the face of gradient noise. These results offer new insights into the opportunity to prune large-scale networks early in training and the behaviors underlying the lottery ticket hypothesis","tags":null,"title":"The Lottery Ticket Hypothesis at Scale","type":"publication"},{"authors":["Jonathan Pilault","Jaehong Park","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1551657600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1551657600,"objectID":"1606e906219a4354d65ae70e249b7a4f","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/jonathanpilaultonthacl2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/jonathanpilaultonthacl2019/","section":"publication","summary":"In this work, we investigate the performance of untrained randomly initialized encoders in a general class of sequence to sequence models and compare their performance with that of fully-trained encoders on the task of abstractive summarization. We hypothesize that random projections of an input text have enough representational power to encode the hierarchical structure of sentences and semantics of documents. Using a trained decoder to produce abstractive text summaries, we empirically demonstrate that architectures with untrained randomly initialized encoders perform competitively with respect to the equivalent architectures with fully-trained encoders. We further find that the capacity of the encoder not only improves overall model generalization but also closes the performance gap between untrained randomly initialized and full-trained encoders. To our knowledge, it is the first time that general sequence to sequence models with attention are assessed for trained and randomly projected representations on abstractive summarization.","tags":["Natural Language Processing","Summarization"],"title":"On the impressive performance of randomly weighted encoders in summarization tasks","type":"publication"},{"authors":["Vardaan Pahuja","Jie Fu","Sarath Chandar","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1551657600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1551657600,"objectID":"0a32e7a64e4a52a8dbef7867fcfa883e","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/vardaanpahujastruacl2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/vardaanpahujastruacl2019/","section":"publication","summary":"Neural Module Networks, originally proposed for the task of visual question answering, are a class of neural network architectures that involve human-specified neural modules, each designed for a specific form of reasoning. In current formulations of such networks only the parameters of the neural modules and/or the order of their execution is learned. In this work, we further expand this approach and also learn the underlying internal structure of modules in terms of the ordering and combination of simple and elementary arithmetic operators. Our results show that one is indeed able to simultaneously learn both internal module structure and module sequencing without extra supervisory signals for module execution sequencing. With this approach, we report performance comparable to models using hand-designed modules.","tags":["Structure Learning"],"title":"Structure Learning for Neural Module Networks","type":"publication"},{"authors":["Rodrigo Toro Icarte","Ethan Waldie","Toryn Q. Klassen","Richard Valenzano","Margarita P. Castro","Sheila A. McIlraith"],"categories":null,"content":"’ \u0026#39;\n","date":1551398400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1551398400,"objectID":"12d5642166af388b39383dfed7a5f022","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/rodrigotoroicartesearrldm2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/rodrigotoroicartesearrldm2019/","section":"publication","summary":"In partially observable environments, an agent’s policy should often be a function of the history of its interaction with the environment. This contradicts the Markovian assumption that underlies most reinforcement learning (RL) approaches. Recent efforts to address this issue have focused on training Recurrent Neural Networks using policy gradient methods. In this work, we propose an alternative – and possibly complementary – approach. We exploit the fact that in many cases a partially observable problem can be decomposed into a small set of individually Markovian subproblems that collectively preserve the optimal policy. Given such a decomposition, any RL method can be used to learn policies for the subproblems. We pose the task of learning the decomposition as a discrete optimization problem that learns a form of Finite State Machine from traces. In doing so, our method learns a high-level representation of a partially observable problem that summarizes the history of the agent’s interaction with the environment, and then uses that representation to quickly learn a policy from low-level observations to actions. Our approach is shown to significantly outperform standard Deep RL approaches, including A3C, PPO, and ACER, on three partially observable grid domains.","tags":["Reinforcement Learning"],"title":"Searching for Markovian Subproblems to Address Partially Observable Reinforcement Learning","type":"publication"},{"authors":["Alexander Wong","Anqi Xu","Gregory Dudek"],"categories":null,"content":"’ \u0026#39;\n","date":1550448000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1550448000,"objectID":"de16871d29345abc8c6dd542c8000c8c","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/alexanderwonginvecrv2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/alexanderwonginvecrv2019/","section":"publication","summary":"This paper explores the impact of warnings, audio feedback, and gender on human-robot trust in the context of autonomous driving and specifically shared robot control. We use pre-existing methods for the estimation and assessment of human-robot trust where trust was found to vary as a function of the quality of behavior of an autonomous driving controller. We extend these models and empirical methods to examine the impact of audio cues on trust, specifically studying the impacts of gender-specific audio cues on the elicitation of trust. Our study compares agents with and without human-voiced indicators of uncertainty and evaluates differences in trust with inferred and introspective methods. We find that a person's trust in a robot can be influenced by verbal feedback from the robot agent. Specifically, people tend to lend more trust to agents whose voice is of the same gender as their own.","tags":["Natural Language Processing","Robotics","Bias"],"title":"Investigating Trust Factors in Human-Robot Shared Control: Implicit Gender Bias Around Robot Voice","type":"publication"},{"authors":["Chin-Wei Huang","Kris Sankaran","Eeshan Dhekane","Alexandre Lacoste","Aaron Courville"],"categories":null,"content":"’ \u0026#39;\n","date":1548201600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1548201600,"objectID":"1e234c6aa85763e3e8ae7ccee4b7cd25","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/chin-weihuanghiericml2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/chin-weihuanghiericml2019/","section":"publication","summary":"Importance weighted variational inference (Burda et al., 2015) uses multiple i.i.d. samples to have a tighter variational lower bound. We believe a joint proposal has the potential of reducing the number of redundant samples, and introduce a hierarchical structure to induce correlation. The hope is that the proposals would coordinate to make up for the error made by one another to reduce the variance of the importance estimator. Theoretically, we analyze the condition under which convergence of the estimator variance can be connected to convergence of the lower bound. Empirically, we confirm that maximization of the lower bound does implicitly minimize variance. Further analysis shows that this is a result of negative correlation induced by the proposed hierarchical meta sampling scheme, and performance of inference also improves when the number of samples increases.","tags":["Unsupervised Learning","Autoencoders"],"title":"Hierarchical Importance Weighted Autoencoders","type":"publication"},{"authors":["Jeffrey Negrea","Mahdi Haghifam","Gintare Karolina Dziugaite","Ashish Khisti","Daniel M. Roy"],"categories":null,"content":"’ \u0026#39;\n","date":1548201600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1548201600,"objectID":"95dddf4681efa35ed1ffcdad51acd053","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/jeffreynegreainfoicmlworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/jeffreynegreainfoicmlworkshops2019/","section":"publication","summary":"In this work, we improve upon the stepwise analysis of noisy iterative learning algorithms initiated by Pensia, Jog, and Loh (2018) and recently extended by Bu, Zou, and Veeravalli (2019). Our main contributions are significantly improved mutual information bounds for Stochastic Gradient Langevin Dynamics via data-dependent estimates. Our approach is based on the variational characterization of mutual information and the use of data-dependent priors that forecast the mini-batch gradient based on a subset of the training samples. Our approach is broadly applicable within the information-theoretic framework of Russo and Zou (2015) and Xu and Raginsky (2017). Our bound can be tied to a measure of flatness of the empirical risk surface. As compared with other bounds that depend on the squared norms of gradients, empirical investigations show that the terms in our bounds are orders of magnitude smaller.","tags":null,"title":"Information-Theoretic Generalization Bounds for SGLD via Data-Dependent Estimates","type":"publication"},{"authors":["Yukai (Kris) Hong","Pedro O. Pinheiro","Scott Weichenthal"],"categories":null,"content":"’ \u0026#39;\n","date":1548201600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1548201600,"objectID":"af4c656774b70f4df1260858336bc23e","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/yukaikrishonglearicmlworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/yukaikrishonglearicmlworkshops2019/","section":"publication","summary":"Here we present a new method of estimating global variations in outdoor PM2.5 concentrations using satellite images combined with ground-level measurements and deep convolutional neural networks. Specifically, new deep learning models were trained over the global PM2.5 concentration range (","tags":["Remote Sensing","Climate Change"],"title":"Learning Global Variations in Outdoor PM_2.5 Concentrations with Satellite Images","type":"publication"},{"authors":["Chin-Wei Huang","Ahmed Touati","Pascal Vincent","Gintare Karolina Dziugaite","Alexandre Lacoste","Aaron Courville"],"categories":null,"content":"’ \u0026#39;\n","date":1548201600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1548201600,"objectID":"f56d393473dca9fb0831a8c2959b999b","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/chin-weihuangstocicmlworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/chin-weihuangstocicmlworkshops2019/","section":"publication","summary":"Recent advances in variational inference enable the modelling of highly structured joint distributions, but are limited in their capacity to scale to the high-dimensional setting of stochastic neural networks. This limitation motivates a need for scalable parameterizations of the noise generation process, in a manner that adequately captures the dependencies among the various parameters. In this work, we address this need and present the Kronecker Flow, a generalization of the Kronecker product to invertible mappings designed for stochastic neural networks. We apply our method to variational Bayesian neural networks on predictive tasks, PAC-Bayes generalization bound estimation, and approximate Thompson sampling in contextual bandits. In all setups, our methods prove to be competitive with existing methods and better than the baselines.","tags":null,"title":"Stochastic Neural Network with Kronecker Flow","type":"publication"},{"authors":["Issam H. Laradji","Mark Schmidt","Vladimir Pavlovic","Minyoung Kim"],"categories":null,"content":"’ \u0026#39;\n","date":1547510400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1547510400,"objectID":"c316ee00831d6b8c4d10e2f6e3d1e902","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/issamh.laradjieffiijcnn2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/issamh.laradjieffiijcnn2019/","section":"publication","summary":"Deep Gaussian processes (DGP) have appealing Bayesian properties, can handle variable-sized data, and learn deep features. Their limitation is that they do not scale well with the size of the data. Existing approaches address this using a deep random feature (DRF) expansion model, which makes inference tractable by approximating DGPs. However, DRF is not suitable for variable-sized input data such as trees, graphs, and sequences. We introduce the GP-DRF, a novel Bayesian model with an input layer of GPs, followed by DRF layers. The key advantage is that the combination of GP and DRF leads to a tractable model that can both handle a variable-sized input as well as learn deep long-range dependency structures of the data. We provide a novel efficient method to simultaneously infer the posterior of GP's latent vectors and infer the posterior of DRF's internal weights and random frequencies. Our experiments show that GP-DRF outperforms the standard GP model and DRF model across many datasets. Furthermore, they demonstrate that GP-DRF enables improved uncertainty quantification compared to GP and DRF alone, with respect to a Bhattacharyya distance assessment. Source code is available at this https URL.","tags":["Optimization"],"title":"Efficient Deep Gaussian Process Models for Variable-Sized Inputs","type":"publication"},{"authors":["Joel Lamy Poirier","Anqi Xu"],"categories":null,"content":"’ \u0026#39;\n","date":1544832000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1544832000,"objectID":"ff3d0c9f3eb117e56666f16a8adbcac0","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/joellamypoirierhintarxiv2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/joellamypoirierhintarxiv2018/","section":"publication","summary":"We present Hinted Networks: a collection of architectural transformations for improving the accuracies of neural network models for regression tasks, through the injection of a prior for the output prediction (i.e. a hint). We ground our investigations within the camera relocalization domain, and propose two variants, namely the Hinted Embedding and Hinted Residual networks, both applied to the PoseNet base model for regressing camera pose from an image. Our evaluations show practical improvements in localization accuracy for standard outdoor and indoor localization datasets, without using additional information. We further assess the range of accuracy gains within an aerial-view localization setup, simulated across vast areas at different times of the year.","tags":null,"title":"Hinted Networks","type":"publication"},{"authors":["Guillem Cucurull","Perouz Taslakian","David Vazquez"],"categories":null,"content":"’ \u0026#39;\n","date":1542326400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1542326400,"objectID":"795e31f58afea11a4eaf686ded18c39c","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/guillemcucurullcontcvpr2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/guillemcucurullcontcvpr2019/","section":"publication","summary":"How do we determine whether two or more clothing items are compatible or visually appealing? Part of the answer lies in understanding of visual aesthetics, and is biased by personal preferences shaped by social attitudes, time, and place. In this work we propose a method that predicts compatibility between two items based on their visual features, as well as their context. We define context as the products that are known to be compatible with each of these item. Our model is in contrast to other metric learning approaches that rely on pairwise comparisons between item features alone. We address the compatibility prediction problem using a graph neural network that learns to generate product embeddings conditioned on their context. We present results for two prediction tasks (fill in the blank and outfit compatibility) tested on two fashion datasets Polyvore and Fashion-Gen, and on a subset of the Amazon dataset; we achieve state of the art results when using context information and show how test performance improves as more context is used.","tags":["Graphs","Computer Vision","Recommender Systems"],"title":"Context-Aware Visual Compatibility Prediction","type":"publication"},{"authors":["Xiang Zhang","Yann LeCun"],"categories":null,"content":"’ \u0026#39;\n","date":1541808000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1541808000,"objectID":"0d592176035cebc857552dea59cb3e11","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/xiangzhangadvearxiv2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/xiangzhangadvearxiv2018/","section":"publication","summary":"This article proposes Adversarially-Trained Normalized Noisy-Feature Auto-Encoder (ATNNFAE) for byte-level text generation. An ATNNFAE consists of an auto-encoder where the internal code is normalized on the unit sphere and corrupted by additive noise. Simultaneously, a replica of the decoder (sharing the same parameters as the AE decoder) is used as the generator and fed with random latent vectors. An adversarial discriminator is trained to distinguish training samples reconstructed from the AE from samples produced through the random-input generator, making the entire generator-discriminator path differentiable for discrete data like text. The combined effect of noise injection in the code and shared weights between the decoder and the generator can prevent the mode collapsing phenomenon commonly observed in GANs. Since perplexity cannot be applied to non-sequential text generation, we propose a new evaluation method using the total variance distance between frequencies of hash-coded byte-level n-grams (NGTVD). NGTVD is a single benchmark that can characterize both the quality and the diversity of the generated texts. Experiments are offered in 6 large-scale datasets in Arabic, Chinese and English, with comparisons against n-gram baselines and recurrent neural networks (RNNs). Ablation study on both the noise level and the discriminator is performed. We find that RNNs have trouble competing with the n-gram baselines, and the ATNNFAE results are generally competitive.","tags":["Natural Language Processing","Text Generation","Adversarial Learning","Autoencoders"],"title":"Adversarially-Trained Normalized Noisy-Feature Auto-Encoder for Text Generation","type":"publication"},{"authors":["Alexandre Drouin","Gaël Letarte","Frédéric Raymond","Mario Marchand","Jacques Corbeil","François Laviolette"],"categories":null,"content":"’ \u0026#39;\n","date":1538697600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1538697600,"objectID":"bd9967dfc6411aa699e059083ca70a4b","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/alexandredrouinintenaturesr2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/alexandredrouinintenaturesr2020/","section":"publication","summary":"Understanding the relationship between the genome of a cell and its phenotype is a central problem in precision medicine. Nonetheless, genotype-to-phenotype prediction comes with great challenges for machine learning algorithms that limit their use in this setting. The high dimensionality of the data tends to hinder generalization and challenges the scalability of most learning algorithms. Additionally, most algorithms produce models that are complex and difficult to interpret. We alleviate these limitations by proposing strong performance guarantees, based on sample compression theory, for rule-based learning algorithms that produce highly interpretable models. We show that these guarantees can be leveraged to accelerate learning and improve model interpretability. Our approach is validated through an application to the genomic prediction of antimicrobial resistance, an important public health concern. Highly accurate models were obtained for 12 species and 56 antibiotics, and their interpretation revealed known resistance mechanisms, as well as some potentially new ones. An open-source disk-based implementation that is both memory and computationally efficient is provided with this work. The implementation is turnkey, requires no prior knowledge of machine learning, and is complemented by comprehensive tutorials.","tags":["Interpretability","Generalization Guarranties","Bioinformatics"],"title":"Interpretable genotype-to-phenotype classifiers with performance guarantees","type":"publication"},{"authors":["Chen Xing","Negar Rostamzadeh","Boris N. Oreshkin","Pedro O. Pinheiro"],"categories":null,"content":"’ \u0026#39;\n","date":1538006400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1538006400,"objectID":"e1bcade4944b214dd631fb874d57b1f8","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/chenxingadapiclrworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/chenxingadapiclrworkshops2019/","section":"publication","summary":"Metric-based meta-learning techniques have successfully been applied to few-shot classification problems. In this paper, we propose to leverage cross-modal information to enhance metric-based few-shot learning methods. Visual and semantic feature spaces have different structures by definition. For certain concepts, visual features might be richer and more discriminative than text ones. While for others, the inverse might be true. Moreover, when the support from visual information is limited in image classification, semantic representations (learned from unsupervised text corpora) can provide strong prior knowledge and context to help learning. Based on these two intuitions, we propose a mechanism that can adaptively combine information from both modalities according to new image categories to be learned. Through a series of experiments, we show that by this adaptive combination of the two modalities, our model outperforms current uni-modality few-shot learning methods and modality-alignment methods by a large margin on all benchmarks and few-shot scenarios tested. Experiments also show that our model can effectively adjust its focus on the two modalities. The improvement in performance is particularly large when the number of shots is very small.","tags":["Few-shot Learning"],"title":"Adaptive Cross-Modal Few-shot Learning","type":"publication"},{"authors":["Mennatullah Siam","Boris N. Oreshkin"],"categories":null,"content":"’ \u0026#39;\n","date":1538006400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1538006400,"objectID":"075789a30f7e8bf995cc65ddfefb60a4","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/mennatullahsiamadapiclrworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/mennatullahsiamadapiclrworkshops2019/","section":"publication","summary":"Deep learning has mainly thrived by training on large-scale datasets. However, for continual learning in applications such as robotics, it is critical to incrementally update its model in a sample efficient manner. We propose a novel method that constructs the new class weights from few labelled samples in the support set, while updating the previously learned classes. Inspiring from the work on adaptive correlation filters, an adaptive masked imprinted weights method is proposed. It utilizes a masked average pooling layer on the output embeddings and acts as a positive proxy for that class. It is then used to adaptively update the 1x1 convolutional filters that are responsible for the final classification. Our proposed method is evaluated on PASCAL-5i dataset and outperforms the state of the art in the 5-shot semantic segmentation. Unlike previous methods, our proposed approach does not require a second branch to estimate parameters or prototypes, and it enables the adaptation of previously learned weights. We further propose a novel setup for evaluating incremental object segmentation which we term as incremental PASCAL (iPASCAL), where our adaptation method has shown to outperform the baseline method.","tags":["Few-shot Learning","Semantic Segmentation"],"title":"Adaptive Masked Weight Imprinting for Few-Shot Segmentation","type":"publication"},{"authors":["Saypraseuth Mounsaveng","David Vazquez","Ismail Ben Ayed","Marco Pedersoli"],"categories":null,"content":"’ \u0026#39;\n","date":1538006400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1538006400,"objectID":"949be19498457bc518dab6e46df3c200","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/saypraseuthmounsavengadveiclrworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/saypraseuthmounsavengadveiclrworkshops2019/","section":"publication","summary":"Data augmentation (DA) is fundamental against overfitting in large convolutional neural networks, especially with a limited training dataset. In images, DA is usually based on heuristic transformations, like geometric or color transformations. Instead of using predefined transformations, our work learns data augmentation directly from the training data by learning to transform images with an encoder-decoder architecture combined with a spatial transformer network. The transformed images still belong to the same class but are new, more complex samples for the classifier. Our experiments show that our approach is better than previous generative data augmentation methods, and comparable to predefined transformation methods when training an image classifier.","tags":["Data Augmentation","Adversarial Learning"],"title":"Adversarial Learning of General Transformations for Data Augmentation","type":"publication"},{"authors":["Christopher Beckham","Sina Honari","Vikas Verma","Alex Lamb","Farnoosh Ghadiri","R Devon Hjelm","Yoshua Bengio","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1538006400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1538006400,"objectID":"4886c4248891cce45ef41059b8f3fdb9","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/christopherbeckhamadveiclrworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/christopherbeckhamadveiclrworkshops2019/","section":"publication","summary":"In this paper, we explore new approaches to combining information encoded within the learned representations of auto-encoders. We explore models that are capable of combining the attributes of multiple inputs such that a resynthesised output is trained to fool an adversarial discriminator for real versus synthesised data. Furthermore, we explore the use of such an architecture in the context of semi-supervised learning, where we learn a mixing function whose objective is to produce interpolations of hidden states, or masked combinations of latent representations that are consistent with a conditioned class label. We show quantitative and qualitative evidence that such a formulation is an interesting avenue of research.","tags":["Unsupervised Learning","Adversarial Learning"],"title":"Adversarial Mixup Resynthesizers","type":"publication"},{"authors":["Maxime Chevalier-Boisvert","Dzmitry Bahdanau","Salem Lahlou","Lucas Willems","Chitwan Saharia","Thien Huu Nguyen","Yoshua Bengio"],"categories":null,"content":"’ \u0026#39;\n","date":1538006400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1538006400,"objectID":"184ef236478b106182ebf9e1bb714c79","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/maximechevalier-boisvertbabyiclr2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/maximechevalier-boisvertbabyiclr2019/","section":"publication","summary":"Allowing humans to interactively train artificial agents to understand language instructions is desirable for both practical and scientific reasons, but given the poor data efficiency of the current learning methods, this goal may require substantial research efforts. Here, we introduce the BabyAI research platform to support investigations towards including humans in the loop for grounded language learning. The BabyAI platform comprises an extensible suite of 19 levels of increasing difficulty. The levels gradually lead the agent towards acquiring a combinatorially rich synthetic language which is a proper subset of English. The platform also provides a heuristic expert agent for the purpose of simulating a human teacher. We report baseline results and estimate the amount of human involvement that would be required to train a neural network-based agent on some of the BabyAI levels. We put forward strong evidence that current deep learning methods are not yet sufficiently sample efficient when it comes to learning a language with compositional properties.","tags":["Natural Language Processing","Computer Vision","Multi-modal Learning","Reinforcement Learning"],"title":"BabyAI: A Platform to Study the Sample Efficiency of Grounded Language Learning","type":"publication"},{"authors":["Chin-Wei Huang","Faruk Ahmed","Kundan Kumar","Alexandre Lacoste","Aaron Courville"],"categories":null,"content":"’ \u0026#39;\n","date":1538006400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1538006400,"objectID":"eef5060e5d083f2ce24d52993c9bfd02","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/chin-weihuangondiiclr2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/chin-weihuangondiiclr2019/","section":"publication","summary":"Probability distillation has recently been of interest to deep learning practitioners as it presents a practical solution for sampling from autoregressive models for deployment in real-time applications. We identify a pathological optimization issue with the commonly adopted stochastic minimization of the (reverse) KL divergence, owing to sparse gradient signal from the teacher model due to curse of dimensionality. We also explore alternative principles for distillation, and show that one can achieve qualitatively better results than with KL minimization. ","tags":["Distilation"],"title":"On Difficulties of Probability Distillation","type":"publication"},{"authors":["Alexandre Piche","Valentin Thomas","Cyril Ibrahim","Julien Cornebise","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1538006400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1538006400,"objectID":"f49888393f6f6c0aad59ab7818d95e86","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/alexandrepicheplaniclrworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/alexandrepicheplaniclrworkshops2019/","section":"publication","summary":"In this work, we draw connections between planning and latent variable models1. Specifically, planning can be seen as introducing latent future optimal trajectories to improve the estimation of the agent’s policy. This insight allows us to improve two model-based reinforcement learning (RL) algorithms: Cross Entropy Methods (CEM) and Sequential Monte Carlo Planning (SMCP). Finally, we demonstrate that our methods learn faster and achieve higher performance in early training on a continuous control benchmark.","tags":["Planning"],"title":"Planning with Latent SImulated Trajectories","type":"publication"},{"authors":["Titouan Parcollet","Mirco Ravanelli","Mohamed Morchid","Georges Linarès","Chiheb Trabelsi","Renato De Mori","Yoshua Bengio"],"categories":null,"content":"’ \u0026#39;\n","date":1538006400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1538006400,"objectID":"8d94b514c00b0ad8196251c08da26608","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/titouanparcolletquaticlr2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/titouanparcolletquaticlr2019/","section":"publication","summary":"Recurrent neural networks (RNNs) are powerful architectures to model sequential data, due to their capability to learn short and long-term dependencies between the basic elements of a sequence. Nonetheless, popular tasks such as speech or images recognition, involve multi-dimensional input features that are characterized by strong internal dependencies between the dimensions of the input vector. We propose a novel quaternion recurrent neural network (QRNN), alongside with a quaternion long-short term memory neural network (QLSTM), that take into account both the external relations and these internal structural dependencies with the quaternion algebra. Similarly to capsules, quaternions allow the QRNN to code internal dependencies by composing and processing multidimensional features as single entities, while the recurrent operation reveals correlations between the elements composing the sequence. We show that both QRNN and QLSTM achieve better performances than RNN and LSTM in a realistic application of automatic speech recognition. Finally, we show that QRNN and QLSTM reduce by a maximum factor of 3.3x the number of free parameters needed, compared to real-valued RNNs and LSTMs to reach better results, leading to a more compact representation of the relevant information.","tags":["Recurrent Neural Networks"],"title":"Quaternion Recurrent Neural Networks","type":"publication"},{"authors":["Nathan Schucher","Denis Kochetkov","Laure Delisle","Thomas Boquet","Julien Cornebise"],"categories":null,"content":"’ \u0026#39;\n","date":1538006400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1538006400,"objectID":"d7c4bfa8a578675867c94786e7f1daba","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/nathanschucherrepriclrworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/nathanschucherrepriclrworkshops2019/","section":"publication","summary":"We propose a study of the stability of several few-shot learning algorithms subject to variations in the hyper-parameters and optimization schemes while controlling the random seed.  We propose a methodology for testing for statistical differences in model performances under several replications. To study this specific design, we attempt to reproduce results from three prominent papers: Matching Nets, Prototypical Networks, and TADAM. We analyze on the miniImagenet dataset on the standard classification task in the 5-ways, 5-shots learning setting at test time. We find that the selected implementations exhibit stability across random seed, and repeats.","tags":["Few-shot Learning"],"title":"Reproducibility and Stability Analysis in Metric-Based Few-Shot Learning","type":"publication"},{"authors":["Dzmitry Bahdanau","Shikhar Murty","Michael Noukhovitch","Thien Huu Nguyen","Harm de Vries","Aaron Courville"],"categories":null,"content":"’ \u0026#39;\n","date":1538006400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1538006400,"objectID":"2d4294f1918410834e891a152582e556","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/dzmitrybahdanausysticlr2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/dzmitrybahdanausysticlr2019/","section":"publication","summary":"Numerous models for grounded language understanding have been recently proposed, including (i) generic models that can be easily adapted to any given task and (ii) intuitively appealing modular models that require background knowledge to be instantiated. We compare both types of models in how much they lend themselves to a particular form of systematic generalization. Using a synthetic VQA test, we evaluate which models are capable of reasoning about all possible object pairs after training on only a small subset of them. Our findings show that the generalization of modular models is much more systematic and that it is highly sensitive to the module layout, i.e. to how exactly the modules are connected. We furthermore investigate if modular models that generalize well could be made more end-to-end by learning their layout and parametrization. We find that end-to-end methods from prior work often learn inappropriate layouts or parametrizations that do not facilitate systematic generalization. Our results suggest that, in addition to modularity, systematic generalization in language understanding may require explicit regularizers or priors.","tags":["Systematic Generalization"],"title":"Systematic Generalization: What Is Required and Can It Be Learned?","type":"publication"},{"authors":["Misha Benjamin","Paul Gagnon","Negar Rostamzadeh","Christopher Pal","Yoshua Bengio","Alex Shee"],"categories":null,"content":"’ \u0026#39;\n","date":1538006400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1538006400,"objectID":"11a053e2ed7d2fb648f5c5648226b3b9","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/mishabenjamintowaiclrworkshops2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/mishabenjamintowaiclrworkshops2019/","section":"publication","summary":"This paper provides a taxonomy for the licensing of data in the fields of artificial intelligence and machine learning. The paper's goal is to build towards a common framework for data licensing akin to the licensing of open source software. Increased transparency and resolving conceptual ambiguities in existing licensing language are two noted benefits of the approach proposed in the paper. In parallel, such benefits may help foster fairer and more efficient markets for data through bringing about clearer tools and concepts that better define how data can be used in the fields of AI and ML. The paper's approach is summarized in a new family of data license language - \\textit{the Montreal Data License (MDL)}. Alongside this new license, the authors and their collaborators have developed a web-based tool to generate license language espousing the taxonomies articulated in this paper.","tags":["Dataset"],"title":"Towards Standardization of Data Licenses: The Montreal Data License","type":"publication"},{"authors":["Mufan Li","Gintare Karolina Dziugaite","Philippe Casgrain"],"categories":null,"content":"’ \u0026#39;\n","date":1536278400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1536278400,"objectID":"92dfa44fdf5fdfa76ac5fdf676f0a4d6","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/mufanlianeswiml2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/mufanlianeswiml2018/","section":"publication","summary":"’ '","tags":["Guarranties","Optimization"],"title":"An escape-time analysis of SGD","type":"publication"},{"authors":["Negar Rostamzadeh","Seyedarian (Arian) Hosseini","Thomas Boquet","Wojciech Stokowiec","Ying Zhang","Christian Jauvin","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1536278400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1536278400,"objectID":"dbda7eba0a9f8ab34576659637b379c2","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/negarrostamzadehfashwiml2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/negarrostamzadehfashwiml2018/","section":"publication","summary":"We introduce a new dataset of 293,008 high definition (1360 x 1360 pixels) fashion images paired with item descriptions provided by professional stylists. Each item is photographed from a variety of angles. We provide baseline results on 1) high-resolution image generation, and 2) image generation conditioned on the given text descriptions. We invite the community to improve upon these baselines. In this paper, we also outline the details of a challenge that we are launching based upon this dataset.","tags":["Unsupervised Learning","Generative Models","Dataset"],"title":"Fashion-Gen: The Generative Fashion Dataset and Challenge","type":"publication"},{"authors":["Konrad Zolna","Michal Zajac","Negar Rostamzadeh","Pedro O. Pinheiro"],"categories":null,"content":"’ \u0026#39;\n","date":1536105600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1536105600,"objectID":"5309f3484400e62dca8b81221d220346","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/konradzolnaadveaaaistudentabstract2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/konradzolnaadveaaaistudentabstract2019/","section":"publication","summary":"Neural networks are prone to adversarial attacks. In general, such attacks deteriorate the quality of the input by either slightly modifying most of its pixels, or by occluding it with a patch. In this paper, we propose a method that keeps the image unchanged and only adds an adversarial framing on the border of the image. We show empirically that our method is able to successfully attack state-of-the-art methods on both image and video classification problems. Notably, the proposed method results in a universal attack which is very fast at test time. Source code can be found at this https URL .","tags":["Computer Vision","Image Classification","Video Classification","Adversarial Learning"],"title":"Adversarial Framing for Image and Video Classification","type":"publication"},{"authors":["Quentin Cappart","Emmanuel Goutierre","David Bergman","Louis-Martin Rousseau"],"categories":null,"content":"’ \u0026#39;\n","date":1536105600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1536105600,"objectID":"b8a948905417a4219279cccd93aaa857","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/quentincappartimpraaai2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/quentincappartimpraaai2019/","section":"publication","summary":"Finding tight bounds on the optimal solution is a critical element of practical solution methods for discrete optimization problems. In the last decade, decision diagrams (DDs) have brought a new perspective on obtaining upper and lower bounds that can be significantly better than classical bounding mechanisms, such as linear relaxations. It is well known that the quality of the bounds achieved through this flexible bounding method is highly reliant on the ordering of variables chosen for building the diagram, and finding an ordering that optimizes standard metrics is an NP-hard problem. In this paper, we propose an innovative and generic approach based on deep reinforcement learning for obtaining an ordering for tightening the bounds obtained with relaxed and restricted DDs. We apply the approach to both the Maximum Independent Set Problem and the Maximum Cut Problem. Experimental results on synthetic instances show that the deep reinforcement learning approach, by achieving tighter objective function bounds, generally outperforms ordering methods commonly used in the literature when the distribution of instances is known. To the best knowledge of the authors, this is the first paper to apply machine learning to directly improve relaxation bounds obtained by general-purpose bounding mechanisms for combinatorial optimization problems.","tags":["Reinforcement Learning","Optimization"],"title":"Improving Optimization Bounds using Machine Learning: Decision Diagrams meet Deep Reinforcement Learning","type":"publication"},{"authors":["Daniel Hernandez","Lukas Schneider","Pau Cebrian","Antonio Espinosa","David Vazquez","Antonio M. Lopez","Uwe Franke","Marc Pollefeys","Juan C. Moure"],"categories":null,"content":"’ \u0026#39;\n","date":1531267200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1531267200,"objectID":"842da42118596c889525bdb75ac3e6e6","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/danielhernandezslanijcv2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/danielhernandezslanijcv2019/","section":"publication","summary":"This work presents and evaluates a novel compact scene representation based on Stixels that infers geometric and semantic information. Our approach overcomes the previous rather restrictive geometric assumptions for Stixels by introducing a novel depth model to account for non-flat roads and slanted objects. Both semantic and depth cues are used jointly to infer the scene representation in a sound global energy minimization formulation. \nFurthermore, a novel approximation scheme is introduced in order to significantly reduce the computational complexity of the Stixel algorithm, and then achieve real-time computation capabilities. The idea is to first perform an over-segmentation of the image, discarding the unlikely Stixel cuts, and apply the algorithm only on the remaining Stixel cuts. This work presents a novel over-segmentation strategy based on a Fully Convolutional Network (FCN), which outperforms an approach based on using local extrema of the disparity map. \nWe evaluate the proposed methods in terms of semantic and geometric accuracy as well as run-time on four publicly available benchmark datasets. Our approach maintains accuracy on flat road scene datasets while improving substantially on a novel non-flat road dataset.","tags":["3D"],"title":"Slanted Stixels: A way to represent steep streets","type":"publication"},{"authors":["Taesup Kim","Jaesik Yoon","Ousmane Amadou Dia","Sungwoong Kim","Yoshua Bengio","Sungjin Ahn"],"categories":null,"content":"’ \u0026#39;\n","date":1530144000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1530144000,"objectID":"0874aa730c7d7bac72e1ca197aa6f3b3","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/taesupkimbayemais2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/taesupkimbayemais2018/","section":"publication","summary":"Learning to infer Bayesian posterior from a few-shot dataset is an important step towards robust meta-learning due to the model uncertainty inherent in the problem. In this paper, we propose a novel Bayesian model-agnostic meta-learning method. The proposed method combines scalable gradient-based meta-learning with nonparametric variational inference in a principled probabilistic framework. During fast adaptation, the method is capable of learning complex uncertainty structure beyond a point estimate or a simple Gaussian approximation. In addition, a robust Bayesian meta-update mechanism with a new meta-loss prevents overfitting during meta-update. Remaining an efficient gradient-based meta-learner, the method is also model-agnostic and simple to implement. Experiment results show the accuracy and robustness of the proposed method in various tasks: sinusoidal regression, image classification, active learning, and reinforcement learning.","tags":["Meta-Learning"],"title":"Bayesian Model-Agnostic Meta-Learning","type":"publication"},{"authors":["Rey Reza Wiyatno","Anqi Xu"],"categories":null,"content":"’ \u0026#39;\n","date":1530144000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1530144000,"objectID":"a8414a84b6e2e376a2da1692c47b9f50","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/reyrezawiyatnomaximais2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/reyrezawiyatnomaximais2018/","section":"publication","summary":"The Jacobian-based Saliency Map Attack is a family of adversarial attack methods for fooling classification models, such as deep neural networks for image classification tasks. By saturating a few pixels in a given image to their maximum or minimum values, JSMA can cause the model to misclassify the resulting adversarial image as a specified erroneous target class. We propose two variants of JSMA, one which removes the requirement to specify a target class, and another that additionally does not need to specify whether to only increase or decrease pixel intensities. Our experiments highlight the competitive speeds and qualities of these variants when applied to datasets of hand-written digits and natural scenes.","tags":["Adversarial Attacks"],"title":"Maximal Jacobian-based Saliency Map Attack","type":"publication"},{"authors":["Félix G. Harvey","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1528156800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1528156800,"objectID":"b344b3f53e1712c28b840a2518c48c23","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/felixg.harveyrecusiggraphasia2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/felixg.harveyrecusiggraphasia2018/","section":"publication","summary":"Manually authoring transition animations for a complete locomotion system can be a tedious and time-consuming task, especially for large games that allow complex and constrained locomotion movements, where the number of transitions grows exponentially with the number of states. In this paper, we present a novel approach, based on deep recurrent neural networks, to automatically generate such transitions given a past context of a few frames and a target character state to reach. We present the Recurrent Transition Network (RTN), based on a modified version of the Long-Short-Term-Memory (LSTM) network, designed specifically for transition generation and trained without any gait, phase, contact or action labels. We further propose a simple yet principled way to initialize the hidden states of the LSTM layer for a given sequence which improves the performance and generalization to new motions. We both quantitatively and qualitatively evaluate our system and show that making the network terrain-aware by adding a local terrain representation to the input yields better performance for rough-terrain navigation on long transitions. Our system produces realistic and fluid transitions that rival the quality of Motion Capture-based ground-truth motions, even before applying any inverse-kinematics postprocess. Direct benefits of our approach could be to accelerate the creation of transition variations for large coverage, or even to entirely replace transition nodes in an animation graph. We further explore applications of this model in a animation super-resolution setting where we temporally decompress animations saved at 1 frame per second and show that the network is able to reconstruct motions that are hard to distinguish from un-compressed locomotion sequences.","tags":["Sequential Learning"],"title":"Recurrent Transition Networks for Character Locomotion","type":"publication"},{"authors":["Laure Delisle","Alfredo Kalaitzis","Krzysztof Majewski","Archy de Berker","Milena Marin","Julien Cornebise"],"categories":null,"content":"’ \u0026#39;\n","date":1526601600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1526601600,"objectID":"100af728733953fd326cf7188283d476","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/lauredelislealarneuripsworkshops2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/lauredelislealarneuripsworkshops2018/","section":"publication","summary":"We report the first, to the best of our knowledge, hand-in-hand collaboration between human rights activists and machine learners, leveraging crowd-sourcing to study online abuse against women on Twitter. On a technical front, we carefully curate an unbiased yet low-variance dataset of labeled tweets, analyze it to account for the variability of abuse perception, and establish baselines, preparing it for release to community research efforts. On a social impact front, this study provides the technical backbone for a media campaign aimed at raising public and deciders' awareness and elevating the standards expected from social media companies.","tags":null,"title":"A large-scale crowd-sourced analysis of abuse against women journalists and politicians on Twitter","type":"publication"},{"authors":["Taesup Kim","Jaesik Yoon","Sungwoong Kim","Yoshua Bengio","Sungjin Ahn"],"categories":null,"content":"’ \u0026#39;\n","date":1526601600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1526601600,"objectID":"6589a412f2b2c93c0b97a39f91820a0e","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/taesupkimbayeneurips2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/taesupkimbayeneurips2018/","section":"publication","summary":"Learning to infer Bayesian posterior from a few-shot dataset is an important step towards robust meta-learning due to the model uncertainty inherent in the problem. In this paper, we propose a novel Bayesian model-agnostic meta-learning method. The proposed method combines scalable gradient-based meta-learning with nonparametric variational inference in a principled probabilistic framework. During fast adaptation, the method is capable of learning complex uncertainty structure beyond a point estimate or a simple Gaussian approximation. In addition, a robust Bayesian meta-update mechanism with a new meta-loss prevents overfitting during meta-update. Remaining an efficient gradient-based meta-learner, the method is also model-agnostic and simple to implement. Experiment results show the accuracy and robustness of the proposed method in various tasks: sinusoidal regression, image classification, active learning, and reinforcement learning.","tags":["Meta-Learning"],"title":"Bayesian Model-Agnostic Meta-Learning","type":"publication"},{"authors":["Gintare Karolina Dziugaite","Daniel M. Roy"],"categories":null,"content":"’ \u0026#39;\n","date":1526601600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1526601600,"objectID":"bda24df6be027d76939dafc3a3a279db","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/gintarekarolinadziugaitedataneurips2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/gintarekarolinadziugaitedataneurips2018/","section":"publication","summary":"The Probably Approximately Correct (PAC) Bayes framework (McAllester, 1999) can incorporate knowledge about the learning algorithm and (data) distribution through the use of distribution-dependent priors, yielding tighter generalization bounds on data-dependent posteriors. Using this flexibility, however, is difficult, especially when the data distribution is presumed to be unknown. We show how an {\\epsilon}-differentially private data-dependent prior yields a valid PAC-Bayes bound, and then show how non-private mechanisms for choosing priors can also yield generalization bounds. As an application of this result, we show that a Gaussian prior mean chosen via stochastic gradient Langevin dynamics (SGLD; Welling and Teh, 2011) leads to a valid PAC-Bayes bound given control of the 2-Wasserstein distance to an {\\epsilon}-differentially private stationary distribution. We study our data-dependent bounds empirically, and show that they can be nonvacuous even when other distribution-dependent bounds are vacuous.","tags":null,"title":"Data-dependent PAC-Bayes priors via differential privacy","type":"publication"},{"authors":["Chin-Wei Huang","Shawn Tan","Alexandre Lacoste","Aaron Courville"],"categories":null,"content":"’ \u0026#39;\n","date":1526601600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1526601600,"objectID":"5e73cccb248381fcd9abc0b3b0c351f8","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/chin-weihuangimprneurips2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/chin-weihuangimprneurips2018/","section":"publication","summary":"Despite the advances in the representational capacity of approximate distributions for variational inference, the optimization process can still limit the density that is ultimately learned. We demonstrate the drawbacks of biasing the true posterior to be unimodal, and introduce Annealed Variational Objectives (AVO) into the training of hierarchical variational methods. Inspired by Annealed Importance Sampling, the proposed method facilitates learning by incorporating energy tempering into the optimization objective. In our experiments, we demonstrate our method's robustness to deterministic warm up, and the benefits of encouraging exploration in the latent space.","tags":null,"title":"Improving Explorability in Variational Inference with Annealed Variational Objectives","type":"publication"},{"authors":["Alexandre Piche","Valentin Thomas","Cyril Ibrahim","Yoshua Bengio","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1526601600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1526601600,"objectID":"c9be8e93b0526cbecca32796c7a140cc","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/alexandrepicheprobiclr2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/alexandrepicheprobiclr2019/","section":"publication","summary":"In this work, we propose a novel formulation of planning which views it as a probabilistic inference problem over future optimal trajectories. This enables us to use sampling methods, and thus, tackle planning in continuous domains using a fixed computational budget.   We design a new algorithm,  Sequential Monte Carlo Planning, by leveraging classical methods in Sequential Monte Carlo and Bayesian smoothing in the context of control as inference. Furthermore, we show that Sequential Monte Carlo Planning can capture multimodal policies and can quickly learn continuous control tasks.","tags":["Planning"],"title":"Probabilistic Planning with Sequential Monte Carlo","type":"publication"},{"authors":["Konrad Zolna","Negar Rostamzadeh","Yoshua Bengio","Sungjin Ahn","Pedro O. Pinheiro"],"categories":null,"content":"’ \u0026#39;\n","date":1526601600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1526601600,"objectID":"7bc2df69bc08b51fe4c8b5a71bd7f59d","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/konradzolnareinneuripsworkshops2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/konradzolnareinneuripsworkshops2018/","section":"publication","summary":"Imitation learning is an effective alternative approach to learn a policy when the reward function is sparse. In this paper, we consider a challenging setting where an agent and an expert use different actions from each other. We assume that the agent has access to a sparse reward function and state-only expert observations. We propose a method which gradually balances between the imitation learning cost and the reinforcement learning objective. In addition, this method adapts the agent's policy based on either mimicking expert behavior or maximizing sparse reward. We show, through navigation scenarios, that (i) an agent is able to efficiently leverage sparse rewards to outperform standard state-only imitation learning, (ii) it can learn a policy even when its actions are different from the expert, and (iii) the performance of the agent is not bounded by that of the expert, due to the optimized usage of sparse rewards.","tags":["Reinforcement Learning","Imitation Learning"],"title":"Reinforced Imitation in Heterogeneous Action Space","type":"publication"},{"authors":["Nan Rosemary Ke","Anirudh Goyal","Olexa Bilaniuk","Jonathan Binas","Michael C. Mozer","Christopher Pal","Yoshua Bengio"],"categories":null,"content":"’ \u0026#39;\n","date":1526601600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1526601600,"objectID":"cb8632da4624d48caf9383ed3c8859ae","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/nanrosemarykesparneurips2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/nanrosemarykesparneurips2018/","section":"publication","summary":"Learning long-term dependencies in extended temporal sequences requires credit assignment to events far back in the past. The most common method for training recurrent neural networks, back-propagation through time (BPTT), requires credit information to be propagated backwards through every single step of the forward computation, potentially over thousands or millions of time steps. This becomes computationally expensive or even infeasible when used with long sequences. Importantly, biological brains are unlikely to perform such detailed reverse replay over very long sequences of internal states (consider days, months, or years.) However, humans are often reminded of past memories or mental states which are associated with the current mental state. We consider the hypothesis that such memory associations between past and present could be used for credit assignment through arbitrarily long sequences, propagating the credit assigned to the current state to the associated past state. Based on this principle, we study a novel algorithm which only back-propagates through a few of these temporal skip connections, realized by a learned attention mechanism that associates current states with relevant past states. We demonstrate in experiments that our method matches or outperforms regular BPTT and truncated BPTT in tasks involving particularly long-term dependencies, but without requiring the biologically implausible backward replay through the whole history of states. Additionally, we demonstrate that the proposed method transfers to longer sequences significantly better than LSTMs trained with BPTT and LSTMs trained with full self-attention.","tags":null,"title":"Sparse Attentive Backtracking: Temporal Credit Assignment Through Reminding","type":"publication"},{"authors":["Boris N. Oreshkin","Pau Rodriguez","Alexandre Lacoste"],"categories":null,"content":"’ \u0026#39;\n","date":1526601600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1526601600,"objectID":"b0cb306c0e58d3b5e6f20818aa830f3a","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/borisn.oreshkintadaneurips2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/borisn.oreshkintadaneurips2018/","section":"publication","summary":"Few-shot learning has become essential for producing models that generalize from few examples. In this work, we identify that metric scaling and metric task conditioning are important to improve the performance of few-shot algorithms. Our analysis reveals that simple metric scaling completely changes the nature of few-shot algorithm parameter updates. Metric scaling provides improvements up to 14% in accuracy for certain metrics on the mini-Imagenet 5-way 5-shot classification task. We further propose a simple and effective way of conditioning a learner on the task sample set, resulting in learning a task-dependent metric space. Moreover, we propose and empirically test a practical end-to-end optimization procedure based on auxiliary task co-training to learn a task-dependent metric space. The resulting few-shot learning model based on the task-dependent scaled metric achieves state of the art on mini-Imagenet. We confirm these results on another few-shot dataset that we introduce in this paper based on CIFAR100. Our code is publicly available at this https URL.","tags":["Few-shot Learning","Computer Vision","Image Classification"],"title":"TADAM: Task dependent adaptive metric for improved few-shot learning","type":"publication"},{"authors":["Gabriel Arpino","Gintare Karolina Dziugaite","Daniel M. Roy"],"categories":null,"content":"’ \u0026#39;\n","date":1526601600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1526601600,"objectID":"fefda490f6bda72702da72870090a61e","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/gabrielarpinotighneuripsworkshops2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/gabrielarpinotighneuripsworkshops2018/","section":"publication","summary":"’ '","tags":["Guarranties","Optimization"],"title":"Tighter Nonvacuous PAC-Bayes Bounds: Beyond Stability of SGD","type":"publication"},{"authors":["Raymond Li","Samira Ebrahimi Kahou","Hannes Schulz","Vincent Michalski","Laurent Charlin","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1526601600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1526601600,"objectID":"f299f5513127ea68ee058a20add1513c","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/raymondlitowaneurips2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/raymondlitowaneurips2018/","section":"publication","summary":"There has been growing interest in using neural networks and deep learning techniques to create dialogue systems. Conversational recommendation is an interesting setting for the scientific exploration of dialogue with natural language as the associated discourse involves goal-driven dialogue that often transforms naturally into more free-form chat. This paper provides two contributions. First, until now there has been no publicly available large-scale dataset consisting of real-world dialogues centered around recommendations. To address this issue and to facilitate our exploration here, we have collected ReDial, a dataset consisting of over 10,000 conversations centered around the theme of providing movie recommendations. We make this data available to the community for further research. Second, we use this dataset to explore multiple facets of conversational recommendations. In particular we explore new neural architectures, mechanisms, and methods suitable for composing conversational recommendation systems. Our dataset allows us to systematically probe model sub-components addressing different parts of the overall problem domain ranging from: sentiment analysis and cold-start recommendation generation to detailed aspects of how natural language is used in this setting in the real world. We combine such sub-components into a full-blown dialogue system and examine its behavior.","tags":["Natural Language Processing","Dialogs","Recommender Systems"],"title":"Towards Deep Conversational Recommendations","type":"publication"},{"authors":["Sandeep Subramanian","Sai Rajeswar Mudumba","Alessandro Sordoni","Adam Trischler","Aaron Courville","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1526601600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1526601600,"objectID":"5cb916e1f4e5d7894067ca912406fc36","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/sandeepsubramaniantowaneurips2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/sandeepsubramaniantowaneurips2018/","section":"publication","summary":"Recent progress in deep generative models has been fueled by two paradigms – au- toregressive and adversarial models. We propose a combination of both approaches with the goal of learning generative models of text. Our method first produces a high-level sentence outline and then generates words sequentially, conditioning on both the outline and the previous outputs. We generate outlines with an adversarial model trained to approximate the distribution of sentences in a latent space induced by general-purpose sentence encoders. This provides strong, informative condi- tioning for the autoregressive stage. Our quantitative evaluations suggests that conditioning information from generated outlines is able to guide the autoregressive model to produce realistic samples, comparable to maximum-likelihood trained language models, even at high temperatures with multinomial sampling. Qualita- tive results also demonstrate that this generative procedure yields natural-looking sentences and interpolations.","tags":["Text Generation","Natural Language Processing","Adversarial Learning"],"title":"Towards Text Generation with Adversarially Learned Neural Outlines","type":"publication"},{"authors":["Joel Ruben Antony Moniz","Christopher Beckham","Simon Rajotte","Sina Honari","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1526601600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1526601600,"objectID":"39daeccb5c0f5fafa82be3f5305cee8f","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/joelrubenantonymonizunsuneurips2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/joelrubenantonymonizunsuneurips2018/","section":"publication","summary":"We present an unsupervised approach for learning to estimate three dimensional (3D) facial structure from a single image while also predicting 3D viewpoint transformations that match a desired pose and facial geometry. We achieve this by inferring the depth of facial keypoints of an input image in an unsupervised manner, without using any form of ground-truth depth information. We show how it is possible to use these depths as intermediate computations within a new backpropable loss to predict the parameters of a 3D affine transformation matrix that maps inferred 3D keypoints of an input face to the corresponding 2D keypoints on a desired target facial geometry or pose. Our resulting approach, called DepthNets, can therefore be used to infer plausible 3D transformations from one face pose to another, allowing faces to be frontalized, transformed into 3D models or even warped to another pose and facial geometry. Lastly, we identify certain shortcomings with our formulation, and explore adversarial image translation techniques as a post-processing step to re-synthesize complete head shots for faces re-targeted to different poses or identities.","tags":["Unsupervised Learning","3D","Image Processing"],"title":"Unsupervised Depth Estimation, 3D Face Rotation and Replacement","type":"publication"},{"authors":["Pau Rodriguez","Diego Velazquez","Guillem Cucurull","Josep M. Gonfaus","F. Xavier Roca","Jordi Gonzalez"],"categories":null,"content":"’ \u0026#39;\n","date":1525910400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1525910400,"objectID":"ce765320260e1702d03a20cc2e342c7b","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/paurodriguezpayaieeetm2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/paurodriguezpayaieeetm2018/","section":"publication","summary":"Fine-grained image recognition is central to many multimedia tasks such as search, retrieval and captioning. Unfortunately, these tasks are still challenging since the appearance of samples of the same class can be more different than those from different classes. Attention has been typically implemented in neural networks by selecting the most informative regions of the image that improve classification. In contrast, in this paper, attention is not applied at the image level but to the convolutional feature activations. In essence, with our approach, the neural model learns to attend to lower-level feature activations without requiring part annotations and uses those activations to update and rectify the output likelihood distribution. The proposed mechanism is modular, architecture-independent and efficient in terms of both parameters and computation required. Experiments demonstrate that well-known networks such as Wide Residual Networks and ResNeXt, when augmented with our approach, systematically improve their classification accuracy and become more robust to changes in deformation and pose and to the presence of clutter. As a result, our proposal reaches state-of-the-art classification accuracies in CIFAR-10, the Adience gender recognition task, Stanford Dogs, and UEC-Food100 while obtaining competitive performance in ImageNet, CIFAR-100, CUB200 Birds, and Stanford Cars. In addition, we analyze the different components of our model, showing that the proposed attention modules succeed in finding the most discriminative regions of the image. Finally, as a proof of concept, we demonstrate that with only local predictions, an augmented neural network can successfully classify an image before reaching any fully connected layer, thus reducing the computational amount up to 10%.","tags":["Computer Vision","Image Classification","Attention"],"title":"Pay attention to the activations: a modular attention mechanism for fine-grained image recognition","type":"publication"},{"authors":["Titouan Parcollet","Ying Zhang","Mohamed Morchid","Chiheb Trabelsi","Georges Linarès","Renato De Mori","Yoshua Bengio"],"categories":null,"content":"’ \u0026#39;\n","date":1521763200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1521763200,"objectID":"9e17e9c6f0b6353a9a1741febea5ee47","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/titouanparcolletquatinterspeech2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/titouanparcolletquatinterspeech2018/","section":"publication","summary":"Recently, the connectionist temporal classification (CTC) model coupled with recurrent (RNN) or convolutional neural networks (CNN), made it easier to train speech recognition systems in an end-to-end fashion. However in real-valued models, time frame components such as mel-filter-bank energies and the cepstral coefficients obtained from them, together with their first and second order derivatives, are processed as individual elements, while a natural alternative is to process such components as composed entities. We propose to group such elements in the form of quaternions and to process these quaternions using the established quaternion algebra. Quaternion numbers and quaternion neural networks have shown their efficiency to process multidimensional inputs as entities, to encode internal dependencies, and to solve many tasks with less learning parameters than real-valued models. This paper proposes to integrate multiple feature views in quaternion-valued convolutional neural network (QCNN), to be used for sequence-to-sequence mapping with the CTC model. Promising results are reported using simple QCNNs in phoneme recognition experiments with the TIMIT corpus. More precisely, QCNNs obtain a lower phoneme error rate (PER) with less learning parameters than a competing model based on real-valued CNNs.","tags":["Speech Recognition"],"title":"Quaternion Convolutional Neural Networks for End-to-End Automatic Speech Recognition","type":"publication"},{"authors":["Issam H. Laradji","Negar Rostamzadeh","Pedro O. Pinheiro","David Vazquez","Mark Schmidt"],"categories":null,"content":"’ \u0026#39;\n","date":1520985600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1520985600,"objectID":"46118e5f55e975864352980cb2fc9be7","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/issamh.laradjiwhereccv2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/issamh.laradjiwhereccv2018/","section":"publication","summary":"Object counting is an important task in computer vision due to its growing demand in applications such as surveillance, traffic monitoring, and counting everyday objects. State-of-the-art methods use regression-based optimization where they explicitly learn to count the objects of interest. These often perform better than detection-based methods that need to learn the more difficult task of predicting the location, size, and shape of each object. However, we propose a detection-based method that does not need to estimate the size and shape of the objects and that outperforms regression-based methods. Our contributions are three-fold: (1) we propose a novel loss function that encourages the network to output a single blob per object instance using point-level annotations only; (2) we design two methods for splitting large predicted blobs between object instances; and (3) we show that our method achieves new state-of-the-art results on several challenging datasets including the Pascal VOC and the Penguins dataset. Our method even outperforms those that use stronger supervision such as depth features, multi-point annotations, and bounding-box labels.","tags":["Computer Vision","Object Counting","Yea"],"title":"Where are the Blobs: Counting by Localization with Point Supervision","type":"publication"},{"authors":["Alberto Camacho","Rodrigo Toro Icarte","Toryn Q. Klassen","Richard Valenzano","Sheila A. McIlraith"],"categories":null,"content":"’ \u0026#39;\n","date":1517529600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1517529600,"objectID":"8f637f3e1ea237e32b2f93ec05d4ab52","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/albertocamacholtlaijcai2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/albertocamacholtlaijcai2018/","section":"publication","summary":"In Reinforcement Learning (RL), an agent is guided by the rewards it receives from the reward function. Unfortunately, it may take many interactions with the environment to learn from sparse rewards, and it can be challenging to specify reward functions that reflect complex reward-worthy behavior. We propose using reward machines (RMs), which are automata-based representations that expose reward function structure, as a normal form representation for reward functions. We show how specifications of reward in various formal languages, including LTL and other regular languages, can be automatically translated into RMs, easing the burden of complex reward function specification. We then show how the exposed structure of the reward function can be exploited by tailored q-learning algorithms and automated reward shaping techniques in order to improve the sample efficiency of reinforcement learning methods. Experiments show that these RM-tailored techniques significantly outperform state-of-the-art (deep) RL algorithms, solving problems that otherwise cannot reasonably be solved by existing approaches.","tags":["Natural Language Processing","Reinforcement Learning"],"title":"LTL and Beyond: Formal Languages for Reward Function Specification in Reinforcement Learning","type":"publication"},{"authors":["Rodrigo Toro Icarte","Toryn Q. Klassen","Richard Valenzano","Sheila A. McIlraith"],"categories":null,"content":"’ \u0026#39;\n","date":1515974400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1515974400,"objectID":"040b5196a50292b8964335e22e99beda","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/rodrigotoroicarteadvicanadianai2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/rodrigotoroicarteadvicanadianai2018/","section":"publication","summary":"Convergence to an optimal policy using model-based rein- forcement learning can require significant exploration of the environment. In some settings such exploration is costly or even impossible, such as in cases where simulators are not available, or where there are prohibitively large state spaces. In this paper we examine the use of advice to guide the search for an optimal policy. To this end we propose a rich language for providing advice to a reinforcement learning agent. Unlike constraints which potentially eliminate optimal policies, advice offers guidance for the exploration, while preserving the guarantee of convergence to an op- timal policy. Experimental results on deterministic grid worlds demon- strate the potential for good advice to reduce the amount of exploration required to learn a satisficing or optimal policy, while maintaining ro- bustness in the face of incomplete or misleading advice.","tags":["Reinforcement Learning"],"title":"Advice-Based Exploration in Model-Based Reinforcement Learning","type":"publication"},{"authors":["Negar Rostamzadeh","Seyedarian (Arian) Hosseini","Thomas Boquet","Wojciech Stokowiec","Ying Zhang","Christian Jauvin","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1515456000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1515456000,"objectID":"4512c8b9131f40b2b8d0e1e670ec4e2b","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/negarrostamzadehfashicmlworkshops2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/negarrostamzadehfashicmlworkshops2018/","section":"publication","summary":"We introduce a new dataset of 293,008 high definition (1360 x 1360 pixels) fashion images paired with item descriptions provided by professional stylists. Each item is photographed from a variety of angles. We provide baseline results on 1) high-resolution image generation, and 2) image generation conditioned on the given text descriptions. We invite the community to improve upon these baselines. In this paper, we also outline the details of a challenge that we are launching based upon this dataset.","tags":["Unsupervised Learning","Dataset"],"title":"Fashion-Gen: The Generative Fashion Dataset and Challenge","type":"publication"},{"authors":["Ishmael Belghazi","Sai Rajeswar Mudumba","Olivier Mastropietro","Negar Rostamzadeh","Jovana Mitrovic","Aaron Courville"],"categories":null,"content":"’ \u0026#39;\n","date":1515456000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1515456000,"objectID":"d4db31f624a9b85f54bbc9bb8e1da08c","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/ishmaelbelghazihiericmlworkshops2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/ishmaelbelghazihiericmlworkshops2018/","section":"publication","summary":"We propose a novel hierarchical generative model with a simple Markovian structure and a corresponding inference model. Both the generative and inference model are trained using the adversarial learning paradigm. We demonstrate that the hierarchical structure supports the learning of progressively more abstract representations as well as providing semantically meaningful reconstructions with different levels of fidelity. Furthermore, we show that minimizing the Jensen-Shanon divergence between the generative and inference network is enough to minimize the reconstruction error. The resulting semantically meaningful hierarchical latent structure discovery is exemplified on the CelebA dataset. There, we show that the features learned by our model in an unsupervised way outperform the best handcrafted features. Furthermore, the extracted features remain competitive when compared to several recent deep supervised approaches on an attribute prediction task on CelebA. Finally, we leverage the model's inference network to achieve state-of-the-art performance on a semi-supervised variant of the MNIST digit classification task.","tags":["Adversarial Learning","Hierarchical Learning"],"title":"Hierarchical Adversarially Learned Inference","type":"publication"},{"authors":["Chin-Wei Huang","David Krueger","Alexandre Lacoste","Aaron Courville"],"categories":null,"content":"’ \u0026#39;\n","date":1515456000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1515456000,"objectID":"dd6af5b3e07c17248065c596b8bc6eb6","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/chin-weihuangneuricml2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/chin-weihuangneuricml2018/","section":"publication","summary":"Normalizing flows and autoregressive models have been successfully combined to produce state-of-the-art results in density estimation, via Masked Autoregressive Flows (MAF), and to accelerate state-of-the-art WaveNet-based speech synthesis to 20x faster than real-time, via Inverse Autoregressive Flows (IAF). We unify and generalize these approaches, replacing the (conditionally) affine univariate transformations of MAF/IAF with a more general class of invertible univariate transformations expressed as monotonic neural networks. We demonstrate that the proposed neural autoregressive flows (NAF) are universal approximators for continuous probability distributions, and their greater expressivity allows them to better capture multimodal target distributions. Experimentally, NAF yields state-of-the-art performance on a suite of density estimation tasks and outperforms IAF in variational autoencoders trained on binarized MNIST.","tags":["Autoregressive Models","Unsupervised Learning"],"title":"Neural Autoregressive Flow","type":"publication"},{"authors":["Rodrigo Toro Icarte","Toryn Q. Klassen","Richard Valenzano","Sheila A. McIlraith"],"categories":null,"content":"’ \u0026#39;\n","date":1515456000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1515456000,"objectID":"141628e48d5155cb4badc9d8b1325714","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/rodrigotoroicarteusinicml2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/rodrigotoroicarteusinicml2018/","section":"publication","summary":"In this paper we propose Reward Machines – a type of finite state machine that supports the spec- ification of reward functions while exposing re- ward function structure to the learner and support- ing decomposition. We then present Q-Learning for Reward Machines (QRM), an algorithm which appropriately decomposes the reward machine and uses off-policy q-learning to simultaneously learn subpolicies for the different components. QRM is guaranteed to converge to an optimal pol- icy in the tabular case, in contrast to Hierarchical Reinforcement Learning methods which might converge to suboptimal policies. We demonstrate this behavior experimentally in two discrete do- mains. We also show how function approximation methods like neural networks can be incorporated into QRM, and that doing so can find better poli- cies more quickly than hierarchical methods in a domain with a continuous state space.\n","tags":["Reinforcement Learning"],"title":"Using Reward Machines for High-Level Task Specification and Decomposition in Reinforcement Learning","type":"publication"},{"authors":["Michel Deudon","Pierre Cournut","Alexandre Lacoste","Yossiri Adulyasak","Louis-Martin Rousseau"],"categories":null,"content":"’ \u0026#39;\n","date":1513296000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1513296000,"objectID":"84ee5c6966de0e0acdceed65e4a1c6ff","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/micheldeudonlearcpaior2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/micheldeudonlearcpaior2018/","section":"publication","summary":"The aim of the study is to provide interesting insights on how efficient machine learning algorithms could be adapted to solve com- binatorial optimization problems in conjunction with existing heuristic procedures. More specifically, we extend the neural combinatorial opti- mization framework to solve the traveling salesman problem (TSP). In this framework, the city coordinates are used as inputs and the neural network is trained using reinforcement learning to predict a distribution over city permutations. Our proposed framework differs from the one in [1] since we do not make use of the Long Short-Term Memory (LSTM) architecture and we opted to design our own critic to compute a baseline for the tour length which results in more efficient learning. More impor- tantly, we further enhance the solution approach with the well-known 2-opt heuristic. The results show that the performance of the proposed framework alone is generally as good as high performance heuristics (OR- Tools). When the framework is equipped with a simple 2-opt procedure, it could outperform such heuristics and achieve close to optimal results on 2D Euclidean graphs. This demonstrates that our approach based on machine learning techniques could learn good heuristics which, once being enhanced with a simple local search, yield promising results.","tags":["Planning"],"title":"Learning Heuristics for the TSP by Policy Gradient","type":"publication"},{"authors":["Salman Mohammed","Peng Shi","Jimmy Li"],"categories":null,"content":"’ \u0026#39;\n","date":1513296000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1513296000,"objectID":"e095e43aed1219555b27cdcbdd351b53","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/salmanmohammedstronaacl2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/salmanmohammedstronaacl2018/","section":"publication","summary":"We examine the problem of question answering over knowledge graphs, focusing on simple questions that can be answered by the lookup of a single fact. Adopting a straightforward decomposition of the problem into entity detection, entity linking, relation prediction, and evidence combination, we explore simple yet strong baselines. On the popular SimpleQuestions dataset, we find that basic LSTMs and GRUs plus a few heuristics yield accuracies that approach the state of the art, and techniques that do not use neural networks also perform reasonably well. These results show that gains from sophisticated deep learning techniques proposed in the literature are quite modest and that some previous models exhibit unnecessary complexity.","tags":["Natural Language Processing","Knowledge Graphs","Graphs","Question Answering"],"title":"Strong Baselines for Simple Question Answering over Knowledge Graphs with and without Neural Networks","type":"publication"},{"authors":["Pedro O. Pinheiro"],"categories":null,"content":"’ \u0026#39;\n","date":1510704000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1510704000,"objectID":"7e012432ab7f8825fe41400a7e40a8f9","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/pedroo.pinheirounsucvpr2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/pedroo.pinheirounsucvpr2018/","section":"publication","summary":"The objective of unsupervised domain adaptation is to leverage features from a labeled source domain and learn a classifier for an unlabeled target domain, with a similar but different data distribution. Most deep learning approaches to domain adaptation consist of two steps: (i) learn features that preserve a low risk on labeled samples (source domain) and (ii) make the features from both domains to be as indistinguishable as possible, so that a classifier trained on the source can also be applied on the target domain. In general, the classifiers in step (i) consist of fully-connected layers applied directly on the indistinguishable features learned in (ii). In this paper, we propose a different way to do the classification, using similarity learning. The proposed method learns a pairwise similarity function in which classification can be performed by computing similarity between prototype representations of each category. The domain-invariant features and the categorical prototype representations are learned jointly and in an end-to-end fashion. At inference time, images from the target domain are compared to the prototypes and the label associated with the one that best matches the image is outputed. The approach is simple, scalable and effective. We show that our model achieves state-of-the-art performance in different unsupervised domain adaptation scenarios.","tags":["Domain Adaptation","Unsupervised Learning","Metric Learning"],"title":"Unsupervised Domain Adaptation with Similarity Learning","type":"publication"},{"authors":["Rodrigo Toro Icarte","Toryn Q. Klassen","Richard Valenzano","Sheila A. McIlraith"],"categories":null,"content":"’ \u0026#39;\n","date":1510617600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1510617600,"objectID":"1f776fe68b165a79a51b0fa41a1a31ba","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/rodrigotoroicarteteacaamas2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/rodrigotoroicarteteacaamas2018/","section":"publication","summary":"This paper examines the problem of how to teach multiple tasks to a Reinforcement Learning (RL) agent. To this end, we use Linear Temporal Logic (LTL) as a language for specifying multiple tasks in a manner that supports the composition of learned skills. We also propose a novel algorithm that exploits LTL progression and off- policy RL to speed up learning without compromising convergence guarantees, and show that our method outperforms the state-of- the-art approach on randomly generated Minecraft-like grids.","tags":["Reinforcement Learning"],"title":"Teaching Multiple Tasks to an RL Agent using LTL","type":"publication"},{"authors":["Lironne Kurzman","David Vazquez","Issam H. Laradji"],"categories":null,"content":"’ \u0026#39;\n","date":1506470400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1506470400,"objectID":"dc24e38530ae2f2e53b137b33e7485f1","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/lironnekurzmanclasiclrworkshops2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/lironnekurzmanclasiclrworkshops2018/","section":"publication","summary":"We propose a Class-Based Styling method (CBS) that can map different styles for different object classes in real-time. CBS achieves real-time performance by carrying out two steps simultaneously. While a semantic segmentation method is used to obtain the mask of each object class in a video frame, a styling method is used to style that frame globally. Then an object class can be styled by combining the segmentation mask and the styled image. The user can also select multiple styles so that different object classes can have different styles in a single frame. For semantic segmentation, we leverage DABNet that achieves high accuracy, yet only has 0.76 million parameters and runs at 104 FPS. For the style transfer step, we use a popular real-time method proposed by Johnson et al. [7]. We evaluated CBS on a video of the CityScapes dataset and observed high-quality localized style transfer results for different object classes and real-time performance.","tags":["Computer Vision","Style Transfer","Semantic Segmentation"],"title":"Class-Based Styling: Real-time Localized Style Transfer with Semantic Segmentation","type":"publication"},{"authors":["Chiheb Trabelsi","Olexa Bilaniuk","Ying Zhang","Dmitriy Serdyuk","Sandeep Subramanian","João Felipe Santos","Soroush Mehri","Negar Rostamzadeh","Yoshua Bengio","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1506470400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1506470400,"objectID":"742a98842c37d7840b2b7e49921497ae","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/chihebtrabelsideepiclr2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/chihebtrabelsideepiclr2018/","section":"publication","summary":"At present, the vast majority of building blocks, techniques, and architectures for deep learning are based on real-valued operations and representations. However, recent work on recurrent neural networks and older fundamental theoretical analysis suggests that complex numbers could have a richer representational capacity and could also facilitate noise-robust memory retrieval mechanisms. Despite their attractive properties and potential for opening up entirely new neural architectures, complex-valued deep neural networks have been marginalized due to the absence of the building blocks required to design such models. In this work, we provide the key atomic components for complex-valued deep neural networks and apply them to convolutional feed-forward networks and convolutional LSTMs. More precisely, we rely on complex convolutions and present algorithms for complex batch-normalization, complex weight initialization strategies for complex-valued neural nets and we use them in experiments with end-to-end training schemes. We demonstrate that such complex-valued models are competitive with their real-valued counterparts. We test deep complex models on several computer vision tasks, on music transcription using the MusicNet dataset and on Speech Spectrum Prediction using the TIMIT dataset. We achieve state-of-the-art performance on these audio-related tasks.","tags":null,"title":"Deep Complex Networks","type":"publication"},{"authors":["Valentin Thomas","Jules Pondard","Emmanuel Bengio","Marc Sarfati","Philippe Beaudoin","Marie-Jean Meurs","Joelle Pineau","Doina Precup","Yoshua Bengio"],"categories":null,"content":"’ \u0026#39;\n","date":1501718400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1501718400,"objectID":"0710aec9194bbe989e7efed1124506d2","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/valentinthomasindearxiv2017/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/valentinthomasindearxiv2017/","section":"publication","summary":"It has been postulated that a good representation is one that disentangles the underlying explanatory factors of variation. However, it remains an open question what kind of training framework could potentially achieve that. Whereas most previous work focuses on the static setting (e.g., with images), we postulate that some of the causal factors could be discovered if the learner is allowed to interact with its environment. The agent can experiment with different actions and observe their effects. More specifically, we hypothesize that some of these factors correspond to aspects of the environment which are independently controllable, i.e., that there exists a policy and a learnable feature for each such aspect of the environment, such that this policy can yield changes in that feature with minimal changes to other features that explain the statistical variations in the observed data. We propose a specific objective function to find such factors and verify experimentally that it can indeed disentangle independently controllable aspects of the environment without any extrinsic reward signal.","tags":null,"title":"Independently Controllable Factors","type":"publication"},{"authors":["Chris H. Bahnsen","David Vazquez","Antonio M. Lopez","Thomas B. Moeslun"],"categories":null,"content":"’ \u0026#39;\n","date":1501459200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1501459200,"objectID":"6e31143a038ffcdcbb863ef1de2976df","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/chrish.bahnsenlearvisigrapp2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/chrish.bahnsenlearvisigrapp2018/","section":"publication","summary":"Rainfall is a problem in automated traffic surveillance. Rain streaks occlude the road users and degrade the overall visibility which in turn decrease object detection performance. One way of alleviating this is by artificially removing the rain from the images. This requires knowledge of corresponding rainy and rain-free images. Such images are often produced by overlaying synthetic rain on top of rain-free images. However, this method fails to incorporate the fact that rain fall in the entire three-dimensional volume of the scene. To overcome this, we introduce training data from the SYNTHIA virtual world that models rain streaks in the entirety of a scene. We train a conditional Generative Adversarial Network for rain removal and apply it on traffic surveillance images from SYNTHIA and the AAU RainSnow datasets. To measure the applicability of the rain-removed images in a traffic surveillance context, we run the YOLOv2 object detection algorithm on the original and rain-removed frames. The results on SYNTHIA show an 8% increase in detection accuracy compared to the original rain image. Interestingly, we find that high PSNR or SSIM scores do not imply good object detection performance.\n ","tags":["Synthetic Data","Image Processing"],"title":"Learning to Remove Rain in Traffic Surveillance by Using Synthetic Data","type":"publication"},{"authors":["David Krueger","Chin-Wei Huang","Riashat Islam","Ryan Turner","Alexandre Lacoste","Aaron Courville"],"categories":null,"content":"’ \u0026#39;\n","date":1495152000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1495152000,"objectID":"7682bda4c16771bec28bd81aad054f87","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/davidkruegerbayeneuripsworkshops2017/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/davidkruegerbayeneuripsworkshops2017/","section":"publication","summary":"We study Bayesian hypernetworks: a framework for approximate Bayesian inference in neural networks. A Bayesian hypernetwork $\\h$ is a neural network which learns to transform a simple noise distribution, $p(\\vec\\epsilon) = \\N(\\vec 0,\\mat I)$, to a distribution $q(\\pp) := q(h(\\vec\\epsilon))$ over the parameters $\\pp$ of another neural network (the \"primary network\")\\@. We train q with variational inference, using an invertible $\\h$ to enable efficient estimation of the variational lower bound on the posterior $p(\\pp | \\D)$ via sampling. In contrast to most methods for Bayesian deep learning, Bayesian hypernets can represent a complex multimodal approximate posterior with correlations between parameters, while enabling cheap iid sampling of~$q(\\pp)$. In practice, Bayesian hypernets can provide a better defense against adversarial examples than dropout, and also exhibit competitive performance on a suite of tasks which evaluate model uncertainty, including regularization, active learning, and anomaly detection.","tags":null,"title":"Bayesian Hypernetworks","type":"publication"},{"authors":["Alexandre Lacoste","Thomas Boquet","Negar Rostamzadeh","Boris N. Oreshkin","Wonchang Chung","David Krueger"],"categories":null,"content":"’ \u0026#39;\n","date":1495152000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1495152000,"objectID":"40391d2f7f219f33d160ab32baf3a6f6","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/alexandrelacostedeepneuripsworkshops2017/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/alexandrelacostedeepneuripsworkshops2017/","section":"publication","summary":"The recent literature on deep learning offers new tools to learn a rich probability distribution over high dimensional data such as images or sounds. In this work we investigate the possibility of learning the prior distribution over neural network parameters using such tools. Our resulting variational Bayes algorithm generalizes well to new tasks, even when very few training examples are provided. Furthermore, this learned prior allows the model to extrapolate correctly far from a given task's training data on a meta-dataset of periodic signals.","tags":null,"title":"Deep Prior","type":"publication"},{"authors":["Valentin Thomas","Emmanuel Bengio","William Fedus","Jules Pondard","Philippe Beaudoin","Hugo Larochelle","Joelle Pineau","Doina Precup","Yoshua Bengio"],"categories":null,"content":"’ \u0026#39;\n","date":1495152000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1495152000,"objectID":"2d2d02fa38b41df0c1c56b7cbb6098aa","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/valentinthomasdiseneuripsworkshops2017/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/valentinthomasdiseneuripsworkshops2017/","section":"publication","summary":"It has been postulated that a good representation is one that disentangles the underlying explanatory factors of variation. However, it remains an open question what kind of training framework could potentially achieve that. Whereas most previous work focuses on the static setting (e.g., with images), we postulate that some of the causal factors could be discovered if the learner is allowed to interact with its environment. The agent can experiment with different actions and observe their effects. More specifically, we hypothesize that some of these factors correspond to aspects of the environment which are independently controllable, i.e., that there exists a policy and a learnable feature for each such aspect of the environment, such that this policy can yield changes in that feature with minimal changes to other features that explain the statistical variations in the observed data. We propose a specific objective function to find such factors, and verify experimentally that it can indeed disentangle independently controllable aspects of the environment without any extrinsic reward signal.","tags":null,"title":"Disentangling the independently controllable factors of variation by interacting with the world","type":"publication"},{"authors":["Daniel Hewlett","Llion Jones","Alexandre Lacoste","Izzeddin Gur"],"categories":null,"content":"’ \u0026#39;\n","date":1492128000,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1492128000,"objectID":"592df223dbbd0ba2cbaf32c5c3561a6b","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/danielhewlettaccuemnlp2017/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/danielhewlettaccuemnlp2017/","section":"publication","summary":"We introduce a hierarchical architecture for machine reading capable of extracting precise information from long documents. The model divides the document into small, overlapping windows and encodes all windows in parallel with an RNN. It then attends over these window encodings, reducing them to a single encoding, which is decoded into an answer using a sequence decoder. This hierarchical approach allows the model to scale to longer documents without increasing the number of sequential steps. In a supervised setting, our model achieves state of the art accuracy of 76.8 on the WikiReading dataset. We also evaluate the model in a semi-supervised setting by downsampling the WikiReading training set to create increasingly smaller amounts of supervision, while leaving the full unlabeled document corpus to train a sequence autoencoder on document windows. We evaluate models that can reuse autoencoder states and outputs without fine-tuning their weights, allowing for more efficient training and inference.","tags":["Natural Language Processing","Machine Reading","Semi-supervised Learning"],"title":"Accurate Supervised and Semi-Supervised Machine Reading for Long Documents","type":"publication"},{"authors":["Nare Karapetyan","Kelly Benson","Chris McKinney","Perouz Taslakian","Ioannis Rekleitis"],"categories":null,"content":"’ \u0026#39;\n","date":1488326400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1488326400,"objectID":"006712224979d929b917b5fa281f2faa","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/narekarapetyaneffiiros2017/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/narekarapetyaneffiiros2017/","section":"publication","summary":"This paper addresses the complete area coverage problem of a known environment by multiple-robots. Complete area coverage is the problem of moving an end-effector over all available space while avoiding existing obstacles. In such tasks, using multiple robots can increase the efficiency of the area coverage in terms of minimizing the operational time and increase the robustness in the face of robot attrition. Unfortunately, the problem of finding an optimal solution for such an area coverage problem with multiple robots is known to be NP-complete. In this paper we present two approximation heuristics for solving the multi-robot coverage problem. The first solution presented is a direct extension of an efficient single robot area coverage algorithm, based on an exact cellular decomposition. The second algorithm is a greedy approach that divides the area into equal regions and applies an efficient single-robot coverage algorithm to each region. We present experimental results for two algorithms. Results indicate that our approaches provide good coverage distribution between robots and minimize the workload per robot, meanwhile ensuring complete coverage of the area.","tags":["Robotics"],"title":"Efficient Multi-Robot Coverage of a Known Environment","type":"publication"},{"authors":["Florian Shkurti","Wei-Di Chang","Peter Henderson","Md Jahidul Islam","Juan Camilo Gamboa Higuera","Jimmy Li","Travis Manderson","Anqi Xu","Gregory Dudek","Junaed Sattar"],"categories":null,"content":"’ \u0026#39;\n","date":1488326400,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1488326400,"objectID":"025475ba4607361b3d4b36f2124ac537","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/florianshkurtiundeiros2017/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/florianshkurtiundeiros2017/","section":"publication","summary":"We present a robust multi-robot convoying approach that relies on visual detection of the leading agent, thus enabling target following in unstructured 3-D environments. Our method is based on the idea of tracking-by-detection, which interleaves efficient model-based object detection with temporal filtering of image-based bounding box estimation. This approach has the important advantage of mitigating tracking drift (i.e. drifting away from the target object), which is a common symptom of model-free trackers and is detrimental to sustained convoying in practice. To illustrate our solution, we collected extensive footage of an underwater robot in ocean settings, and hand-annotated its location in each frame. Based on this dataset, we present an empirical comparison of multiple tracker variants, including the use of several convolutional neural networks, both with and without recurrent connections, as well as frequency-based model-free trackers. We also demonstrate the practicality of this tracking-by-detection strategy in real-world scenarios by successfully controlling a legged underwater robot in five degrees of freedom to follow another robot's independent motion.","tags":["Robotics"],"title":"Underwater Multi-Robot Convoying using Visual Tracking by Detection","type":"publication"},{"authors":["Luis Barba","Prosenjit Bose","Jean-Lou De Carufel","Mirela Damian","Rolf Fagerberg","André van Renssen","Perouz Taslakian","Sander Verdonschot"],"categories":null,"content":"’ \u0026#39;\n","date":1485907200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1485907200,"objectID":"6785801fec2e530558f6340d8476672e","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/luisbarbacontcg2017/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/luisbarbacontcg2017/","section":"publication","summary":"In this paper, we introduce a variation of the well-studied Yao graphs. Given a set of points S⊂ℝ2 and an angle 0","tags":["Graphs"],"title":"Continuous Yao Graphs","type":"publication"},{"authors":["Daniel Hernandez","Antonio Espinosa","David Vazquez","Antonio M. Lopez","Juan C. Moure"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"569bf0a022960c738dd1f21885f64296","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/danielhernandez3dpeieeet-pds2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/danielhernandez3dpeieeet-pds2021/","section":"publication","summary":"This article presents a GPU-accelerated software design of the recently proposed model of Slanted Stixels, which represents the geometric and semantic information of a scene in a compact and accurate way. We reformulate the measurement depth model to reduce the computational complexity of the algorithm, relying on the confidence of the depth estimation and the identification of invalid values to handle outliers. The proposed massively parallel scheme and data layout for the irregular computation pattern that corresponds to a Dynamic Programming paradigm is described and carefully analyzed in performance terms. Performance is shown to scale gracefully on current generation embedded GPUs. We assess the proposed methods in terms of semantic and geometric accuracy as well as run-time performance on three publicly available benchmark datasets. Our approach achieves real-time performance with high accuracy for 2048 × 1024 image sizes and 4 × 4 Stixel resolution on the low-power embedded GPU of an NVIDIA Tegra Xavier.","tags":["Computer Vision","3D"],"title":"3D Perception with Slanted Stixels on GPU","type":"publication"},{"authors":["Yoshua Bengio","Tristan Deleu","Nasim Rahaman","Nan Rosemary Ke","Sébastien Lachapelle","Olexa Bilaniuk","Anirudh Goyal","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"6e31633a26b2017bd5b0e14cb1c1dec4","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/yoshuabengioameticlr2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/yoshuabengioameticlr2020/","section":"publication","summary":"We propose to meta-learn causal structures based on how fast a learner adapts to new distributions arising from sparse distributional changes, e.g. due to interventions, actions of agents and other sources of non-stationarities. We show that under this assumption, the correct causal structural choices lead to faster adaptation to modified distributions because the changes are concentrated in one or just a few mechanisms when the learned knowledge is modularized appropriately. This leads to sparse expected gradients and a lower effective number of degrees of freedom needing to be relearned while adapting to the change. It motivates using the speed of adaptation to a modified distribution as a meta-learning objective. We demonstrate how this can be used to determine the cause-effect relationship between two observed variables. The distributional changes do not need to correspond to standard interventions (clamping a variable), and the learner has no direct knowledge of these interventions. We show that causal structures can be parameterized via continuous variables and learned end-to-end. We then explore how these ideas could be used to also learn an encoder that would map low-level observed variables to unobserved causal variables leading to faster adaptation out-of-distribution, learning a representation space where one can satisfy the assumptions of independent mechanisms and of small and sparse changes in these mechanisms due to actions and non-stationarities.","tags":["Causality"],"title":"A Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms","type":"publication"},{"authors":["Alexandre Piche","Rafael Pardinas","David Vazquez","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"f373565937fb5e2ea5a9134b6cecbafa","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/alexandrepicheaproiclrworkshops2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/alexandrepicheaproiclrworkshops2022/","section":"publication","summary":"Reinforcement Learning via Supervised Learning (RvS) only uses supervised techniques to learn desirable behaviors from large datasets. RvS has attracted much attention lately due to its simplicity and ability to leverage diverse trajectories. We introduce Density to Decision (D2D), a new framework, to unify a myriad of RvS algorithms. The Density to Decision framework formulates RvS as a two-step process: i) density estimation via supervised learning and ii) decision making via exponential tilting of the density. Using our framework, we categorise popular RvS algorithms and show how they are different by the design choices in their implementation. We then introduce a novel algorithm, Implicit RvS, leveraging powerful density estimation techniques that can easily be tilted to produce desirable behaviors. We compare the performance of a suite of RvS algorithms on the D4RL benchmark. Finally, we highlight the limitations of current RvS algorithms in comparison with traditional RL ones.","tags":["Reinforcement Learning","Offline Reinforcement Learning","Energy-based model"],"title":"A Probabilistic Perspective on Reinforcement Learning via Supervised Learning","type":"publication"},{"authors":["Paul Barde","Julien Roy","Wonseok Jeon","Joelle Pineau","Christopher Pal","Derek Nowrouzezahrai"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"1d4d8de5f176a16796c10c0e5c07aa82","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/paulbardeadveneurips2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/paulbardeadveneurips2020/","section":"publication","summary":"Adversarial Imitation Learning alternates between learning a discriminator -- which tells apart expert's demonstrations from generated ones -- and a generator's policy to produce trajectories that can fool this discriminator. This alternated optimization is known to be delicate in practice since it compounds unstable adversarial training with brittle and sample-inefficient reinforcement learning. We propose to remove the burden of the policy optimization steps by leveraging a novel discriminator formulation. Specifically, our discriminator is explicitly conditioned on two policies: the one from the previous generator's iteration and a learnable policy. When optimized, this discriminator directly learns the optimal generator's policy. Consequently, our discriminator's update solves the generator's optimization problem for free: learning a policy that imitates the expert does not require an additional optimization loop. This formulation effectively cuts by half the implementation and computational burden of Adversarial Imitation Learning algorithms by removing the Reinforcement Learning phase altogether. We show on a variety of tasks that our simpler approach is competitive to prevalent Imitation Learning methods.","tags":["Imitation Learning"],"title":"Adversarial Soft Advantage Fitting: Imitation Learning without Policy Optimization","type":"publication"},{"authors":["Stanislav Fort","Gintare Karolina Dziugaite","Mansheej Paul","Sepideh Kharaghani","Daniel M. Roy","Surya Ganguli"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"c2372902fdaa91a98f39c0bed8410ed0","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/stanislavfortanemneurips2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/stanislavfortanemneurips2020/","section":"publication","summary":"’ '","tags":["Guarranties"],"title":"An empirical study of loss landscape geometry and evolution of the data-dependent Neural Tangent Kernel","type":"publication"},{"authors":["Quentin Cappart","Thierry Moisan","Louis-Martin Rousseau","Isabeau Prémont-Schwarz","Andre Cire"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"3df7a53f9b6e3a627617c45512bfb858","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/quentincappartcombaaai2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/quentincappartcombaaai2021/","section":"publication","summary":"Combinatorial optimization has found applications in numerous fields, from aerospace to transportation planning and economics. The goal is to find an optimal solution among a finite set of possibilities. The well-known challenge one faces with combinatorial optimization is the state-space explosion problem: the number of possibilities grows exponentially with the problem size, which makes solving intractable for large problems. In the last years, deep reinforcement learning (DRL) has shown its promise for designing good heuristics dedicated to solve NP-hard combinatorial optimization problems. However, current approaches have two shortcomings: (1) they mainly focus on the standard travelling salesman problem and they cannot be easily extended to other problems, and (2) they only provide an approximate solution with no systematic ways to improve it or to prove optimality. In another context, constraint programming (CP) is a generic tool to solve combinatorial optimization problems. Based on a complete search procedure, it will always find the optimal solution if we allow an execution time large enough. A critical design choice, that makes CP non-trivial to use in practice, is the branching decision, directing how the search space is explored. In this work, we propose a general and hybrid approach, based on DRL and CP, for solving combinatorial optimization problems. The core of our approach is based on a dynamic programming formulation, that acts as a bridge between both techniques. We experimentally show that our solver is efficient to solve two challenging problems: the traveling salesman problem with time windows, and the 4-moments portfolio optimization problem. Results obtained show that the framework introduced outperforms the stand-alone RL and CP solutions, while being competitive with industrial solvers.","tags":["Reinforcement Learning","Constrain Programming","Combinatorial Optimization"],"title":"Combining Reinforcement Learning and Constraint Programming for Combinatorial Optimization","type":"publication"},{"authors":["Jonathan Pilault","Amine El Hattami","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"f67445dee8cc2c295d4260a671e1958d","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/jonathanpilaultcondiclr2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/jonathanpilaultcondiclr2021/","section":"publication","summary":"Multi-Task Learning (MTL) networks have emerged as a promising method for transferring learned knowledge across different tasks. However, MTL must deal with challenges such as: overfitting to low resource tasks, catastrophic forgetting, and negative task transfer, or learning interference. Often, in Natural Language Processing (NLP), a separate model per task is needed to obtain the best performance. However, many fine-tuning approaches are both parameter inefficient, i.e., potentially involving one new model per task, and highly susceptible to losing knowledge acquired during pretraining. We propose a novel Transformer architecture consisting of a new conditional attention mechanism as well as a set of task-conditioned modules that facilitate weight sharing. Through this construction, we achieve more efficient parameter sharing and mitigate forgetting by keeping half of the weights of a pretrained model fixed. We also use a new multi-task data sampling strategy to mitigate the negative effects of data imbalance across tasks. Using this approach, we are able to surpass single task fine-tuning methods while being parameter and data efficient (using around 66% of the data for weight updates). Compared to other BERT Large methods on GLUE, our 8-task model surpasses other Adapter methods by 2.8% and our 24-task model outperforms by 0.7-1.0% models that use MTL and single task fine-tuning. We show that a larger variant of our single multi-task model approach performs competitively across 26 NLP tasks and yields state-of-the-art results on a number of test and development sets. Our code is publicly available at this https URL.","tags":["Efficient Learning","Natural Language Processing","Multi-Task Learning"],"title":"Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters \u0026 Less Data","type":"publication"},{"authors":["Ulysse Cote-Allard","Cheikh Latyr Fall","Alexandre Drouin","Alexandre Campeau-Lecours","Clement Gosselin","Kyrre Glette","François Laviolette","Benoit Gosselin"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"9b1823a6be079275db9129d35b53314f","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/ulyssecote-allarddeepieeensre2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/ulyssecote-allarddeepieeensre2018/","section":"publication","summary":"In recent years, deep learning algorithms have become increasingly more prominent for their unparalleled ability to automatically learn discriminant features from large amounts of data. However, within the field of electromyography-based gesture recognition, deep learning algorithms are seldom employed as they require an unreasonable amount of effort from a single person, to generate tens of thousands of examples. ","tags":["Transfer Learning","Robotics","Deep Learning"],"title":"Deep learning for electromyographic hand gesture signal classification using transfer learning","type":"publication"},{"authors":["Gintare Karolina Dziugaite","Shai Ben-David","Daniel M. Roy"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"0e9766f0a8214d0f164170c1ac4a9ffe","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/gintarekarolinadziugaiteenfoarxiv2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/gintarekarolinadziugaiteenfoarxiv2020/","section":"publication","summary":"To date, there has been no formal study of the statistical cost of interpretability in machine learning. As such, the discourse around potential trade-offs is often informal and misconceptions abound. In this work, we aim to initiate a formal study of these trade-offs. A seemingly insurmountable roadblock is the lack of any agreed upon definition of interpretability. Instead, we propose a shift in perspective. Rather than attempt to define interpretability, we propose to model the \\emph{act} of \\emph{enforcing} interpretability. As a starting point, we focus on the setting of empirical risk minimization for binary classification, and view interpretability as a constraint placed on learning. That is, we assume we are given a subset of hypothesis that are deemed to be interpretable, possibly depending on the data distribution and other aspects of the context. We then model the act of enforcing interpretability as that of performing empirical risk minimization over the set of interpretable hypotheses. This model allows us to reason about the statistical implications of enforcing interpretability, using known results in statistical learning theory. Focusing on accuracy, we perform a case analysis, explaining why one may or may not observe a trade-off between accuracy and interpretability when the restriction to interpretable classifiers does or does not come at the cost of some excess statistical risk. We close with some worked examples and some open problems, which we hope will spur further theoretical development around the tradeoffs involved in interpretability.","tags":["Interpretability"],"title":"Enforcing Interpretability and its Statistical Impacts: Trade-offs between Accuracy and Interpretability","type":"publication"},{"authors":["Jose A. Murillo","Yuri Levin","Mikhail Nediak","Ivan Sergienko"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"271597a1444b567ccb04544d7ce7d701","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/josea.murillohowohbr2018/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/josea.murillohowohbr2018/","section":"publication","summary":"GFNorte recently established a Central Analytics Business Unit (ABU) with the mandate to convert information into profits at a rate of 10X cost and to lead the adoption of a customer-centric approach within the organization. The results significantly exceeded expectations. Why did GFNorte’s analytics investment pay off when so many others’ do not? We believe GFNorte did at least six things right to enable its transformation into an analytically enhanced organization: It set targets, had buy-in from the top, got incentives right, rigorously measured results, communicated effectively, and hired the right people.","tags":null,"title":"How One Company Made Its Analytics Investment Pay Off","type":"publication"},{"authors":["Pau Rodriguez","Jordi Gonzalez","Josep M. Gonfaus","Xavier Roca"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"b47cad946c9e5b8d98609e246f421743","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/paurodriguezinteijssh2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/paurodriguezinteijssh2019/","section":"publication","summary":"’ '","tags":["Multi-modal Learning"],"title":"Integrating Vision and Language in Social Networks for Identifying Visual Patterns of Personality Traits","type":"publication"},{"authors":["Diego Velazquez","Josep M. Gonfaus","Pau Rodriguez","F. Xavier Roca","Seiichi Ozawa","Jordi Gonzalez"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"b6a032827c9c47b759eeb13a5d952172","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/diegovelazquezlogoieeeaccess2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/diegovelazquezlogoieeeaccess2021/","section":"publication","summary":"In recent years, top referred methods on object detection like R-CNN have implemented this task as a combination of proposal region generation and supervised classification on the proposed bounding boxes. Although this pipeline has achieved state-of-the-art results in multiple datasets, it has inherent limitations that make object detection a very complex and inefficient task in computational terms. Instead of considering this standard strategy, in this paper we enhance Detection Transformers (DETR) which tackles object detection as a set-prediction problem directly in an end-to-end fully differentiable pipeline without requiring priors. In particular, we incorporate Feature Pyramids (FP) to the DETR architecture and demonstrate the effectiveness of the resulting DETR-FP approach on improving logo detection results thanks to the improved detection of small logos. So, without requiring any domain specific prior to be fed to the model, DETR-FP obtains competitive results on the OpenLogo and MS-COCO datasets offering a relative improvement of up to 30%, when compared to a Faster R-CNN baseline which strongly depends on hand-designed priors.","tags":["Computer Vision","Object Detection"],"title":"Logo Detection with no Priors","type":"publication"},{"authors":["Francis Brochu","Pier-Luc Plante","Alexandre Drouin","Dominic Gagnon","Dave Richard","Francine Durocher","Caroline Diorio","Mario Marchand","Jacques Corbeil","François Laviolette"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"72530d417282b995391248e551a9f1fb","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/francisbrochumassnaturesr2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/francisbrochumassnaturesr2020/","section":"publication","summary":"Mass spectrometry is a valued method to evaluate the metabolomics content of a biological sample. The recent advent of rapid ionization technologies such as Laser Diode Thermal Desorption (LDTD) and Direct Analysis in Real Time (DART) has rendered high-throughput mass spectrometry possible. It is used for large-scale comparative analysis of populations of samples. In practice, many factors resulting from the environment, the protocol, and even the instrument itself, can lead to minor discrepancies between spectra, rendering automated comparative analysis difficult. In this work, a sequence/pipeline of algorithms to correct variations between spectra is proposed. The algorithms correct multiple spectra by identifying peaks that are common to all and, from those, computes a spectrum-specific correction. We show that these algorithms increase comparability within large datasets of spectra, facilitating comparative analysis, such as machine learning.","tags":["Bioinformatics","Data Augmentation"],"title":"Mass spectra alignment using virtual lock-masses","type":"publication"},{"authors":["Nicolas Gontier","Koustuv Sinha","Siva Reddy","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"d3ea70dca3be1d2ad9201c6391bdc2f6","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/nicolasgontiermeasneurips2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/nicolasgontiermeasneurips2020/","section":"publication","summary":"We are interested in understanding how well Transformer language models (TLMs) can perform reasoning tasks when trained on knowledge encoded in the form of natural language. We investigate their systematic generalization abilities on a logical reasoning task in natural language, which involves reasoning over relationships between entities grounded in first-order logical proofs. Specifically, we perform soft theorem-proving by leveraging TLMs to generate natural language proofs. We test the generated proofs for logical consistency, along with the accuracy of the final inference. We observe length-generalization issues when evaluated on longer-than-trained sequences. However, we observe TLMs improve their generalization performance after being exposed to longer, exhaustive proofs. In addition, we discover that TLMs are able to generalize better using backward-chaining proofs compared to their forward-chaining counterparts, while they find it easier to generate forward chaining proofs. We observe that models that are not trained to generate proofs are better at generalizing to problems based on longer proofs. This suggests that Transformers have efficient internal reasoning strategies that are harder to interpret. These results highlight the systematic generalization behavior of TLMs in the context of logical reasoning, and we believe this work motivates deeper inspection of their underlying reasoning strategies.","tags":["Systematic Generalization","Transformers"],"title":"Measuring Systematic Generalization in Neural Proof Generation with Transformers","type":"publication"},{"authors":["Boris N. Oreshkin","Dmitri Carpov","Nicolas Chapados","Yoshua Bengio"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"6a1f2e286e2d9bb9434d2bbbeab2ec43","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/borisn.oreshkinmetaiclr2019/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/borisn.oreshkinmetaiclr2019/","section":"publication","summary":"Can meta-learning discover generic ways of processing time series (TS) from a diverse dataset so as to greatly improve generalization on new TS coming from different datasets? This work provides positive evidence to this using a broad meta-learning framework which we show subsumes many existing meta-learning algorithms. Our theoretical analysis suggests that residual connections act as a meta-learning adaptation mechanism, generating a subset of task-specific parameters based on a given TS input, thus gradually expanding the expressive power of the architecture on-the-fly. The same mechanism is shown via linearization analysis to have the interpretation of a sequential update of the final linear layer. Our empirical results on a wide range of data emphasize the importance of the identified meta-learning mechanisms for successful zero-shot univariate forecasting, suggesting that it is viable to train a neural network on a source TS dataset and deploy it on a different target TS dataset without retraining, resulting in performance that is at least as good as that of state-of-practice univariate forecasting models.","tags":["Meta-Learning","Zero-Shot Learning","Time Series"],"title":"Meta-Learning Framework with Applications to Zero-Shot Time Series Forecasting","type":"publication"},{"authors":["Gintare Karolina Dziugaite","Kyle Hsu","Waseem Gharbieh","Gabriel Arpino","Daniel M. Roy"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"240e4fa941289ffd35afb71e4d911445","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/gintarekarolinadziugaiteonthaistats2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/gintarekarolinadziugaiteonthaistats2021/","section":"publication","summary":"The dominant term in PAC-Bayes bounds is often the Kullback--Leibler divergence between the posterior and prior. For so-called linear PAC-Bayes risk bounds based on the empirical risk of a fixed posterior kernel, it is possible to minimize the expected value of the bound by choosing the prior to be the expected posterior, which we call the oracle prior on the account that it is distribution dependent. In this work, we show that the bound based on the oracle prior can be suboptimal: In some cases, a stronger bound is obtained by using a data-dependent oracle prior, i.e., a conditional expectation of the posterior, given a subset of the training data that is then excluded from the empirical risk term. While using data to learn a prior is a known heuristic, its essential role in optimal bounds is new. In fact, we show that using data can mean the difference between vacuous and nonvacuous bounds. We apply this new principle in the setting of nonconvex learning, simulating data-dependent oracle priors on MNIST and Fashion MNIST with and without held-out data, and demonstrating new nonvacuous bounds in both cases.","tags":["Guarranties"],"title":"On the role of data in PAC-Bayes bounds","type":"publication"},{"authors":["Yoshua Bengio","Prateek Gupta","Tegan Maharaj","Nasim Rahaman","Martin Weiss","Tristan Deleu","Eilif Benjamin Muller","Meng Qu","victor schmidt","Pierre-luc St-charles","hannah alsdurf","Olexa Bilaniuk","david buckeridge","gaetan caron","pierre luc carrier","Joumana Ghosn","satya ortiz gagne","Christopher Pal","Irina Rish","Bernhard Schölkopf","abhinav sharma","Jian Tang","andrew williams"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"d86ccc67999f20ab91f02959c9193952","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/yoshuabengioprediclr2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/yoshuabengioprediclr2021/","section":"publication","summary":"The COVID-19 pandemic has spread rapidly worldwide, overwhelming manual contact tracing in many countries and resulting in widespread lockdowns for emergency containment. Large-scale digital contact tracing (DCT) has emerged as a potential solution to resume economic and social activity while minimizing spread of the virus. Various DCT methods have been proposed, each making trade-offs between privacy, mobility restrictions, and public health. The most common approach, binary contact tracing (BCT), models infection as a binary event, informed only by an individual's test results, with corresponding binary recommendations that either all or none of the individual's contacts quarantine. BCT ignores the inherent uncertainty in contacts and the infection process, which could be used to tailor messaging to high-risk individuals, and prompt proactive testing or earlier warnings. It also does not make use of observations such as symptoms or pre-existing medical conditions, which could be used to make more accurate infectiousness predictions. In this paper, we use a recently-proposed COVID-19 epidemiological simulator to develop and test methods that can be deployed to a smartphone to locally and proactively predict an individual's infectiousness (risk of infecting others) based on their contact history and other information, while respecting strong privacy constraints. Predictions are used to provide personalized recommendations to the individual via an app, as well as to send anonymized messages to the individual's contacts, who use this information to better predict their own infectiousness, an approach we call proactive contact tracing (PCT). We find a deep-learning based PCT method which improves over BCT for equivalent average mobility, suggesting PCT could help in safe re-opening and second-wave prevention.","tags":null,"title":"Predicting Infectiousness for Proactive Contact Tracing","type":"publication"},{"authors":["Julien Roy","Paul Barde","Félix G. Harvey","Derek Nowrouzezahrai","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"08e5b5b27bd32f0c580b4e242340b0c4","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/julienroypromneurips2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/julienroypromneurips2020/","section":"publication","summary":"In multi-agent reinforcement learning, discovering successful collective behaviors is challenging as it requires exploring a joint action space that grows exponentially with the number of agents. While the tractability of independent agent-wise exploration is appealing, this approach fails on tasks that require elaborate group strategies. We argue that coordinating the agents' policies can guide their exploration and we investigate techniques to promote such an inductive bias. We propose two policy regularization methods: TeamReg, which is based on inter-agent action predictability and CoachReg that relies on synchronized behavior selection. We evaluate each approach on four challenging continuous control tasks with sparse rewards that require varying levels of coordination as well as on the discrete action Google Research Football environment. Our experiments show improved performance across many cooperative multi-agent problems. Finally, we analyze the effects of our proposed methods on the policies that our agents learn and show that our methods successfully enforce the qualities that we propose as proxies for coordinated behaviors.","tags":["Reinforcement Learning"],"title":"Promoting Coordination through Policy Regularization in Multi-Agent Deep Reinforcement Learning","type":"publication"},{"authors":["Jonathan Frankle","Gintare Karolina Dziugaite","Daniel M. Roy","Michael Carbin"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"aec23b8baac412d7b35d2387f6b102da","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/jonathanfranklepruniclr2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/jonathanfranklepruniclr2021/","section":"publication","summary":"Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.","tags":null,"title":"Pruning Neural Networks at Initialization: Why are We Missing the Mark?","type":"publication"},{"authors":["Jonathan Frankle","Gintare Karolina Dziugaite","Daniel M. Roy","Michael Carbin"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"5a1d9413ef6899028884522ffe75b8e2","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/jonathanfrankleprunneuripsworkshops2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/jonathanfrankleprunneuripsworkshops2020/","section":"publication","summary":"Recent work has explored the possibility of pruning neural networks at initialization. We assess proposals for doing so: SNIP (Lee et al., 2019), GraSP (Wang et al., 2020), SynFlow (Tanaka et al., 2020), and magnitude pruning. Although these methods surpass the trivial baseline of random pruning, they remain below the accuracy of magnitude pruning after training, and we endeavor to understand why. We show that, unlike pruning after training, randomly shuffling the weights these methods prune within each layer or sampling new initial values preserves or improves accuracy. As such, the per-weight pruning decisions made by these methods can be replaced by a per-layer choice of the fraction of weights to prune. This property suggests broader challenges with the underlying pruning heuristics, the desire to prune at initialization, or both.","tags":null,"title":"Pruning Neural Networks at Initialization: Why Are We Missing the Mark? ","type":"publication"},{"authors":["Simon Ramstedt","Yann Bouteiller","Giovanni Beltrame","Christopher Pal","Jonathan Binas"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"841fc09911498c7acc2e0f792a32c146","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/simonramstedtreiniclr2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/simonramstedtreiniclr2021/","section":"publication","summary":"Action and observation delays commonly occur in many Reinforcement Learning applications, such as remote control scenarios. We study the anatomy of randomly delayed environments, and show that partially resampling trajectory fragments in hindsight allows for off-policy multi-step value estimation. We apply this principle to derive Delay-Correcting Actor-Critic (DCAC), an algorithm based on Soft Actor-Critic with significantly better performance in environments with delays. This is shown theoretically and also demonstrated practically on a delay-augmented version of the MuJoCo continuous control benchmark.","tags":["Reinforcement Learning"],"title":"Reinforcement Learning with Random Delays","type":"publication"},{"authors":["Mahdi Haghifam","Jeffrey Negrea","Ashish Khisti","Daniel M. Roy","Gintare Karolina Dziugaite"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"784a0f46cddaf6035c3b5db164b3e6a8","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/mahdihaghifamsharneurips2020/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/mahdihaghifamsharneurips2020/","section":"publication","summary":"The information-theoretic framework of Russo and J. Zou (2016) and Xu and Raginsky (2017) provides bounds on the generalization error of a learning algorithm in terms of the mutual information between the algorithm's output and the training sample. In this work, we study the proposal, by Steinke and Zakynthinou (2020), to reason about the generalization error of a learning algorithm by introducing a super sample that contains the training sample as a random subset and computing mutual information conditional on the super sample. We first show that these new bounds based on the conditional mutual information are tighter than those based on the unconditional mutual information. We then introduce yet tighter bounds, building on the \"individual sample\" idea of Bu, S. Zou, and Veeravalli (2019) and the \"data dependent\" ideas of Negrea et al. (2019), using disintegrated mutual information. Finally, we apply these bounds to the study of Langevin dynamics algorithm, showing that conditioning on the super sample allows us to exploit information in the optimization trajectory to obtain tighter bounds based on hypothesis tests.","tags":["Guarranties"],"title":"Sharpened Generalization Bounds based on Conditional Mutual Information and an Application to Noisy-Gradient Iterative Algorithms","type":"publication"},{"authors":["Nan Rosemary Ke","Aniket Didolkar","Sarthak Mittal","Anirudh Goyal","Guillaume Lajoie","Stefan Bauer","Danilo Rezende","Yoshua Bengio","Michael Mozer","Christopher Pal"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"7c9e8fbe3b251ec56ac09eaee7b703ee","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/nanrosemarykesystneurips2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/nanrosemarykesystneurips2021/","section":"publication","summary":"Inducing causal relationships from observations is a classic problem in machine learning. Most work in causality starts from the premise that the causal variables themselves are observed. However, for AI agents such as robots trying to make sense of their environment, the only observables are low-level variables like pixels in images. To generalize well, an agent must induce high-level variables, particularly those which are causal or are affected by causal variables. A central goal for AI and causality is thus the joint discovery of abstract representations and causal structure. However, we note that existing environments for studying causal induction are poorly suited for this objective because they have complicated task-specific causal graphs which are impossible to manipulate parametrically (e.g., number of nodes, sparsity, causal chain length, etc.). In this work, our goal is to facilitate research in learning representations of high-level variables as well as causal structures among them. In order to systematically probe the ability of methods to identify these variables and structures, we design a suite of benchmarking RL environments. We evaluate various representation learning algorithms from the literature and find that explicitly incorporating structure and modularity in models can help causal induction in model-based reinforcement learning.","tags":["Causality","Causal Discovery","Reinforcement Learning"],"title":"Systematic Evaluation of Causal Discovery in Visual Model Based Reinforcement Learning","type":"publication"},{"authors":["Sai Rajeswar","Cyril Ibrahim","Nitin Surya","Florian Golemo","David Vazquez","Aaron Courville","Pedro O. Pinheiro"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"82a4e75d28ff829a3fdf227ecf015885","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/sairajeswartouccorl2021/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/sairajeswartouccorl2021/","section":"publication","summary":"Robots in many real-world settings have access to force/torque sensors in their gripper and tactile sensing is often necessary in tasks that involve contact-rich motion. In this work, we leverage surprise from mismatches in touch feedback to guide exploration in hard sparse-reward reinforcement learning tasks. Our approach, Touch-based Curiosity (ToC), learns what visible objects interactions are supposed to \"feel\" like. We encourage exploration by rewarding interactions where the expectation and the experience don't match. In our proposed method, an initial task-independent exploration phase is followed by an on-task learning phase, in which the original interactions are relabeled with on-task rewards. We test our approach on a range of touch-intensive robot arm tasks (e.g. pushing objects, opening doors), which we also release as part of this work. Across multiple experiments in a simulated setting, we demonstrate that our method is able to learn these difficult tasks through sparse reward and curiosity alone. We compare our cross-modal approach to single-modality (touch- or vision-only) approaches as well as other curiosity-based methods and find that our method performs better and is more sample-efficient.","tags":["Computer Vision","Reinforcement Learning","Multi-modal Learning","Curiosity Learning"],"title":"Touch-based Curiosity for Sparse-Reward Tasks","type":"publication"},{"authors":["Torsten Scholak","Tao Yu"],"categories":null,"content":"’ \u0026#39;\n","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1483228800,"objectID":"a554c9557ee10c7d37430c6499df9a2b","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/torstenscholakunifnoconference2022/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/torstenscholakunifnoconference2022/","section":"publication","summary":"Structured knowledge grounding (SKG) leverages structured knowledge to complete user requests, such as semantic parsing over databases and question answering over knowledge bases. Since the inputs and outputs of SKG tasks are heterogeneous, they have been studied separately by different communities, which limits systematic and compatible research on SKG. In this paper, we overcome this limitation by proposing the SKG framework, which unifies 21 SKG tasks into a text-to-text format, aiming to promote systematic SKG research, instead of being exclusive to a single task, domain, or dataset. We use UnifiedSKG to benchmark T5 with different sizes and show that T5, with simple modifications when necessary, achieves state-of-the-art performance on almost all of the 21 tasks. We further demonstrate that multi-task prefix-tuning improves the performance on most tasks, largely improving the overall performance. UnifiedSKG also facilitates the investigation of zero-shot and few-shot learning, and we show that T0, GPT-3, and Codex struggle in zero-shot and few-shot learning for SKG. We also use UnifiedSKG to conduct a series of controlled experiments on structured knowledge encoding variants across SKG tasks. UnifiedSKG is easily extensible to more tasks, and it is open-sourced at this https URL Latest collections at this https URL.","tags":["Natural Language Processing","Sequence to Sequence","Multi-Task Learning"],"title":"UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models","type":"publication"},{"authors":["Eunsol Choi","Daniel Hewlett","Jakob Uszkoreit","Illia Polosukhin","Alexandre Lacoste","Jonathan Berant"],"categories":null,"content":"’ \u0026#39;\n","date":1457049600,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":1457049600,"objectID":"c1c0c46e6ce9329222b1fc3854250150","permalink":"https://elementai.github.io/servicenowresearch/fr/publication/eunsolchoicoaracl2016/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/publication/eunsolchoicoaracl2016/","section":"publication","summary":"We present a framework for question answering that can efficiently scale to longer documents while maintaining or even improving performance of state-of- the-art models. While most successful ap- proaches for reading comprehension rely on recurrent neural networks (RNNs), run- ning them over long documents is pro- hibitively slow because it is difficult to parallelize over sequences. Inspired by how people first skim the document, iden- tify relevant parts, and carefully read these parts to produce an answer, we combine a coarse, fast model for selecting rele- vant sentences and a more expensive RNN for producing the answer from those sen- tences. We treat sentence selection as a la- tent variable trained jointly from the an- swer only using reinforcement learning. Experiments demonstrate the state of the art performance on a challenging subset of the WIKIREADING dataset (Hewlett et al., 2016) and on a new dataset, while speed- ing up the model by 3.5x-6.7x.","tags":["Natural Language Processing","Question Answering"],"title":"Coarse-to-Fine Question Answering for Long Documents","type":"publication"},{"authors":null,"categories":null,"content":"‘The Fashion-Gen dataset includes 293,008 high-definition fashion images paired with item descriptions provided by professional stylists from the fashion design domain. It provides an excellent public benchmark for research exploring state-of-the-art text-to-image design-oriented generative models.\nFashion-Gen data is expert-annotated e-commerce photographs shared by the global fashion platform SSENSE with the AI research community and partnering with ServiceNow to prepare and host the data.\n\u0026#39;\n","date":-61945603200,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":-61945603200,"objectID":"e4ddebf8643f91703d66592221e8a513","permalink":"https://elementai.github.io/servicenowresearch/fr/datasets/fashion-gen-the/","publishdate":"0007-01-09T00:00:00Z","relpermalink":"/servicenowresearch/fr/datasets/fashion-gen-the/","section":"datasets","summary":"The Fashion-Gen dataset includes 293,008 high-definition fashion images paired with item descriptions provided by professional stylists from the fashion design domain. It provides an excellent public benchmark for research exploring state-of-the-art text-to-image design-oriented generative models. Fashion-Gen data is expert-annotated e-commerce photographs shared by the global fashion platform SSENSE with the AI research community and partnering with ServiceNow to prepare and host the data.","tags":null,"title":"Fashion-Gen: the generative fashion dataset","type":"datasets"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":-62135596800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://elementai.github.io/servicenowresearch/fr/contact/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/contact/","section":"","summary":"","tags":null,"title":"","type":"widget_page"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"fr","lastmod":-62135596800,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://elementai.github.io/servicenowresearch/fr/people/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/servicenowresearch/fr/people/","section":"","summary":"","tags":null,"title":"","type":"widget_page"}]